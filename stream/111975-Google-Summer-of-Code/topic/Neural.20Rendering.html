<html>
<head><meta charset="utf-8"><title>Neural Rendering · Google Summer of Code · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/index.html">Google Summer of Code</a></h2>
<h3>Topic: <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html">Neural Rendering</a></h3>

<hr>

<base href="https://brlcad.zulipchat.com">

<head><link href="https://brl-cad.github.io/zulip_archive/style.css" rel="stylesheet"></head>

<a name="424426002"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424426002" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424426002">(Mar 02 2024 at 16:42)</a>:</h4>
<p>Hi <span class="user-mention" data-user-id="694938">@Senthil Palanisamy</span>, lets continue the discussion here.  Can you tell me more about your background and what you understand about this effort?  Have you read the AMD paper?</p>



<a name="424429528"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424429528" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424429528">(Mar 02 2024 at 17:27)</a>:</h4>
<p>(deleted)</p>



<a name="424455092"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424455092" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Senthil Palanisamy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424455092">(Mar 02 2024 at 23:36)</a>:</h4>
<p>Hi Sean, Thanks for the message. </p>
<p><strong>About my background:</strong> I come from a geometric vision background where I worked more than 6 years, to go along with my masters in robotics from Northwestern.  I have developed solutions to problems like Stereo visual Odometry, Depth data based SLAM / TSDF fusion of depth maps into a volumetric volume to generate geometry, Extrinsic sensor calibration algorithms (the act of optimizing solutions to where sensors are located). I have done a few deep learning works as well like deep reinforcement policy  learning for a knot tieing, weed localization and human character recgonition. I can send you my resume to any mail id of interest, if you want to know about my background further. Though I don't actively have a graphics background, I do understand the broader details and am able to grasp quickly to execute ideas. My programming languages of comfort are C++ and python (though I do think I can pick up any language within a reasonable time)</p>
<p><strong>About the work</strong>: I did spent a few hours trying to understand the work. Here is my summary - A classic ray tracing pipeline on BVH for rendering objects is slow. One of the deep learning ways to speed this up is to  train a MLP to be a neural intersection function - a network that primarily predicts occupancy as a probability (0-1), but it can be trained to predict other properties as well like shading /  reflectence. This network can be trained directly on position and ray directions, but it does not practically work well. So, the solution is to learn some feature embeddings for position and direction, which then feed into MLP. Each of position and direction are points in R^3, but this leads to ray duplicates, so they can be compactly represented as points in R^2, by using spherical co-ordinates and substituting the ray origin with ray intersection. Raycasting is usually done in multi bounces, where secondary rays are traced from the primary ray. So there are two NIFs one (outer NIF) predicting the primary intersection, and the other (inner NIF) predicting occupancy from the secondary intersection. The inner NIF takes ray distance embedding as input in addition to position and direction embeddings. It seems like a classic tracing tracing scheme employs two hierarchies in BVH to trace rays. The top BVH tracing is cheap while the bottom BVH tracking is expensive. NIFs replace the bottom BVH part, while the top BVH tracing is done through classical means. The outer NIF just predicts occupancy while the inner NIF predicts other properties in addition to occupancy.</p>
<p><strong>Some open questions I am still trying to find answers to</strong></p>
<ol>
<li>What is the feature embedding scheme for position and direction? I know that sine and cosine bases (fourier analysis motivated) is used a lot in works like nerfs, but I have not got to the bottom of what embedding is used here</li>
<li>It seems like the networks used here are AMD specific C++ libraries. Is this something that we will use in this work? Or is the idea to use a more popular library like pytorch.</li>
</ol>
<p><strong>My personal motivation for taking this work</strong></p>
<ol>
<li>I have never contributed to open source and I was scouting for places to begin my open source journey. Contributing to open source increases my visibility and exposes me to learn a lot more than from just contributing to the private repos that I work for.</li>
<li>I want to work on a geometric deep learning project to update myself to the SOTA</li>
</ol>



<a name="424676516"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424676516" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424676516">(Mar 04 2024 at 15:06)</a>:</h4>
<p><span class="user-mention" data-user-id="694938">@Senthil Palanisamy</span> Thank you for the excellent introduction.  From your background, it sounds like you could probably propose a couple different projects that would align with needs (like a slam-based object reconstruction using ray tracing), which is all outstanding background for working on neural rendering.  Obviously a lot of related concepts.  As for your resume, you can just submit that when you submit a proposal (which you can/should do early and then continuously update, whenever it opens).  Given the nature of GSoC, resume's and the project write-up itself are only a small fraction of selection criteria.  It's communication that matters most (both here and via code).</p>
<p>I think your understanding of the project is right on track and you did a great job summarizing AMD's work.  They essentially showed that it can be faster, so now my question is whether it can be faster and more generally applicable for a set of conditions like expensive geometries and reasonably precise hit points. Can we actually use it as an acceleration structure in practice, or is the training phase entirely impractical; what sort of net is needed to capture all the necessary detail; is the two-layer network adequate; are the two NIFs actually necessary; ... lots of open questions many of which are hand-waved in the paper and proved challenging in our previous investigations by a team at TAMU.</p>
<p>As to your questions, if I'm understanding you correctly, then 1) is really just a dimensionality reduction so lookups can be fast and fewer parameters in the latent space are needed for encoding.  Instead of using 6 float/double values for the input layer (xyz pos + ijk dir), they use 4 float values (az/el pos + az/el dir).  There may be more nuance implied for feature embedding, though, so there may be work needed to understand it if changes are to be made.  I'm a little surprised I didn't see residual linkages, and that they got away with such simple topology, but then we have yet to reproduce  their results either. As for 2) the did rely on libs for performance and they certainly can be used but they're not a focus or requirement.  The fundamental question is is this approach even feasible as an acceleration approach to represent a given geometry model.  That has both elements of accuracy and performance, but can be proven without making it production-ready.  Libs like pytorch can certainly be used.  In fact, the previous team fully bridged from C to Py to C during ray-tracing which was of course painfully slow, but they weren't successful in getting accurate hit points so the question is still an open one.</p>



<a name="424707867"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424707867" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Senthil Palanisamy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424707867">(Mar 04 2024 at 17:23)</a>:</h4>
<p>Thanks for the response. The grid look up makes sense now. I was intially under the misunderstanding that some network converts position, direction -&gt; position, direction embedding. But it does make sense that it is just a grid that is trained as well in the training process. I have a few follow up questions</p>
<ol>
<li>What kind of training practically are we talking of? Since this is a CAD product, is the idea that the network has to train real time as the user possibly edits the model to update the rendering in real time? Or is the idea the training can be done once, in a somewhat offline fashion (like a few minutes or few 10s of minutes) and then can be used for rendering (where the user is assumed to not edit)</li>
<li>As for the implementation is concerned, the network itself looks simple and innocuous, each NIF is a MLP - the outer is a 2 layer MLP with 64 units in each layer, while the inner NIF is a two layer MLP with 48 units in each layer, I am just trying to get my head around how the training data is generated and from what sources,  to set up this training problem. I should be able to code this up once I figure out the training data.</li>
<li>You mentioned something about another project - "slam-based object reconstruction using ray tracing", Can you point me to any thread or resources to understand this better? I would love to know details about this.</li>
</ol>



<a name="424801041"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424801041" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424801041">(Mar 05 2024 at 05:59)</a>:</h4>
<p>It's not really a grid lookup.  It's just a different way to express a vector.  For the neural net, it's less input data and thus less latent space nodes are needed to encode.  It's still just a vector though, a clever optimization.  We even coincidentally have an image depicting both (the vector can point outwards or inwards): <a href="https://brlcad.org/gallery/picture.php?/4">https://brlcad.org/gallery/picture.php?/4</a></p>
<ol>
<li>
<p>The latter. A given model will get "baked" such that a NN is trained, ideally in just a couple minutes,  and then is available+valid for use until the geometry changes.</p>
</li>
<li>
<p>The training data should come directly from the ray tracer (either in advance or streamed real-time).  Imagine shooting a million rays at an object from it's bounding sphere, some hit, some miss.  Each hit is not just the first hit but all the possible hits along the path.  That's the training corpus.  Rays input, hit list output.  We can probably shoot rays faster than the net can train an epoch, so you'd probably want to just stream rays as fast as it can train.  Alternatively, shoot a million, train, shoot another million, train, etc.<br>
<a href="/user_uploads/1549/NkXAc6hfckCsEFq5EfLJEnb0/rppvalidation_dirs.png">rppvalidation_dirs.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/NkXAc6hfckCsEFq5EfLJEnb0/rppvalidation_dirs.png" title="rppvalidation_dirs.png"><img src="/user_uploads/1549/NkXAc6hfckCsEFq5EfLJEnb0/rppvalidation_dirs.png"></a></div></li>
<li>
<p>there's no threads on the topic.  general idea though would be to propose something CAD-related involving slam like making a portable 3D CAD scanner app. e.g., try to output CAD instead of just point clouds or meshes.  maybe hook into iphone lidar sensor.   could also be slam and point cloud based, but then imports into BRL-CAD on the fly for processing.  lots of possibilities.</p>
</li>
</ol>
<p>You'd have to really make a strong case for your project regardless.  Needs to have a compelling benefit that ties into CAD specifically, not just 3D or vision or graphics-related.</p>



<a name="425358037"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/425358037" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Senthil Palanisamy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#425358037">(Mar 07 2024 at 17:26)</a>:</h4>
<p>Thanks for the clarification. I went back and spent more time. I think I am getting closer to the true understanding. Its funny my understanding about the work keeps getting refined and is probably starting to converge. So it seems like the grid encoding is done on a per object basis - the inputs for both for the outer and inner network, while the networks itself are object agnostic occupancy predictors. So we would end up having two encoded grids (one for outer and one for innter) for each unique object and two network that are sort of object agnostic, but acts on any given object to predict occupancy. </p>
<p>In order to accomplish this, I would need to modify the ray tracing pipeline on our system - record input data - for both outer and inner network and then attempt to train those networks</p>
<p>So my two action items are</p>
<ol>
<li>Modify the existing pipeline to record data</li>
<li>Work on the network that can train on this</li>
</ol>
<p>I think I can do action 2 pretty independently (the networks are simple) but to do 1, I would need some directions on how I can do this. What's the fastest way to get there? Are there any documents /sections of code in our repository that I can go through to better understand how to do this? Also, I will try to setup BRL CAD (<a href="https://github.com/BRL-CAD/brlcad">https://github.com/BRL-CAD/brlcad</a>) in the first place, which I will get started with</p>
<p>I know we are interested in the core hypothesis of - is this fast enough? If there is a way to get this data, without having to collect it ourselves (may be any opensource datasets that can be directly plugged in), if any such options exist, the core hypothesis on speed can be validated quicker? Any thoughts on this</p>



<a name="429793730"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/429793730" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#429793730">(Mar 27 2024 at 06:42)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> and others, I have uploaded information and materials relevant to the neural rendering project to <a href="https://brlcad.org/design/neural">https://brlcad.org/design/neural</a></p>



<a name="430048328"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430048328" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430048328">(Mar 28 2024 at 11:41)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> I looked over your proposal update and it looks really pretty good.  I like that you identified some potential errors in the tamu team's approach.   I think overall you have a good plan. </p>
<p>That said, I think you could make your proposal even better by more clearly identifying what the results of your project will be exactly.  I love that you dedicated time to writing up results -- it's reasonable to spend time getting a paper out of this work given the nature of the work.  In additional to a technical paper, though, what precisely will be the resulting products of your work in addition to things learned, which will be documented and which you underscored in your writeup.</p>



<a name="430048607"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430048607" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430048607">(Mar 28 2024 at 11:43)</a>:</h4>
<p>Is the goal to implement a non-grid sampling method, train on that, and demonstrate the efficacy of using that method with "rt" or something similar?  The tamu team resorted to a fixed view silhouette rendering via "rt" as their output target given they couldn't fully achieve generalization to 3D.</p>



<a name="430048840"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430048840" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430048840">(Mar 28 2024 at 11:45)</a>:</h4>
<p>You mention nerf and potentially using different networks -- could definitely write more on what you mean there.  I do suspect that the simple 2-layer FCN is inadequate for full generalization, but AMD's results certainly suggest otherwise may be possible.</p>



<a name="430050286"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430050286" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430050286">(Mar 28 2024 at 11:52)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Thank you for reading. Essentially, the goal is to achieve generalization, so we will try an approach aimed at improving the bounding box approach. However, even by adding this, I suspect that the neural network implemented by the students may not be sufficient to ensure good generalization for any view and thus for any arbitrary ray. For this reason, I believe (but it needs to be verified after obtaining the results of the first part) that it is reasonable to consider modifying the neural network with others more powerful to encode more information about the geometry of the 3D object. In any case, I will provide a better explanation in the proposal. Thank you.</p>



<a name="430050760"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430050760" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430050760">(Mar 28 2024 at 11:54)</a>:</h4>
<p>An approach I think would be considerably more effective is generating training data based on spherical sampling.  That in practice does a very good job to sample the volume unbiased and converges through potential shotlines.  It's pretty simple to generate -- I just did that in our new "rtsurf" application.</p>



<a name="430050913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430050913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430050913">(Mar 28 2024 at 11:55)</a>:</h4>
<p>Ends up looking a bit like this:<br>
<a href="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png">rppvalidation_dirs.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png" title="rppvalidation_dirs.png"><img src="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png"></a></div>



<a name="430051414"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430051414" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430051414">(Mar 28 2024 at 11:58)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/430050913">ha scritto</a>:</p>
<blockquote>
<p>Ends up looking a bit like this:<br>
<a href="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png">rppvalidation_dirs.png</a></p>
</blockquote>
<p>yes i think it's the same of the bounding box approach used by tamu students or am I wrong?<br>
<a href="/user_uploads/1549/r0S--pVCJ3nqBeJL1barFFe6/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/r0S--pVCJ3nqBeJL1barFFe6/image.png" title="image.png"><img src="/user_uploads/1549/r0S--pVCJ3nqBeJL1barFFe6/image.png"></a></div>



<a name="430051517"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430051517" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430051517">(Mar 28 2024 at 11:58)</a>:</h4>
<p>I don't know why they call it bounding box even though it seems more like a sphere.</p>



<a name="430052785"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430052785" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430052785">(Mar 28 2024 at 12:04)</a>:</h4>
<p>So it seems that Tamu students have previously employed this method to generate training data, but encountered issues with its generalization. I believe that the neural network might be lacking in its ability to extract all pertinent information from the geometry.</p>



<a name="430053474"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430053474" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430053474">(Mar 28 2024 at 12:07)</a>:</h4>
<p>I have not looked into their code to see whether they're actually evaluating the bounding box or bounding sphere, but I do recall them saying all rays sample through the origin so it's not an unbiased sampling regardless.</p>



<a name="430053747"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430053747" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430053747">(Mar 28 2024 at 12:08)</a>:</h4>
<p>that image there could also simply be hits on a sphere in a bounding box, heh.  would have to double check that as well.</p>



<a name="430054563"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430054563" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430054563">(Mar 28 2024 at 12:13)</a>:</h4>
<p>That is, I believe they were sampling the geometry like this:  <a href="/user_uploads/1549/TLh7Bb0AEw2wdPF0pP9pUy4x/samples.png">samples.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/TLh7Bb0AEw2wdPF0pP9pUy4x/samples.png" title="samples.png"><img src="/user_uploads/1549/TLh7Bb0AEw2wdPF0pP9pUy4x/samples.png"></a></div><p>The general assumption being they were sampling and trying to reconstruct simple shapes like a box, sphere, torus, etc.</p>



<a name="430054708"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430054708" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430054708">(Mar 28 2024 at 12:14)</a>:</h4>
<p>i.e., <a href="/user_uploads/1549/pMsyrJjZ86LIxqmXAVd5-uwW/box.png">box.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/pMsyrJjZ86LIxqmXAVd5-uwW/box.png" title="box.png"><img src="/user_uploads/1549/pMsyrJjZ86LIxqmXAVd5-uwW/box.png"></a></div>



<a name="430077955"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430077955" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430077955">(Mar 28 2024 at 14:19)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> you were right. I studied better what they did as sampling methods and it seems they used these two approaches: one is a grid approach (and ok we all agree it can't be used for generalization), the second is a mixed bounding box exactly like you said (ray origins were selected from a bounding sphere around the geometry, as well as from within the bounding sphere itself). <br>
But there was another approach they never tested, the "pure" bounding sphere approach: this<br>
method find a random point at radius distance away from the center of the geometry. This would serve as the ray origin. Then, it would find a different, random point at radius distance away from the origin. It would then determine the direction between the two points to determine the direction vector of the ray. It's pretty clear that this is the approach you suggested.<br>
This morning I had understood that they had used this latest approach (so I assumed that neither with this sampling they could generalize), but I was wrong. So, this changes everything because there might not be a need to implement any more sophisticated neural network (but it all depends on the results we will have on thanks to this different spherical sampling).</p>



<a name="430087784"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430087784" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430087784">(Mar 28 2024 at 15:00)</a>:</h4>
<p><span class="user-mention" data-user-id="102939">@Daniel Rossberg</span> I have updated my proposal and submitted it. I am looking forward for hearing from you. <br>
Thanks</p>



<a name="440303717"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/440303717" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#440303717">(May 23 2024 at 11:36)</a>:</h4>
<p>While looking through previous work(<a href="https://brlcad.org/design/neural/">https://brlcad.org/design/neural/</a>), I noticed this <a href="https://colab.research.google.com/drive/1WtY_IdgLojdbwzfachHtpOIim7n1XPbg?usp=sharing#scrollTo=jLLlkJfDP-tN">file</a> to what looks like a python version of the NIF implementation. Perhaps I could start by converting this job to a C++ version?Then in the meantime, I'll try to optimize it.</p>



<a name="440312021"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/440312021" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#440312021">(May 23 2024 at 12:28)</a>:</h4>
<p>(deleted)</p>



<a name="443607575"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/443607575" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#443607575">(Jun 09 2024 at 15:34)</a>:</h4>
<p>I have some thoughts on why AMD chose a simple neural network. Recently, while deploying a Transformer model, I found that when there are too many parameters, the model's speed also noticeably decreases. Therefore, overly complex neural networks may sacrifice some efficiency.</p>



<a name="444221101"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/444221101" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#444221101">(Jun 12 2024 at 12:22)</a>:</h4>
<p>I have a question about '''rt_shootray()".  When calling <code>rt</code> with default parameters, does it call <code>rt_shootray</code> only once for each pixel to calculate the RGB value, and does it not use the Monte Carlo algorithm at all during the process?</p>



<a name="444265054"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/444265054" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#444265054">(Jun 12 2024 at 15:27)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/443607575">said</a>:</p>
<blockquote>
<p>I have some thoughts on why AMD chose a simple neural network. Recently, while deploying a Transformer model, I found that when there are too many parameters, the model's speed also noticeably decreases. Therefore, overly complex neural networks may sacrifice some efficiency.</p>
</blockquote>
<p>Yes, and I mentioned something to that effect -- it was absolutely made that simple in order to achieve their realtime performance goal.  What's still particularly amazing though is that it achieved such precise matching output on such a complex scene with so few parameters.</p>



<a name="444266014"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/444266014" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#444266014">(Jun 12 2024 at 15:31)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/444221101">said</a>:</p>
<blockquote>
<p>I have a question about '''rt_shootray()".  When calling <code>rt</code> with default parameters, does it call <code>rt_shootray</code> only once for each pixel to calculate the RGB value, and does it not use the Monte Carlo algorithm at all during the process?</p>
</blockquote>
<p>It will call rt_shootray one for each primary ray -- which typically results in secondary rays as well for reflection, specular, light/shadow samples, etc.  Rt is not a montecarlo renderer, but there are options like -H for hypersampling where there will be multiple samples per pixel.  There are also different lighting modes and different renderers that employ different methods.  For example -l7 uses photon mapping and the 'art' ray tracer is a PBR renderer based on appleseed.</p>



<a name="445278798"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445278798" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445278798">(Jun 18 2024 at 06:14)</a>:</h4>
<p>After the rendering is complete, I want to plot some sampling points. I think I should operate on this object. Is there any related function?</p>
<div class="codehilite" data-code-language="C++"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">fb</span><span class="w"> </span><span class="o">*</span><span class="n">fbp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">FB_NULL</span><span class="p">;</span><span class="w"> </span><span class="cm">/* Framebuffer handle */</span>
</code></pre></div>



<a name="445459785"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445459785" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445459785">(Jun 18 2024 at 20:56)</a>:</h4>
<p>If rendering is complete do you mean 2d plotting over the image??  Or are you wanting to plot 3D points and render them as well?</p>



<a name="445460135"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445460135" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445460135">(Jun 18 2024 at 20:58)</a>:</h4>
<p>If you’re just wanting to visualize some diagnostic info for debugging, you can make geometry (eg point cloud or spheres) and view that in mged or with rt, you can plot to 3D with annotation points, you could manually project 3D points to 2d and draw them</p>



<a name="445495215"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445495215" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445495215">(Jun 19 2024 at 02:19)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/445460135">said</a>:</p>
<blockquote>
<p>If you’re just wanting to visualize some diagnostic info for debugging, you can make geometry (eg point cloud or spheres) and view that in mged or with rt, you can plot to 3D with annotation points, you could manually project 3D points to 2d and draw them</p>
</blockquote>
<p>Sorry for not being clear. I just want to visualize these points, and I will try to plot them in a 3D view.</p>



<a name="446189703"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446189703" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Erik <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446189703">(Jun 21 2024 at 22:54)</a>:</h4>
<p>Happy Friday! did you figure out how to plot the points? Is there enough progress for a little show&amp;tell?</p>



<a name="446367597"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446367597" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446367597">(Jun 23 2024 at 04:37)</a>:</h4>
<p><span class="user-mention silent" data-user-id="103542">Erik</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/446189703">said</a>:</p>
<blockquote>
<p>Happy Friday! did you figure out how to plot the points? Is there enough progress for a little show&amp;tell?</p>
</blockquote>
<p>I'm sorry for the late reply. I completed the drawing in a strange way...</p>



<a name="446367611"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446367611" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446367611">(Jun 23 2024 at 04:37)</a>:</h4>
<p>I do have some results to report, and I would like to know if my direction is correct. Is next Wednesday or Thursday okay?</p>



<a name="446797805"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446797805" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446797805">(Jun 25 2024 at 07:22)</a>:</h4>
<p>where is the center of model bounding sphere?</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>0.5</mn><mo stretchy="false">(</mo><mi>m</mi><mi>d</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>m</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>m</mi><mi>d</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">?</mo></mrow><annotation encoding="application/x-tex">0.5(mdl\_min+mdl\_max)?</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord">0.5</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">min</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mclose">)?</span></span></span></span></span></p>
<div class="codehilite"><pre><span></span><code>struct rt_i{
...
/* THESE ITEMS ARE AVAILABLE FOR APPLICATIONS TO READ */
point_t             mdl_min;        /**&lt; @brief  min corner of model bounding RPP */
point_t             mdl_max;        /**&lt; @brief  max corner of model bounding RPP */
point_t             rti_pmin;       /**&lt; @brief  for plotting, min RPP */
point_t             rti_pmax;       /**&lt; @brief  for plotting, max RPP */
double              rti_radius;     /**&lt; @brief  radius of model bounding sphere */
struct db_i *       rti_dbip;       /**&lt; @brief  prt to Database instance struct */
</code></pre></div>



<a name="446798094"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446798094" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446798094">(Jun 25 2024 at 07:24)</a>:</h4>
<p>And please let me know when will you're available to meet. I will be free after Tuesday.</p>



<a name="446895409"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446895409" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446895409">(Jun 25 2024 at 14:09)</a>:</h4>
<p>I have finished a few sample methods , this is uniform sphere sample:<br>
<a href="/user_uploads/1549/PRn-rHvwlNCdeXaXjWHdCpfu/sample.png">sample.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/PRn-rHvwlNCdeXaXjWHdCpfu/sample.png" title="sample.png"><img src="/user_uploads/1549/PRn-rHvwlNCdeXaXjWHdCpfu/sample.png"></a></div>



<a name="447031678"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447031678" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Erik <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447031678">(Jun 26 2024 at 00:52)</a>:</h4>
<p>I can make time on Wednesday, or on Thursday until 1630EDT, or Friday after 0830EDT. But I think Sean is more aware of what's going on and it'd be more valuable to have him present? <br>
the center of the bounding sphere is the same as the bounding box, um, I think the AABB is used more than the sphere. iirc, when I did the metaball primitive, I did a bounding box, then just said the bounding sphere was the same center and had  a radius equal to the distance from  a corner of the bounding box to the center?</p>



<a name="447103961"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447103961" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447103961">(Jun 26 2024 at 04:16)</a>:</h4>
<p>Okay, I'll ask Sean when he's available.</p>
<p><span class="user-mention silent" data-user-id="103542">Erik</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/447031678">said</a>:</p>
<blockquote>
<p>I can make time on Wednesday, or on Thursday until 1630EDT, or Friday after 0830EDT. But I think Sean is more aware of what's going on and it'd be more valuable to have him present? <br>
the center of the bounding sphere is the same as the bounding box, um, I think the AABB is used more than the sphere. iirc, when I did the metaball primitive, I did a bounding box, then just said the bounding sphere was the same center and had  a radius equal to the distance from  a corner of the bounding box to the center?</p>
</blockquote>



<a name="447164652"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447164652" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447164652">(Jun 26 2024 at 09:15)</a>:</h4>
<p>There looks to be a small error in rt/worker.c:  there is no need to statistic <strong> colorsum </strong> for normal sample, just do it in hyper sample</p>
<div class="codehilite" data-code-language="C"><pre><span></span><code><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hypersample</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="p">...</span>
<span class="n">VADD2</span><span class="p">(</span><span class="n">colorsum</span><span class="p">,</span><span class="w"> </span><span class="n">colorsum</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">a_color</span><span class="p">);</span>

<span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="cm">/* hypersampling, so iterate */</span>
</code></pre></div>



<a name="447193979"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447193979" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447193979">(Jun 26 2024 at 11:37)</a>:</h4>
<p><span class="user-mention" data-user-id="102939">@Daniel Rossberg</span>  <span class="user-mention" data-user-id="252475">@Himanshu</span>  I have created a new pull request addressing the selectPrimitive feature's bug <a href="https://github.com/BRL-CAD/arbalest/pull/51">here</a></p>



<a name="447396149"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447396149" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447396149">(Jun 27 2024 at 06:26)</a>:</h4>
<p><span class="user-mention" data-user-id="103542">@Erik</span> Is June 28 11.30(EDT) OK for you?</p>



<a name="448092373"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448092373" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448092373">(Jun 30 2024 at 09:14)</a>:</h4>
<p>I finished the whole process of neural network rendering and generated a not-so-good rgb map：<br>
<a href="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png">render.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png" title="render.png"><img src="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png"></a></div>



<a name="448099591"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448099591" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448099591">(Jun 30 2024 at 10:18)</a>:</h4>
<p>why the direction of ray keep const when rendering? According to ray tracing algorithm, each ray should have a different direction: <br>
<a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png">RaysViewportSchema.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png" title="RaysViewportSchema.png"><img src="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png"></a></div>



<a name="448123324"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448123324" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448123324">(Jun 30 2024 at 14:46)</a>:</h4>
<p>Is there a function to calculate the intersection of a ray and a sphere?</p>



<a name="448222663"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448222663" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448222663">(Jul 01 2024 at 05:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448099591">said</a>:</p>
<blockquote>
<p>why the direction of ray keep const when rendering? According to ray tracing algorithm, each ray should have a different direction: <br>
<a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png">RaysViewportSchema.png</a></p>
</blockquote>
<p>I get it , the default is to use parallel projection</p>



<a name="448341781"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448341781" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448341781">(Jul 01 2024 at 14:01)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448123324">said</a>:</p>
<blockquote>
<p>Is there a function to calculate the intersection of a ray and a sphere?</p>
</blockquote>
<p>I implemented the algorithm myself</p>



<a name="448846756"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448846756" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448846756">(Jul 03 2024 at 13:15)</a>:</h4>
<p>I found an interesting parper:NeRF: Representing Scenes as  Neural Radiance Fields for View Synthesis(<a href="https://dl.acm.org/doi/abs/10.1145/3503250">https://dl.acm.org/doi/abs/10.1145/3503250</a>)</p>



<a name="448853370"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448853370" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448853370">(Jul 03 2024 at 13:41)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448846756">ha scritto</a>:</p>
<blockquote>
<p>I found an interesting parper:NeRF: Representing Scenes as  Neural Radiance Fields for View Synthesis(<a href="https://dl.acm.org/doi/abs/10.1145/3503250">https://dl.acm.org/doi/abs/10.1145/3503250</a>)</p>
</blockquote>
<p>Why do you think it is interesting?</p>



<a name="448863224"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448863224" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448863224">(Jul 03 2024 at 14:24)</a>:</h4>
<p>The Positional encoding,  according to Rahaman's work <a href="https://arxiv.org/abs/1806.08734">On the Spectral Bias of Neural Networks</a>, deep networks are biased towards learning lower frequency functions. They use positional encoding methods to solve this problem.</p>



<a name="448900107"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448900107" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448900107">(Jul 03 2024 at 16:38)</a>:</h4>
<p><a href="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg">IMG_1921.jpeg</a><br>
this is the ground truth</p>
<div class="message_inline_image"><a href="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg" title="IMG_1921.jpeg"><img src="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg"></a></div>



<a name="448900278"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448900278" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448900278">(Jul 03 2024 at 16:39)</a>:</h4>
<p><a href="/user_uploads/1549/uMhAaXGt-u3MRQyJvV2NV3H4/IMG_1922.jpeg">IMG_1922.jpeg</a><br>
And this is with neural network prediction (bounding box). There are some issues to resolve</p>
<div class="message_inline_image"><a href="/user_uploads/1549/uMhAaXGt-u3MRQyJvV2NV3H4/IMG_1922.jpeg" title="IMG_1922.jpeg"><img src="/user_uploads/1549/uMhAaXGt-u3MRQyJvV2NV3H4/IMG_1922.jpeg"></a></div>



<a name="448900529"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448900529" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448900529">(Jul 03 2024 at 16:41)</a>:</h4>
<p>Probably they are mainly with rendering and not with the NN itself</p>



<a name="448901952"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448901952" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448901952">(Jul 03 2024 at 16:49)</a>:</h4>
<p>Or maybe the number of samples in the dataset are too low.</p>



<a name="449297977"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449297977" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449297977">(Jul 05 2024 at 12:09)</a>:</h4>
<p>I solved the issue with the rendering and got improvements</p>



<a name="449297987"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449297987" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449297987">(Jul 05 2024 at 12:09)</a>:</h4>
<p><a href="/user_uploads/1549/adq2ZvACbgm9ME6bkj2zezyB/IMG_1929.jpeg">IMG_1929.jpeg</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/adq2ZvACbgm9ME6bkj2zezyB/IMG_1929.jpeg" title="IMG_1929.jpeg"><img src="/user_uploads/1549/adq2ZvACbgm9ME6bkj2zezyB/IMG_1929.jpeg"></a></div>



<a name="449298375"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449298375" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449298375">(Jul 05 2024 at 12:10)</a>:</h4>
<p>With n=100'000 rays I got 0.94% of accuracy which is not bad but the major problem is that with bounding sphere approach we need to sample a lot of rays in order to achieve a good accuracy for every angle of the camera.</p>



<a name="449298872"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449298872" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449298872">(Jul 05 2024 at 12:13)</a>:</h4>
<p>The problem isn't with the Neural Network because I have a 0.99 accuracy with Training Set, but since we have an infinite number of rays that goes in all the directions in the bounding sphere, I think it is not possible to achieve the same results with the rendering without changing something because otherwise we need to sample an infinite number of rays to give to the NN (and of course it is not possible).</p>



<a name="449299212"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449299212" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449299212">(Jul 05 2024 at 12:15)</a>:</h4>
<p>So we must be smarter than this and try to change representations of the input features or trying different architectures of NN</p>



<a name="449299318"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449299318" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449299318">(Jul 05 2024 at 12:16)</a>:</h4>
<p>But first I want to try with n=1 million samples to see how good are the performances.</p>



<a name="449299951"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449299951" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449299951">(Jul 05 2024 at 12:20)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448900107">ha scritto</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg">IMG_1921.jpeg</a><br>
this is the ground truth</p>
</blockquote>
<p>Remember that this is the ground truth.</p>



<a name="449318723"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449318723" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449318723">(Jul 05 2024 at 13:55)</a>:</h4>
<p><a href="/user_uploads/1549/r-ScLIaNys2JvMxwkVH66F9J/IMG_1930.jpeg">IMG_1930.jpeg</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/r-ScLIaNys2JvMxwkVH66F9J/IMG_1930.jpeg" title="IMG_1930.jpeg"><img src="/user_uploads/1549/r-ScLIaNys2JvMxwkVH66F9J/IMG_1930.jpeg"></a></div>



<a name="449318885"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449318885" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449318885">(Jul 05 2024 at 13:56)</a>:</h4>
<p>This is with 1 million rays, I got the best epoch with 0.986 % of accuracy. We are on the right path :)</p>



<a name="449330639"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449330639" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449330639">(Jul 05 2024 at 14:58)</a>:</h4>
<p>I use a deep resnet to learn rgb value. The left is the result of neural rendering and the right is normal rendering<br>
<a href="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png">res_net.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png" title="res_net.png"><img src="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png"></a></div>



<a name="449330816"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449330816" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449330816">(Jul 05 2024 at 14:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449330639">ha scritto</a>:</p>
<blockquote>
<p>I use a deep resnet to learn rgb value. The left is the result of neural rendering and the right is normal rendering<br>
<a href="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png">res_net.png</a></p>
</blockquote>
<p>Which sampling approach have you used?</p>



<a name="449331053"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331053" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331053">(Jul 05 2024 at 15:00)</a>:</h4>
<p>Random sample, with 1million rays which have the same direction and hit the bounding sphere</p>



<a name="449331190"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331190" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331190">(Jul 05 2024 at 15:01)</a>:</h4>
<p>I want to improve network first and then sample method</p>



<a name="449331352"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331352" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331352">(Jul 05 2024 at 15:02)</a>:</h4>
<p>Mh ok so it cannot be generalized with every angle at the moment... Predicting rgb is much more difficult, I see...</p>



<a name="449331376"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331376" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331376">(Jul 05 2024 at 15:02)</a>:</h4>
<p>The current network fits a continuous function, but the objective function is not actually continuous..</p>



<a name="449331502"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331502" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331502">(Jul 05 2024 at 15:02)</a>:</h4>
<p>We need a new structure...</p>



<a name="449333208"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449333208" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449333208">(Jul 05 2024 at 15:10)</a>:</h4>
<p>I don't know if it can improve the results, but have you tried giving to the network only the rays that hit the  object and not all the rays?<br>
This can be done because first we predict with "my" network if it has hitted or not, so "your" network should predict only the ones that hit the object</p>



<a name="449333774"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449333774" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449333774">(Jul 05 2024 at 15:13)</a>:</h4>
<p>This a direction. I will try it later</p>



<a name="449333873"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449333873" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449333873">(Jul 05 2024 at 15:13)</a>:</h4>
<p>Can you tell which object you've hit?</p>



<a name="449334154"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449334154" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449334154">(Jul 05 2024 at 15:15)</a>:</h4>
<p>This would be very helpful to me, maybe I could train two networks</p>



<a name="449335156"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449335156" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449335156">(Jul 05 2024 at 15:19)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449333873">ha scritto</a>:</p>
<blockquote>
<p>Can you tell which object you've hit?</p>
</blockquote>
<p>Regarding this, we must decide if we have to train one network for each object or not... I think  deciding all this in a meeting would be more appropriate.</p>



<a name="449335299"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449335299" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449335299">(Jul 05 2024 at 15:20)</a>:</h4>
<p>OK, let's decide this later</p>



<a name="449613007"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449613007" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449613007">(Jul 07 2024 at 06:42)</a>:</h4>
<p>I got a great result with gridnet:<br>
<a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png">grid_methos</a><br>
here is the loss:<br>
<a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png">loss</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png" title="grid_methos"><img src="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png" title="loss"><img src="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png"></a></div>



<a name="449614206"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449614206" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449614206">(Jul 07 2024 at 06:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449613007">ha scritto</a>:</p>
<blockquote>
<p>I got a great result with gridnet:<br>
<a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png">grid_methos</a><br>
here is the loss:<br>
<a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png">loss</a></p>
</blockquote>
<p>Very good. This is grid + resnet?</p>



<a name="449615980"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449615980" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449615980">(Jul 07 2024 at 07:24)</a>:</h4>
<p>Just grid net. I will add resnet later.</p>



<a name="449616299"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449616299" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449616299">(Jul 07 2024 at 07:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449615980">ha scritto</a>:</p>
<blockquote>
<p>Just grid net. I will add resnet later.</p>
</blockquote>
<p>What is the mean absolute error?I think it would be easier to understand how good is this model.</p>



<a name="449616407"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449616407" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449616407">(Jul 07 2024 at 07:30)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449613007">ha scritto</a>:</p>
<blockquote>
<p>I got a great result with gridnet:<br>
<a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png">grid_methos</a><br>
here is the loss:<br>
<a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png">loss</a></p>
</blockquote>
<p>And why do you think  there are those white dots (noise) ?</p>



<a name="449616444"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449616444" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449616444">(Jul 07 2024 at 07:31)</a>:</h4>
<p>Anyway, seeing your results, I think I will also add this grid method, I think it would improve my network too.</p>



<a name="449825650"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449825650" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449825650">(Jul 08 2024 at 10:03)</a>:</h4>
<p>I tried with grid encoding but my network does not seem to improve any further. I will try different sampling approach.</p>



<a name="449828956"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449828956" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449828956">(Jul 08 2024 at 10:21)</a>:</h4>
<p>I think that grid encoding is appropriate only when the direction of the rays is fixed, because if you divide your sphere in 256*256 = 65536 cells, then each cell will have an average number of 15 rays to be trained (if your training set has 1 million rays). The problem is that if your direction is fixed, then 15 rays for each cell can be acceptable but if the direction isn't fixed, then 15 is a very small number of rays to train.<br>
I tried also with a different size of grid (20x20, 50x50, 100x100) and the NN performs like before more or less (98% accuracy with 20x20).<br>
I also implemented different grid versions  in the same NN (20x20, 50x50, 100x100, 256x256) and combined them together with some weights, but I got the same results...<br>
So this makes me think that grid encoding isn't appropriate when rays are not fixed.</p>



<a name="449937826"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449937826" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449937826">(Jul 08 2024 at 17:38)</a>:</h4>
<p>Today I improved results to 0.991 (test set) using a different optimizer.</p>



<a name="449953919"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449953919" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449953919">(Jul 08 2024 at 18:49)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448099591">said</a>:</p>
<blockquote>
<p>why the direction of ray keep const when rendering? According to ray tracing algorithm, each ray should have a different direction: <br>
<a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png">RaysViewportSchema.png</a></p>
</blockquote>
<p>There are two different kinds of cameras -- perspective and orthogonal.  Orthogonal is default for most engineering purposes and perspective is what you want for visualizations approximating human vision.  Perspective rays (typically) diverge.  Ortho are parallel grids. </p>
<p>For volumetric encoding, you almost certainly will want ortho or unbiased random.</p>



<a name="449954153"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449954153" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449954153">(Jul 08 2024 at 18:50)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448092373">said</a>:</p>
<blockquote>
<p>I finished the whole process of neural network rendering and generated a not-so-good rgb map：<br>
<a href="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png">render.png</a></p>
</blockquote>
<p>That's actually not "terrible".  Not great but not terrible to say the least.  It's clearly recognizable.</p>



<a name="450216289"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450216289" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450216289">(Jul 09 2024 at 16:18)</a>:</h4>
<p>I also use a 4-Dimensions network to train, the inputs are both direction and position:<br>
<a href="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png">net.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png" title="net.png"><img src="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png"></a></div>



<a name="450457252"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450457252" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450457252">(Jul 10 2024 at 13:46)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450216289">said</a>:</p>
<blockquote>
<p>I also use a 4-Dimensions network to train, the inputs are both direction and position:<br>
<a href="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png">net.png</a></p>
</blockquote>
<p>That's clearly "seeing" the model in some sense, even getting some of the surfacing right but in a dream state.  How many training epochs is that?</p>
<p>One thing you could try is to reduce the input dimensionality to just azimuth and elevation (2 floats).  That's a much smaller space to optimize across and will result in the same centered visual for our current purposes.</p>



<a name="450458097"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450458097" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450458097">(Jul 10 2024 at 13:50)</a>:</h4>
<p>Oh, I have convert both direction and position to azimuth and elevation, so there are just four float inputs. It takes me one hour to train(with a 4060 GPU)</p>



<a name="450458373"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450458373" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450458373">(Jul 10 2024 at 13:52)</a>:</h4>
<p>I use a grid which has a shape of 128<em>128</em>64*64 to train.  That's the maximum number of ginsengs my GPU can handle.</p>



<a name="450458592"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450458592" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450458592">(Jul 10 2024 at 13:53)</a>:</h4>
<p>I noticed this paper: <a href="https://arxiv.org/pdf/2003.08934">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a>, they used a A100 to train and it costs more than two days.</p>



<a name="450459161"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450459161" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450459161">(Jul 10 2024 at 13:55)</a>:</h4>
<p>I'm trying to improve my net from the sampling methodology. Since I know more about active learning, I might train another network for sampling</p>



<a name="450469913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450469913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450469913">(Jul 10 2024 at 14:33)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450458592">ha scritto</a>:</p>
<blockquote>
<p>I noticed this paper: <a href="https://arxiv.org/pdf/2003.08934">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a>, they used a A100 to train and it costs more than two days.</p>
</blockquote>
<p>Yeah, this paper and its related works are the state of the art about neural rendering.</p>



<a name="450806288"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450806288" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450806288">(Jul 11 2024 at 20:31)</a>:</h4>
<p>Close to state of the art -- I listened to that paper when it came out back in 2020.  There's been a lot of work on NeRFs since then and a lot of advancements.  That's still a rather different approach altogether that thus far hasn't generalized very well.  That's why the newer AMD research is more the basis for this work.</p>



<a name="450810201"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450810201" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450810201">(Jul 11 2024 at 20:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450806288">ha scritto</a>:</p>
<blockquote>
<p>Close to state of the art -- I listened to that paper when it came out back in 2020.  There's been a lot of work on NeRFs since then and a lot of advancements.  That's still a rather different approach altogether that thus far hasn't generalized very well.  That's why the newer AMD research is more the basis for this work.</p>
</blockquote>
<p>Do you know why was there a need to try a different approach rather than NeRFs?</p>



<a name="450812109"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450812109" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450812109">(Jul 11 2024 at 21:13)</a>:</h4>
<p>Well fundamentally, nerfs are based on trying to obtain output visualizations of a 3D object based on just having some 2D view points (pictures).  They only use the 3D in the test and evaluation phase, but the model is generally unknown or non-existent.</p>



<a name="450812416"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450812416" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450812416">(Jul 11 2024 at 21:15)</a>:</h4>
<p>We have the 3D models.  They aren't the unknown in our case.  Our situation is really needing to know precisely where the 3D object is for given (unknown) view points.  That's where the optimization and needs are a bit different.  It's more about encoding and/or estimating a given model from the known model, but sufficiently abstracted that we can get accurate queries really fast.</p>



<a name="450812801"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450812801" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450812801">(Jul 11 2024 at 21:17)</a>:</h4>
<p>We could certainly build up and train a NeRF by feeding it a set of renderings for the 3D model, to see if it can generalize it well enough, but every approach I've seen thus far is about achieving optically adequate results, not necessarily something that would pass any fidelity comparison with the ground truth 3D model.</p>



<a name="450815937"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450815937" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450815937">(Jul 11 2024 at 21:32)</a>:</h4>
<p>Ok, understood. However, I believe that AMD research still lacks comprehensive volumetric information about 3D models, preventing the NN from predicting rays hit/miss with 100% precision if we wanna achieve full generalization. Perhaps we can draw inspiration from NeRF and its related works. I plan to update my work on GitHub tomorrow so that you can review and test what I have done so far.</p>



<a name="451038141"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451038141" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451038141">(Jul 12 2024 at 17:46)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Here there is the repo <a href="https://github.com/bralani/rt_volume/tree/neural_rendering">https://github.com/bralani/rt_volume/tree/neural_rendering</a>. Please be sure you follow in order these steps:</p>
<p>Installation:</p>
<p>1) Download libtorch from here <a href="https://pytorch.org/">https://pytorch.org/</a> paying attention to build "preview nightly" and remember the version you have installed (debug or release):<br>
<a href="/user_uploads/1549/cs8UI0afE68eGit_YprQNA4b/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/cs8UI0afE68eGit_YprQNA4b/image.png" title="image.png"><img src="/user_uploads/1549/cs8UI0afE68eGit_YprQNA4b/image.png"></a></div><p>2) Unzip the folder and put the libtorch folder wherever you want and then go to src\rt\CMakeLists.txt, line 56 and change these three paths with your libtorch path:<br>
<a href="/user_uploads/1549/lSIfYYz08dyAGMJJlHun7s5K/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/lSIfYYz08dyAGMJJlHun7s5K/image.png" title="image.png"><img src="/user_uploads/1549/lSIfYYz08dyAGMJJlHun7s5K/image.png"></a></div><p>3) Now be sure to build "rt_trainneural" with "Debug" version if you have installed libtorch "Debug" or with "Release" if you have installed "Release" libtorch.</p>
<p>4) This step is not always required but in my case it was essential otherwise there were some issues in the execution: go to path_libtorch\lib, copy all the files inside this folder and paste these files in the build/bin (where there is the .exe) of brl-cad.</p>
<p>Ok now we can finally run the code with two steps:</p>
<p>Go to rt/train_neural.cpp and see these options:<br>
<a href="/user_uploads/1549/Q5q8p-QQUbsZbaIqgTFJUmO_/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/Q5q8p-QQUbsZbaIqgTFJUmO_/image.png" title="image.png"><img src="/user_uploads/1549/Q5q8p-QQUbsZbaIqgTFJUmO_/image.png"></a></div><p>TRAINING:<br>
1)  In the first step we generate the dataset with bounding sphere sampling (so make sure that opts.generate_dataset is true), set your db and obj as you want and set also the num of rays you want to generate (I suggest 1 million). Run the code.<br>
2) You should see a file "train_neural.json" and "test_neural.txt" inside the path you have run the file (build/bin). <br>
3) Go to rt/train.py and set on top your variables:<br>
<a href="/user_uploads/1549/CIY8U07xrP71pBjgOZJvlry5/image.png">image.png</a><br>
4) Run the script, the NN will stop on epoch 200 but on each epoch it validate on test set and if the accuracy of current epoch is higher than all the previous, it overwrites the model "<a href="http://model_sph.pt">model_sph.pt</a>".</p>
<div class="message_inline_image"><a href="/user_uploads/1549/CIY8U07xrP71pBjgOZJvlry5/image.png" title="image.png"><img src="/user_uploads/1549/CIY8U07xrP71pBjgOZJvlry5/image.png"></a></div><p>RENDERING:<br>
1) Go back to rt/train_neural.cpp, set opts.generate_dataset = false, set properly opts.model_path with the path of the model trained, adjust the azimuth and elevation as you wish (to perform render) and then set opts.neural_render=0 if you want the ground truth rendering, otherwise set to 1 if you want to perform your neural rendering. :)</p>



<a name="451039002"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039002" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039002">(Jul 12 2024 at 17:52)</a>:</h4>
<p>I guarantee that it works in Windows, I have not tried with any other OS.</p>



<a name="451039115"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039115" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039115">(Jul 12 2024 at 17:53)</a>:</h4>
<p>I have also a Mac M1 but I have always a lot of errors when I try to build BRL-CAD...</p>



<a name="451039490"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039490" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039490">(Jul 12 2024 at 17:56)</a>:</h4>
<p>Awesome, thank you <span class="user-mention" data-user-id="702819">@Matteo Balice</span> I'll definitely be taking a deeper look at it later today, and see if I can get it up and running.  I'm on M2, so will see if there are issues.</p>



<a name="451039550"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039550" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039550">(Jul 12 2024 at 17:56)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> on Mac, you must enable -DBRLCAD_BUNDLED_LIBS=ON or the build will fail when it tries to use the system Tcl/Tk</p>



<a name="451039559"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039559" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039559">(Jul 12 2024 at 17:56)</a>:</h4>
<p>(during cmake)</p>



<a name="451039634"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039634" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039634">(Jul 12 2024 at 17:57)</a>:</h4>
<p>I already have pytorch installed and a brl-cad build, so should hopefully all just work!</p>



<a name="451039931"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039931" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039931">(Jul 12 2024 at 17:59)</a>:</h4>
<p>Ahh ok I will try it now so you don't have any issues tomorrow on your M2. <br>
I have also prepared a small script here that tries to find CUDA if you have a GPU or metal acceleration if you have any "M" series of Mac:<br>
<a href="/user_uploads/1549/RRPOkm_KlCg0rn9SRVTjdThx/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/RRPOkm_KlCg0rn9SRVTjdThx/image.png" title="image.png"><img src="/user_uploads/1549/RRPOkm_KlCg0rn9SRVTjdThx/image.png"></a></div>



<a name="451069638"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451069638" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451069638">(Jul 12 2024 at 20:35)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450815937">said</a>:</p>
<blockquote>
<p>Ok, understood. However, I believe that AMD research still lacks comprehensive volumetric information about 3D models, preventing the NN from predicting rays hit/miss with 100% precision if we wanna achieve full generalization. Perhaps we can draw inspiration from NeRF and its related works. I plan to update my work on GitHub tomorrow so that you can review and test what I have done so far.</p>
</blockquote>
<p>I'd like to hear more what you meant by this -- encoding comprehensive volumetric information isn't the goal, but some faithful encoding.  A prediction with some general precision assertion (hopefully).  Similar in the text space, we want a reasonably accurate response to an input prompt that is more than vague (blurry) writing. </p>
<p>Issue I have with radiance fields is the method isn't exactly aligned well with our available training data.  We'd literally throw away information to then try to reconstitute it.  The method is really a whole field that's trying to construct 3D where it did not exist previously (i.e., from photos or scans).</p>



<a name="451070030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070030">(Jul 12 2024 at 20:37)</a>:</h4>
<p>From my reading, the AMD research is compelling because it is just a bifurcated training of two networks, one for outside, one for inside/near, and lots of reductions made for the sake of adequate performance.  My thinking is lets increase the network a bit, and see how well it can generalize.</p>



<a name="451070363"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070363" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070363">(Jul 12 2024 at 20:39)</a>:</h4>
<p>On a related note, here's a nice site that summarizes a lot of the neural field papers -- definitely are concepts that are relevant in some of them:  <a href="https://radiancefields.com/siggraph-2024-program-announced">https://radiancefields.com/siggraph-2024-program-announced</a></p>



<a name="451070607"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070607" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070607">(Jul 12 2024 at 20:40)</a>:</h4>
<p>I have already made just a little bit more complex the NN of AMD research and it generalizes very well.</p>



<a name="451070693"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070693" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070693">(Jul 12 2024 at 20:40)</a>:</h4>
<p>This means that for each angle of the object, the NN is able to understand the shape.</p>



<a name="451070780"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070780" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070780">(Jul 12 2024 at 20:41)</a>:</h4>
<p>But the problem is that on the boundaries of the objects, there are still some artifacts (for example the shape is smooth even though it should be sharp from the ground truth). It is not very precise there.</p>



<a name="451070930"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070930" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070930">(Jul 12 2024 at 20:42)</a>:</h4>
<p>My idea was to substitute the grid encoding approach they used.</p>



<a name="451071002"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451071002" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451071002">(Jul 12 2024 at 20:42)</a>:</h4>
<p>Because for me, the grid encoding was working only because they trained the NN with fixed directions of the rays. But in our case, the rays can have infinite directions from the same origin.</p>



<a name="451071510"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451071510" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451071510">(Jul 12 2024 at 20:45)</a>:</h4>
<p>If you think about the grid encoding, every ray that hit a specific cell have a very similar origin since the direction is fixed.</p>



<a name="451071594"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451071594" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451071594">(Jul 12 2024 at 20:45)</a>:</h4>
<p>But in our case this is not true.</p>



<a name="451072518"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451072518" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451072518">(Jul 12 2024 at 20:49)</a>:</h4>
<p>I know that encoding volumetric informations are not the final goal, but I believe that the NN is not able to capture very well this details due to the lack of volumetric informations of the model itself. We could use for example an encoding like "voxels" because they are invariant to directions. This is just an idea for the moment, I don't know if it can work.</p>



<a name="451073664"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451073664" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451073664">(Jul 12 2024 at 20:54)</a>:</h4>
<p>I will read some papers in these days about this.</p>



<a name="451121429"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451121429" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451121429">(Jul 13 2024 at 03:57)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span>  That is sort of incorporating some of the concepts of a radiance field (what you're calling a grid encoding), also known as a volumetric encoding.  Your intuition about the direction vectors being fixed does certainly sound plausible.  While the image space was fixed, the rays themselves were scattering in nearly all directions due to the physically based lighting model they were using (lots of reflection rays, refraction rays, light sampling rays, diffuse surface rays, and more).  Still, that is certainly a vast subset for the net to train on, and like I said, you have a reasoned impetus for trying to encode it volumetrically.</p>



<a name="451121613"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451121613" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451121613">(Jul 13 2024 at 03:58)</a>:</h4>
<p>You'd definitely need something more descriptive than voxels unless we go pixar route to sub-pixel resolution, which is not practical (for lots of reasons).</p>



<a name="451121738"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451121738" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451121738">(Jul 13 2024 at 04:00)</a>:</h4>
<p>You'd probably need something more like a vdb signed distance field (sdf) where you have voxel occupancy as well as surface direction vectors.</p>



<a name="451321049"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451321049" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451321049">(Jul 14 2024 at 05:39)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> AMD research doesn't use rays with fixed directions. They encoded both diection and position, then concatenated  them to a vector:<br>
<a href="/user_uploads/1549/WCjqqOJr3v2hz1Y9QF_NlFfM/AMD.png">AMD.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/WCjqqOJr3v2hz1Y9QF_NlFfM/AMD.png" title="AMD.png"><img src="/user_uploads/1549/WCjqqOJr3v2hz1Y9QF_NlFfM/AMD.png"></a></div>



<a name="451321515"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451321515" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451321515">(Jul 14 2024 at 05:48)</a>:</h4>
<p>I think a different strategy could be used for grid coding. Replacing a 2-dimensional network with a 4-dimensional network, this grid coding encodes both positional and directional information in a single vector</p>



<a name="451328162"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328162" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328162">(Jul 14 2024 at 07:02)</a>:</h4>
<p>Maybe I was not so clear. Yes, they encoded both direction and position BUT they trained with a fixed viewpoint:<br>
<a href="/user_uploads/1549/bLA96oXiOSQtHnGE1XcpOlqy/Screenshot-2024-07-14-alle-09.00.20.png">Screenshot-2024-07-14-alle-09.00.20.png</a><br>
This means that all the rays have more or less the same directions each training.<br>
<a href="/user_uploads/1549/-ze6tTd7GIv9w8LNXKteSUXt/Screenshot-2024-07-14-alle-09.01.26.png">Screenshot-2024-07-14-alle-09.01.26.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/bLA96oXiOSQtHnGE1XcpOlqy/Screenshot-2024-07-14-alle-09.00.20.png" title="Screenshot-2024-07-14-alle-09.00.20.png"><img src="/user_uploads/1549/bLA96oXiOSQtHnGE1XcpOlqy/Screenshot-2024-07-14-alle-09.00.20.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/-ze6tTd7GIv9w8LNXKteSUXt/Screenshot-2024-07-14-alle-09.01.26.png" title="Screenshot-2024-07-14-alle-09.01.26.png"><img src="/user_uploads/1549/-ze6tTd7GIv9w8LNXKteSUXt/Screenshot-2024-07-14-alle-09.01.26.png"></a></div><p>This is very different from our goal and I explained why it can not work in our case (from my hypothesis).</p>



<a name="451328614"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328614" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328614">(Jul 14 2024 at 07:06)</a>:</h4>
<p>I got it. Thanks</p>



<a name="451328625"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328625" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328625">(Jul 14 2024 at 07:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451321515">ha scritto</a>:</p>
<blockquote>
<p>I think a different strategy could be used for grid coding. Replacing a 2-dimensional network with a 4-dimensional network, this grid coding encodes both positional and directional information in a single vector</p>
</blockquote>
<p>Can you elaborate more about this?</p>



<a name="451328750"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328750" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328750">(Jul 14 2024 at 07:09)</a>:</h4>
<p>I put my codes here:<a href="https://github.com/Rainy-fall-end/Rendernn/blob/main/trainDir.py">trainDir</a>. I use a 128×128×64×64 net to encodes both dir and pos.</p>



<a name="451329160"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329160" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329160">(Jul 14 2024 at 07:15)</a>:</h4>
<p>Mh I cannot quite understand this. Are you using a total of 128x128x64x64=67billions cells?</p>



<a name="451329221"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329221" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329221">(Jul 14 2024 at 07:16)</a>:</h4>
<p>This is quite overfitting because you will get train error 0 since you have less rays than cells.</p>



<a name="451329248"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329248" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329248">(Jul 14 2024 at 07:17)</a>:</h4>
<p>Or am I wrong?</p>



<a name="451329254"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329254" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329254">(Jul 14 2024 at 07:17)</a>:</h4>
<p>Yes... I am trying to improve it.</p>



<a name="451329264"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329264" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329264">(Jul 14 2024 at 07:17)</a>:</h4>
<p>Maybe it can work only if the viewpoint is fixed.</p>



<a name="451329267"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329267" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329267">(Jul 14 2024 at 07:17)</a>:</h4>
<p>There are too many parameters</p>



<a name="451365877"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451365877" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451365877">(Jul 14 2024 at 16:17)</a>:</h4>
<p>I've been doing a lot of experimenting with grid net lately, and it's hard for him to predict rays in all directions, which may require a lot of parameters. One of the big problems is that the objective function is non-differentiable</p>



<a name="451366101"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451366101" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451366101">(Jul 14 2024 at 16:20)</a>:</h4>
<p>Instead of using nif directly for rendering, AMD just uses NIF to intersect to speed up the rendering process. The focus is really on intersection, which is effective for rendering complex geometry.</p>



<a name="451366395"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451366395" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451366395">(Jul 14 2024 at 16:25)</a>:</h4>
<p>Nerf is actually rendered differently than we are, they are using volume rendering while we are doing ray tracing.</p>



<a name="451366539"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451366539" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451366539">(Jul 14 2024 at 16:27)</a>:</h4>
<p>I'd like to try to modify the objective function later in order to make ray-tracing a differentiable process, and if all the data for the model is known, can I then return exactly which point was hit, and the distance between the hit point and the origin?</p>



<a name="451370675"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451370675" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451370675">(Jul 14 2024 at 17:45)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> I confirm that on my Mac m1 it works well now.</p>



<a name="451371911"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451371911" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451371911">(Jul 14 2024 at 18:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451328162">said</a>:</p>
<blockquote>
<p>Maybe I was not so clear. Yes, they encoded both direction and position BUT they trained with a fixed viewpoint:</p>
</blockquote>
<p>I certainly got what you meant, and there's certainly truth in both statements.  The fact that the training is happening across two networks and with rays very much scattered in all directions does to me indicate that it likely can generalize (with more parameters).  They did not pick a simple scene to say the least, and their sampling was not at a low resolution.  The fixed viewpoint is what let them achieve their target performance, but I don't think that their approach was really indicative of an overtrained solution.  On the contrary, they showed how well it performed on other viewpoints in their talk (they just don't go into that detail on their paper -- that's another paper).</p>



<a name="451373109"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451373109" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451373109">(Jul 14 2024 at 18:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451371911">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451328162">said</a>:</p>
<blockquote>
<p>Maybe I was not so clear. Yes, they encoded both direction and position BUT they trained with a fixed viewpoint:</p>
</blockquote>
<p>I certainly got what you meant, and there's certainly truth in both statements.  The fact that the training is happening across two networks and with rays very much scattered in all directions does to me indicate that it likely can generalize (with more parameters).  They did not pick a simple scene to say the least, and their sampling was not at a low resolution.  The fixed viewpoint is what let them achieve their target performance, but I don't think that their approach was really indicative of an overtrained solution.  On the contrary, they showed how well it performed on other viewpoints in their talk (they just don't go into that detail on their paper -- that's another paper).</p>
</blockquote>
<p>Yes I agree with you, their approach is certainly able to generalize and I have proved it but we need to add a more complex encoding like we were saying yesterday to reach the maximum accuracy. I will study more about the papers you gave us and expecially with sdf.</p>



<a name="451535418"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451535418" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451535418">(Jul 15 2024 at 16:06)</a>:</h4>
<p>Before implementing a more complex encoding (like sdf), today I tried first with positional encoding of Nerf's work. The idea is that MPL neural networks perform poorly at representing high-frequency variation in geometry. Mapping the inputs to a higher dimensional space using high frequency functions before passing them to the network enables better fitting of data that contains high frequency variation.</p>
<p>I got an improvement of 0.02% of accuracy, from 99.1% to 99.3%. These are two renders of the same objects but with different angles (and of course it's the same model without retraining):</p>
<p><a href="/user_uploads/1549/n4oPMMw47I5E7k1mIpFE2-jC/output0_ground.png">output0_ground.png</a><br>
<a href="/user_uploads/1549/gf3Nw7Z7hRyMrQx8ggDI00ij/output0_pred.png">output0_pred.png</a><br>
<a href="/user_uploads/1549/S4qjgfMFSgiAlG5g2-hbHaPd/output1_ground.png">output1_ground.png</a><br>
<a href="/user_uploads/1549/Y7UzmOCsDRd57to14CjsC1Lv/output1_pred.png">output1_pred.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/n4oPMMw47I5E7k1mIpFE2-jC/output0_ground.png" title="output0_ground.png"><img src="/user_uploads/1549/n4oPMMw47I5E7k1mIpFE2-jC/output0_ground.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/gf3Nw7Z7hRyMrQx8ggDI00ij/output0_pred.png" title="output0_pred.png"><img src="/user_uploads/1549/gf3Nw7Z7hRyMrQx8ggDI00ij/output0_pred.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/S4qjgfMFSgiAlG5g2-hbHaPd/output1_ground.png" title="output1_ground.png"><img src="/user_uploads/1549/S4qjgfMFSgiAlG5g2-hbHaPd/output1_ground.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/Y7UzmOCsDRd57to14CjsC1Lv/output1_pred.png" title="output1_pred.png"><img src="/user_uploads/1549/Y7UzmOCsDRd57to14CjsC1Lv/output1_pred.png"></a></div>



<a name="451537139"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451537139" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451537139">(Jul 15 2024 at 16:15)</a>:</h4>
<p>Left is ground truth, right is prediction.</p>



<a name="451537557"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451537557" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451537557">(Jul 15 2024 at 16:17)</a>:</h4>
<p>Major issues concern the boundaries, which are not as sharp as they should be but rather tend to be smooth.</p>



<a name="451538558"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451538558" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451538558">(Jul 15 2024 at 16:22)</a>:</h4>
<p>I believe both of these issues can be resolved by using a different and more complex encoding approach, as we discussed. <span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="700180">@fall Rainy</span></p>



<a name="451638003"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451638003" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451638003">(Jul 15 2024 at 21:59)</a>:</h4>
<p>Another idea I was thinking to help the NN is to modify a bit the sampling method. Now I use a totally randomic sampling around the bounding sphere but we can use a smarter approach using an importance sampling to sample more the regions where we are more uncertain.<br>
There are 4 steps: <br>
-first we sample randomly using the same approach as now.<br>
-Second, we can divide in N cells (like a grid) the rays basing on their origin and directions so that very similar rays will be found in the same cell.<br>
-Third, we calculate for each cell the uncertainty (very easy to calculate).<br>
-Lastly, We resemple but this time using the uncertainty in order to gather more samples in regions where we are more uncertain.</p>
<p>Do you think it could work?</p>



<a name="451642643"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451642643" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451642643">(Jul 15 2024 at 22:36)</a>:</h4>
<p>Think those percentages might be a little misleading?   Is it taking all the black background into account also?  If we count up expected hits vs predicted hits, that output0 in particular looks considerably more than 1% deviated.</p>



<a name="451643256"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451643256" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451643256">(Jul 15 2024 at 22:41)</a>:</h4>
<p>Importance sampling would be good, but that's typically done as an optimization -- Would need to see a graph over epochs to see if this actually could converge onto the solution (even if over-trained).  Can you make a graph?</p>
<p>That said, I think it might help with some of the perimeter and higher frequency detail, but it's really easy to get the sampling ever so subtle wrong and introduce bias or error.  Kind of what to see proven that we can get a robust fit, that a given network topology is capable of precise match before going down that route.</p>



<a name="451670446"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451670446" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451670446">(Jul 16 2024 at 02:57)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Can we treat the image as a whole, rather than a single pixel, so that we can use the filtering algorithm to do some post-processing?</p>



<a name="451690863"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451690863" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451690863">(Jul 16 2024 at 06:45)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451642643">ha scritto</a>:</p>
<blockquote>
<p>Think those percentages might be a little misleading?   Is it taking all the black background into account also?  If we count up expected hits vs predicted hits, that output0 in particular looks considerably more than 1% deviated.</p>
</blockquote>
<p>Yes you are right. The dataset is unbalanced (more black than white) and this is the reason why accuracy is not the best in this case (I print also precision recall and better F1). But I remember that previous students used accuracy as the main metric and I wouldn’t change it. If you are interested in F1, it is 0.988 (a bit lower)</p>



<a name="451690999"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451690999" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451690999">(Jul 16 2024 at 06:45)</a>:</h4>
<p>Sure, I can plot a graph over epochs.</p>



<a name="451736447"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451736447" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451736447">(Jul 16 2024 at 11:14)</a>:</h4>
<p>I want to discuss just a moment about metrics. Do you think precision, recall or F1 is the most important one in our case?</p>
<p>Just to remember (I know you are familiar with all of these):</p>
<ul>
<li>precision is the percentage of true and predicted hitted rays among those predicted and hitted.</li>
<li>recall is the pecentage of true predicted hitted rays among all true hitted rays.</li>
<li>F1 is an armonic mean between precision and recall.</li>
</ul>
<p>I think both precision and recall are important in our case, so I believe that F1 is the most significant one.</p>



<a name="451736529"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451736529" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451736529">(Jul 16 2024 at 11:15)</a>:</h4>
<p>Or maybe do you think some others metrics I have not mentioned are more relevant in our case?</p>



<a name="451739810"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451739810" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451739810">(Jul 16 2024 at 11:38)</a>:</h4>
<p>This is the plot of the model of yesterday (so without importance sampling):<br>
<a href="/user_uploads/1549/nheHYp8UKzkQYAfXESxespLx/download.png">download.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/nheHYp8UKzkQYAfXESxespLx/download.png" title="download.png"><img src="/user_uploads/1549/nheHYp8UKzkQYAfXESxespLx/download.png"></a></div><p>As we can notice, as we increase the number of epochs we get an average F1 between 0.98 and 0.99, so we can say that our model has an average error of 1.5%.</p>



<a name="451739890"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451739890" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451739890">(Jul 16 2024 at 11:39)</a>:</h4>
<p>Today I will implement importance sampling to see if we get improvements.</p>



<a name="451802049"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451802049" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451802049">(Jul 16 2024 at 16:22)</a>:</h4>
<p>And this is the behaviour with importance sampling (a moderate importance sampling):<br>
<a href="/user_uploads/1549/ze_CILI4SHrGNIUCnCEs8NZy/download.png">download.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/ze_CILI4SHrGNIUCnCEs8NZy/download.png" title="download.png"><img src="/user_uploads/1549/ze_CILI4SHrGNIUCnCEs8NZy/download.png"></a></div>



<a name="451802730"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451802730" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451802730">(Jul 16 2024 at 16:24)</a>:</h4>
<p>I tried also with a more aggressive importance sampling and I got an improvement of F1: 0.991, accuracy: 0.994. So overall:<br>
importance sampling helps the model to understand better the regions more uncertain but it is not sufficient alone to achieve best results.</p>



<a name="451803116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451803116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451803116">(Jul 16 2024 at 16:25)</a>:</h4>
<p>So it means that we need a more complex encoding or a more complex NN. For the moment I will focus on exploring encoding based on sdf.</p>



<a name="452234079"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452234079" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452234079">(Jul 18 2024 at 03:00)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451670446">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> Can we treat the image as a whole, rather than a single pixel, so that we can use the filtering algorithm to do some post-processing?</p>
</blockquote>
<p>To what end, what exactly do you mean?  If the end result is pixel approximation, then it will be potentially useful for visualization purposes (only).  That has use, but it's definitely a different target.  The distinguishing feature that makes this challenge is replacing rt_shootray() with a neural net or the slightly higher level do_pixel().  Going full image robustly might allow for a (real-time) preview.</p>



<a name="452239169"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452239169" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452239169">(Jul 18 2024 at 03:52)</a>:</h4>
<p>The image rendered with neural network will have noise, if I can use the denoising algorithm after generating the image, the effect will be good, the left side of the image rendered by neural network, the right side is the image <br>
<a href="/user_uploads/1549/_v4_a7u2gkk4EpDk5B3Se1GG/denose.png">denose.png</a><br>
after denoising</p>
<div class="message_inline_image"><a href="/user_uploads/1549/_v4_a7u2gkk4EpDk5B3Se1GG/denose.png" title="denose.png"><img src="/user_uploads/1549/_v4_a7u2gkk4EpDk5B3Se1GG/denose.png"></a></div>



<a name="452335910"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452335910" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452335910">(Jul 18 2024 at 12:50)</a>:</h4>
<p>Ok after studying some papers about sdf/nerf/gaussian splatting I have understood that one key information I do not actually use in the NN is the direction itself of the ray. Currently as input of the NN I use the spherical coordinates of the first and second intersection but not the direction vector.<br>
Before introducing any further and more complex encoding I need to add this new information as input of the NN because all these methods rely on the direction.<br>
I was thinking that we can use a smart idea to help the NN: we are not interested in the orientation of the vector direction but only on its direction. <br>
<a href="/user_uploads/1549/6TleqJhFROZ4p1NxNmqNi1yE/Direction-bounding-sphere.jpeg.png">Direction-bounding-sphere.jpeg.png</a><br>
Imagine a vector in 2D, the maximum range we can have is from 0 to 180 (red region) since we are interested only on its direction. So, if the vector is in the green area, all we need to do is reflecting its angle to the positive half space. <br>
The same idea can be applied to 3D vectors in spherical coordinates (with a fixed radius).<br>
I think that using these new input features will be beneficial for two reasons:<br>
1) we could use some more complex encoding based on sdf/gaussian that they all rely on the concept of direction.<br>
2) using these input features, we will have as the new input of our NN the first intersection on the bounding sphere and this new vector direction. The advantage is that the range of theta and phi (of the new vector direction) is smaller than the previous input features that used the full ranges in spherical coordinates of the second intersection on the bounding sphere. This should help the NN because it will have less input space to analyse but without loss of informations.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/6TleqJhFROZ4p1NxNmqNi1yE/Direction-bounding-sphere.jpeg.png" title="Direction-bounding-sphere.jpeg.png"><img src="/user_uploads/1549/6TleqJhFROZ4p1NxNmqNi1yE/Direction-bounding-sphere.jpeg.png"></a></div><p>PS: we could even try grid encoding associated to direction and see how it works.</p>



<a name="452380256"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452380256" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452380256">(Jul 18 2024 at 15:54)</a>:</h4>
<p>Is there any way to know exactly which object the light hit?</p>



<a name="452584525"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452584525" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452584525">(Jul 19 2024 at 14:32)</a>:</h4>
<p>Ok I have added also the direction of the ray in the input features. As I was expecting, the NN does not improve adding the direction itself because we are not adding more informations but we are only using different features (I have also tried grid encoding).<br>
But the advantage is that now we can implement a more complex encoding that rely on the concept of direction.</p>



<a name="452590469"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452590469" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452590469">(Jul 19 2024 at 14:58)</a>:</h4>
<p>I have 2 ideas about encodings to try:</p>
<ul>
<li>
<p>first idea (and the best one in my opinion) is similar to the work of <a href="https://arxiv.org/abs/2011.13495">DeepSDF</a>. The idea is to train latent vectors to predict the sdf for each ray.  Then this latent vectors will be the input of our NIF architecture. The problem is that we need to compute the sdf for each ray in the sampling approach. I don't know if there is a fast way to do it. <span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="103542">@Erik</span> <br>
Note that the sdf will be used only to train the latent vectors, so the NIF architecture won't use the sdf but only the latent vectors.</p>
</li>
<li>
<p>second one (more difficult than the first) is a similar work of  <a href="https://arxiv.org/abs/2011.13495">Neural pull</a>. In this case we do not have ground truth sdf, so the idea is to train latent vectors to "pull" rays towards the nearest surface by using the predicted signed distance values and their gradients, which the network computes. The movement of each rays is determined by the predicted distance and can be either towards or away from the surface, depending on the sign of the distance. </p>
</li>
</ul>
<p>In both the cases,  we need to choose an arbitrary number of latent vectors that will be associated to each direction (and this is the reason why I have added the direction to the input features).</p>
<p>I believe that if we can calculate the sdf for each ray the first encoding will be more efficient. I wait for your opinion. <span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="103542">@Erik</span></p>



<a name="453079929"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453079929" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453079929">(Jul 22 2024 at 04:46)</a>:</h4>
<p>I have read a lot of papers, nerf, nerf++,etc...and I decided to use the methodology in this paper:<a href="https://arxiv.org/abs/2308.04079">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a></p>



<a name="453089382"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453089382" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453089382">(Jul 22 2024 at 06:01)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/452590469">said</a>:</p>
<blockquote>
<p>I have 2 ideas about encodings to try:</p>
<ul>
<li>
<p>first idea (and the best one in my opinion) is similar to the work of <a href="https://arxiv.org/abs/2011.13495">DeepSDF</a>. The idea is to train latent vectors to predict the sdf for each ray.  Then this latent vectors will be the input of our NIF architecture. The problem is that we need to compute the sdf for each ray in the sampling approach. I don't know if there is a fast way to do it. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span> <br>
Note that the sdf will be used only to train the latent vectors, so the NIF architecture won't use the sdf but only the latent vectors.</p>
</li>
<li>
<p>second one (more difficult than the first) is a similar work of  <a href="https://arxiv.org/abs/2011.13495">Neural pull</a>. In this case we do not have ground truth sdf, so the idea is to train latent vectors to "pull" rays towards the nearest surface by using the predicted signed distance values and their gradients, which the network computes. The movement of each rays is determined by the predicted distance and can be either towards or away from the surface, depending on the sign of the distance. </p>
</li>
</ul>
<p>In both the cases,  we need to choose an arbitrary number of latent vectors that will be associated to each direction (and this is the reason why I have added the direction to the input features).</p>
<p>I believe that if we can calculate the sdf for each ray the first encoding will be more efficient. I wait for your opinion. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span></p>
</blockquote>
<p>I'm reading some papers on sdf and have some questions, sdf is used to represent geometric objects, how to represent ray with sdf?</p>



<a name="453093169"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453093169" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453093169">(Jul 22 2024 at 06:29)</a>:</h4>
<p>I have currently implemented 3d Gaussian ahah</p>



<a name="453093531"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453093531" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453093531">(Jul 22 2024 at 06:32)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453089382">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/452590469">said</a>:</p>
<blockquote>
<p>I have 2 ideas about encodings to try:</p>
<ul>
<li>
<p>first idea (and the best one in my opinion) is similar to the work of <a href="https://arxiv.org/abs/2011.13495">DeepSDF</a>. The idea is to train latent vectors to predict the sdf for each ray.  Then this latent vectors will be the input of our NIF architecture. The problem is that we need to compute the sdf for each ray in the sampling approach. I don't know if there is a fast way to do it. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span> <br>
Note that the sdf will be used only to train the latent vectors, so the NIF architecture won't use the sdf but only the latent vectors.</p>
</li>
<li>
<p>second one (more difficult than the first) is a similar work of  <a href="https://arxiv.org/abs/2011.13495">Neural pull</a>. In this case we do not have ground truth sdf, so the idea is to train latent vectors to "pull" rays towards the nearest surface by using the predicted signed distance values and their gradients, which the network computes. The movement of each rays is determined by the predicted distance and can be either towards or away from the surface, depending on the sign of the distance. </p>
</li>
</ul>
<p>In both the cases,  we need to choose an arbitrary number of latent vectors that will be associated to each direction (and this is the reason why I have added the direction to the input features).</p>
<p>I believe that if we can calculate the sdf for each ray the first encoding will be more efficient. I wait for your opinion. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span></p>
</blockquote>
<p>I'm reading some papers on sdf and have some questions, sdf is used to represent geometric objects, how to represent ray with sdf?</p>
</blockquote>
<p>The idea is to find the point on the ray such that it has the minimum distance to the surface. See the ray marching algorithm or sphere tracing.</p>



<a name="453171884"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453171884" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453171884">(Jul 22 2024 at 13:05)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453093169">ha scritto</a>:</p>
<blockquote>
<p>I have currently implemented 3d Gaussian ahah</p>
</blockquote>
<p>I am trying with a probabilistic approach because I wasn't sure how to correctly extract the sdf for rays.<br>
My idea is to use an autoencoder (giving as input only the direction) so as to encode in an embedding a number n of gaussians that represent the shape of the object for that direction.</p>



<a name="453172190"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453172190" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453172190">(Jul 22 2024 at 13:07)</a>:</h4>
<p>In principle we do not need to encode all the "pixels" for a given direction in an embedding, but we need only to encode those areas which are the most uncertain.</p>



<a name="453172272"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453172272" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453172272">(Jul 22 2024 at 13:07)</a>:</h4>
<p>So I think I will merge this idea with my previous network which was good apart from the boundaries of the object.</p>



<a name="453173077"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453173077" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453173077">(Jul 22 2024 at 13:12)</a>:</h4>
<p>I made few tries in python so as to take confidence with gaussian splatting (for example I tried approximating an image using n gaussians) and I was really impressed how good is this technique.</p>



<a name="453185710"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453185710" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453185710">(Jul 22 2024 at 14:15)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453172272">said</a>:</p>
<blockquote>
<p>So I think I will merge this idea with my previous network which was good apart from the boundaries of the object.</p>
</blockquote>
<p>I agree with you. The problem is finding the boundaries.</p>



<a name="453186252"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453186252" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453186252">(Jul 22 2024 at 14:17)</a>:</h4>
<p>I have an idea about this. Since I use a sigmoid activation function as last layer to predict hit/miss it is somehow an information of the uncertainty of the prediction.</p>



<a name="453186436"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453186436" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453186436">(Jul 22 2024 at 14:18)</a>:</h4>
<p>So if it gives me a number around 0.5 it means that it is uncertain, so the gaussian should have more weight on that area.</p>



<a name="453187833"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453187833" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453187833">(Jul 22 2024 at 14:22)</a>:</h4>
<p>I think consider using Bayesian optimization</p>



<a name="453188010"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188010" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188010">(Jul 22 2024 at 14:23)</a>:</h4>
<p>About this, I would also calculate what is the mean probability that the NN gives me to each missclassified ray to check whether it can work.</p>



<a name="453188107"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188107" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188107">(Jul 22 2024 at 14:23)</a>:</h4>
<p>Bayesian networks can output both mean and variance simultaneously</p>



<a name="453188196"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188196" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188196">(Jul 22 2024 at 14:23)</a>:</h4>
<p>what is your idea</p>



<a name="453188334"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188334" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188334">(Jul 22 2024 at 14:24)</a>:</h4>
<p>I'm going a little slow, and I'm still considering how to integrate 3dgs</p>



<a name="453188635"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188635" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188635">(Jul 22 2024 at 14:25)</a>:</h4>
<p>I've completely given up on grid net.</p>



<a name="453188738"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188738" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188738">(Jul 22 2024 at 14:25)</a>:</h4>
<p>If you want to know how I want to implemented it, i use an embedding of N gaussians for each direction</p>



<a name="453188958"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188958" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188958">(Jul 22 2024 at 14:26)</a>:</h4>
<p>each gaussian can have a number of parameter that you want</p>



<a name="453189056"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189056" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189056">(Jul 22 2024 at 14:26)</a>:</h4>
<p>Can I refer to your code?</p>



<a name="453189071"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189071" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189071">(Jul 22 2024 at 14:26)</a>:</h4>
<p>but for simplicity I use only mean, variance and I think I should add also a weight</p>



<a name="453189193"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189193" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189193">(Jul 22 2024 at 14:26)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453189056">ha scritto</a>:</p>
<blockquote>
<p>Can I refer to your code?</p>
</blockquote>
<p>Ok later I will upload to github</p>



<a name="453189310"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189310" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189310">(Jul 22 2024 at 14:27)</a>:</h4>
<p>Ok, thx</p>



<a name="453189595"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189595" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189595">(Jul 22 2024 at 14:27)</a>:</h4>
<p>I tried with a small number of rays (10000) and a small number of gaussians for each direction and the NN is perfectly able to discretize all the rays</p>



<a name="453189953"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189953" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189953">(Jul 22 2024 at 14:28)</a>:</h4>
<p>The good thing is that I do not need to add any grid encoding to separate each direction, because the autoencoder is able to output the embedding in a continuos way since the input I give to it (only direction) is continuos</p>



<a name="453190136"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453190136" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453190136">(Jul 22 2024 at 14:29)</a>:</h4>
<p>That sounds great. I'd like to replace the whole rendering process with a 3dgs approach, which might turn into a rasterized rendering</p>



<a name="453265286"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453265286" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453265286">(Jul 22 2024 at 19:54)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453189056">ha scritto</a>:</p>
<blockquote>
<p>Can I refer to your code?</p>
</blockquote>
<p>i have uploaded the code for gaussian splatting. <br>
<a href="https://github.com/bralani/rt_volume/blob/neural_rendering2/src/rt/gaussian_splatting.py">https://github.com/bralani/rt_volume/blob/neural_rendering2/src/rt/gaussian_splatting.py</a></p>



<a name="453535448"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453535448" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453535448">(Jul 23 2024 at 21:48)</a>:</h4>
<p>Today I made another improvement with gaussian splatting. I decided to associate a single gaussian to each positive hit of ray in the training set with a large variance.  Each gaussian has a mean (origin_theta, origin_phi, dir_phi, dir_theta) and a variance (variance_theta, variance_phi, dir_phi, dir_theta). Dir_phi and dir_theta are set to a fixed number of 0.05 because in my opinion we can save some memory in this way and the training process will be faster. The only thing the neural network is supposed to do is to find the maximum variance of each gaussian so that also the negative hits are correctly classified. <br>
The reason why we want to find the largest variance of gaussians is because of overfitting issues.</p>



<a name="453535937"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453535937" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453535937">(Jul 23 2024 at 21:50)</a>:</h4>
<p>This works pretty good with 10000 rays but the problem is that if we increase just a bit the number of examples in the training set, the NN will become very complex in the number of parameters</p>



<a name="453536404"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453536404" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453536404">(Jul 23 2024 at 21:52)</a>:</h4>
<p>I believe that this approach has a lot of potential</p>



<a name="453536818"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453536818" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453536818">(Jul 23 2024 at 21:54)</a>:</h4>
<p>Tomorrow I will focus on reducing the number of gaussians without losing accuracy</p>



<a name="453754141"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754141" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754141">(Jul 24 2024 at 17:16)</a>:</h4>
<p>There is a bottleneck of the current NN because as I increase the number of examples in the training set, it goes out of memory</p>



<a name="453754152"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754152" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754152">(Jul 24 2024 at 17:16)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> Can you recap the structure of the computations and memory involved with the gaussian approach?  How is that related to the Encoder/Decoder networks you have/had in your gaussian_splatting.py</p>



<a name="453754204"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754204" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754204">(Jul 24 2024 at 17:17)</a>:</h4>
<p>Ok</p>



<a name="453754347"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754347" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754347">(Jul 24 2024 at 17:18)</a>:</h4>
<p>I should update that file, anyway</p>



<a name="453754522"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754522" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754522">(Jul 24 2024 at 17:18)</a>:</h4>
<p>The network is very simple: there is an encoder (which has the task to produce the embedding) and a decoder which has the task to produce the output (a probability between 0 and 1)</p>



<a name="453754642"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754642" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754642">(Jul 24 2024 at 17:19)</a>:</h4>
<p>I'm seeing a 6-layer fully connected network there, where the layers are pretty hefty number of weights in total, which would explain the memory explosion</p>



<a name="453754979"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754979" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754979">(Jul 24 2024 at 17:20)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453754642">ha scritto</a>:</p>
<blockquote>
<p>I'm seeing a 6-layer fully connected network there, where the layers are pretty hefty number of weights in total, which would explain the memory explosion</p>
</blockquote>
<p>It is the old version, I don't use any layer anymore.</p>



<a name="453755135"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755135" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755135">(Jul 24 2024 at 17:21)</a>:</h4>
<p>I have uploaded the new version now</p>



<a name="453755335"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755335" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755335">(Jul 24 2024 at 17:22)</a>:</h4>
<p>Okay.  In the old, looks like approximately 4MB of memory for that latent_dim=100 construction on just the encoder side.</p>



<a name="453755472"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755472" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755472">(Jul 24 2024 at 17:23)</a>:</h4>
<p>Sorry, way off... that's better.</p>



<a name="453755698"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755698" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755698">(Jul 24 2024 at 17:24)</a>:</h4>
<p>Ok, in this new version I associate to each gaussian 4 numbers for the mean and 4 for the variance.</p>



<a name="453755812"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755812" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755812">(Jul 24 2024 at 17:24)</a>:</h4>
<p>And the number of gaussians are proportional to the number of positive hit in the training set.</p>



<a name="453756111"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453756111" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453756111">(Jul 24 2024 at 17:25)</a>:</h4>
<p>When I use 10k samples it works fine, with 100k is very slow and with 1 million it goes out of memory</p>



<a name="453756882"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453756882" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453756882">(Jul 24 2024 at 17:29)</a>:</h4>
<p>Maybe I should not associate a single gaussian to each positive hit in the training set but I should randomly take a subset of positive hits...</p>



<a name="453757917"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453757917" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453757917">(Jul 24 2024 at 17:33)</a>:</h4>
<p>So you're using 10k ray samples currently right?  Is that your number of embeddings?</p>



<a name="453758073"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758073" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758073">(Jul 24 2024 at 17:34)</a>:</h4>
<p>With 10k rays, half are positive hits so about 5k are the embeddings</p>



<a name="453758140"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758140" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758140">(Jul 24 2024 at 17:34)</a>:</h4>
<p>Okay, but worst case it's 10k?</p>



<a name="453758170"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758170" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758170">(Jul 24 2024 at 17:35)</a>:</h4>
<p>yes</p>



<a name="453758192"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758192" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758192">(Jul 24 2024 at 17:35)</a>:</h4>
<p>or is there more on disk?  You have it actually using whatever is in the data folder</p>



<a name="453758293"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758293" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758293">(Jul 24 2024 at 17:36)</a>:</h4>
<p>(just need to make sure you don't have a json with 100M lines or something)</p>



<a name="453758373"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758373" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758373">(Jul 24 2024 at 17:36)</a>:</h4>
<p>my json has 1 million data</p>



<a name="453758426"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758426" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758426">(Jul 24 2024 at 17:36)</a>:</h4>
<p>but I take randomly only 10k samples</p>



<a name="453758530"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758530" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758530">(Jul 24 2024 at 17:37)</a>:</h4>
<p>Heh, okay .. but you're still creating an Encoder based on embeddings, which is based on how much is in your json, not how many samples, unless I'm reading this differently</p>



<a name="453758712"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758712" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758712">(Jul 24 2024 at 17:38)</a>:</h4>
<p>if you print(embeddings.shape[0]) in get_embeddings, what's that report?</p>



<a name="453758832"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758832" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758832">(Jul 24 2024 at 17:39)</a>:</h4>
<p>4683</p>



<a name="453758866"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758866" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758866">(Jul 24 2024 at 17:39)</a>:</h4>
<p>Line 47 i cut the json, so I take only 10k examples</p>



<a name="453758894"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758894" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758894">(Jul 24 2024 at 17:39)</a>:</h4>
<p>Okay, so it is hitting the else case in the constructor</p>



<a name="453758913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758913">(Jul 24 2024 at 17:39)</a>:</h4>
<p>yes</p>



<a name="453760043"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760043" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760043">(Jul 24 2024 at 17:43)</a>:</h4>
<p>So in my back-of-napkin calculations, you're really not using much memory at all, nothing that explains running out.</p>



<a name="453760148"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760148" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760148">(Jul 24 2024 at 17:44)</a>:</h4>
<p>With 10k or with 1M?</p>



<a name="453760150"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760150" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760150">(Jul 24 2024 at 17:44)</a>:</h4>
<p>The autoencoder network is trivial as you noted, about 0.25MB total (which is dubious for any real model)</p>



<a name="453760343"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760343" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760343">(Jul 24 2024 at 17:45)</a>:</h4>
<p>I don't (yet) see where you're actually accruing memory in the test iterations.</p>



<a name="453760384"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760384" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760384">(Jul 24 2024 at 17:45)</a>:</h4>
<p>Unless pytorch is doing something under the hood that isn't being used but is growing</p>



<a name="453760515"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760515" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760515">(Jul 24 2024 at 17:46)</a>:</h4>
<p>It does not even start training with 1M</p>



<a name="453760828"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760828" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760828">(Jul 24 2024 at 17:48)</a>:</h4>
<p>You mean all you change is num_epochs = 1000000 and it dies?</p>



<a name="453760873"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760873" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760873">(Jul 24 2024 at 17:49)</a>:</h4>
<p>That doesn't add up</p>



<a name="453760886"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760886" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760886">(Jul 24 2024 at 17:49)</a>:</h4>
<p>not epochs</p>



<a name="453760948"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760948" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760948">(Jul 24 2024 at 17:49)</a>:</h4>
<p>I comment the line 47, so I load all the json</p>



<a name="453761014"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761014" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761014">(Jul 24 2024 at 17:49)</a>:</h4>
<p>Oooh oh, gotcha -- so you're chaning the [:10000] to other values, how much data, how many embeddings</p>



<a name="453761063"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761063" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761063">(Jul 24 2024 at 17:50)</a>:</h4>
<p>yes</p>



<a name="453761291"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761291" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761291">(Jul 24 2024 at 17:51)</a>:</h4>
<p>In the real paper of gaussian splatting they associate a single embedding to each example but I don't understand how they don't run out of memory</p>



<a name="453761854"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761854" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761854">(Jul 24 2024 at 17:55)</a>:</h4>
<p>I don't see how you're running out of memory.</p>



<a name="453761926"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761926" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761926">(Jul 24 2024 at 17:55)</a>:</h4>
<p>there must be some bug or cleanup issue that is ballooning.  Even with 1M samples, that's only about 38MB of data</p>



<a name="453761948"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761948" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761948">(Jul 24 2024 at 17:55)</a>:</h4>
<p>you surely have more than that available :)</p>



<a name="453762030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762030">(Jul 24 2024 at 17:56)</a>:</h4>
<p>how do you calculate it?</p>



<a name="453762189"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762189" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762189">(Jul 24 2024 at 17:57)</a>:</h4>
<p>with double precision, your 5 origin+dir+label tensors consume just 40 bytes</p>



<a name="453762388"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762388" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762388">(Jul 24 2024 at 17:58)</a>:</h4>
<p>mmmm, maybe the issue is with the gradient of pytorch</p>



<a name="453762473"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762473" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762473">(Jul 24 2024 at 17:59)</a>:</h4>
<p>I remember I had this problem a long time ago</p>



<a name="453762523"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762523" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762523">(Jul 24 2024 at 17:59)</a>:</h4>
<p>I must do some checks, thanks</p>



<a name="453762527"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762527" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762527">(Jul 24 2024 at 17:59)</a>:</h4>
<p>at 5000 embeddings, that's not even 1MB for the autoencoding (embeddings + embedding params + proxy vars)</p>



<a name="453762640"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762640" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762640">(Jul 24 2024 at 18:00)</a>:</h4>
<p>got it</p>



<a name="453762802"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762802" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762802">(Jul 24 2024 at 18:00)</a>:</h4>
<p>even if it scaled linearly, to 500000 embeddings, that'd be 100MB max</p>



<a name="453763010"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763010" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763010">(Jul 24 2024 at 18:01)</a>:</h4>
<p>The json file is 100MB, so you are right</p>



<a name="453763183"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763183" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763183">(Jul 24 2024 at 18:02)</a>:</h4>
<p>Well that's text, but even as 8-byte double precision floats there's just not enough data</p>



<a name="453763319"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763319" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763319">(Jul 24 2024 at 18:02)</a>:</h4>
<p>I'd suggest adding some print or pause statements and watch the process memory usage, see if some particular operation is increasing usage substantially</p>



<a name="453763399"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763399" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763399">(Jul 24 2024 at 18:03)</a>:</h4>
<p>Ok thanks 👍🏻</p>



<a name="453763490"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763490" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763490">(Jul 24 2024 at 18:03)</a>:</h4>
<p>got to be something relatively simple.  If you were getting to iterations, I would suggest adding a gc.collect() or something to ensure python has opportunity to purge, but clearly something is going on before that even if it doesn't get to iterations.</p>



<a name="453763619"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763619" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763619">(Jul 24 2024 at 18:04)</a>:</h4>
<p>I don't see it yet, but something is consuming gobs of memory</p>



<a name="453763674"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763674" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763674">(Jul 24 2024 at 18:04)</a>:</h4>
<p>Yes it is really strange</p>



<a name="453763913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763913">(Jul 24 2024 at 18:05)</a>:</h4>
<p>Thanks</p>



<a name="453764292"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453764292" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453764292">(Jul 24 2024 at 18:07)</a>:</h4>
<p>Like I could totally see if it your constructor data hash was making 1M copies of all those string hash keys... but those are reset on each iteration of self.datas.</p>



<a name="453764657"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453764657" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453764657">(Jul 24 2024 at 18:08)</a>:</h4>
<p>maybe some linear overhead of torch.Tensor, but that doesn't make sense to me</p>



<a name="453764725"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453764725" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453764725">(Jul 24 2024 at 18:09)</a>:</h4>
<p>any change if you replace them with:</p>
<p>origin = torch.tensor(data["point1_sph"], dtype=torch.float64) <br>
dir = torch.tensor(data["dir_sph"], dtype=torch.float64) <br>
label = torch.tensor([data["label"]], dtype=torch.float64)</p>
<p>?</p>



<a name="453765068"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765068" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765068">(Jul 24 2024 at 18:10)</a>:</h4>
<p>I have not anymore the pc with me</p>



<a name="453765089"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765089" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765089">(Jul 24 2024 at 18:10)</a>:</h4>
<p>I will try later</p>



<a name="453765589"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765589" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765589">(Jul 24 2024 at 18:12)</a>:</h4>
<p>Okay.  I'd try that but then also exit before the training use and see if you can get a pause before exiting to see how much memory the app is actually using before RayDataset, after RayDataset construction, and after Autoencoder construction, see where it balloons out.</p>



<a name="453765750"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765750" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765750">(Jul 24 2024 at 18:13)</a>:</h4>
<p>Yep it is what I am going to try 👍🏻</p>



<a name="453767361"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453767361" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453767361">(Jul 24 2024 at 18:20)</a>:</h4>
<p>Came across this interesting high-level article posted today, nice generic tutorial... <a href="https://gpuopen.com/learn/deep_learning_crash_course/">https://gpuopen.com/learn/deep_learning_crash_course/</a></p>



<a name="453804846"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453804846" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453804846">(Jul 24 2024 at 22:02)</a>:</h4>
<p><a href="/user_uploads/1549/8gAx74Q6K7ERNGbn0gbqLPi0/Screenshot-2024-07-24-alle-23.59.31.png">Screenshot-2024-07-24-alle-23.59.31.png</a><br>
Ok I got it. <span class="user-mention" data-user-id="102902">@Sean</span> You were right on all the estimations of the memory. The problem is in the decoder which you hadn't seen, when I calculate the probability of the examples that belongs to each gaussian.<br>
I had implemented broadcasting (to speed up calculations) so I clone the embeddings (gaussian) n times where n is the batch size (number of examples).<br>
In this image the batch size was of 256 examples.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/8gAx74Q6K7ERNGbn0gbqLPi0/Screenshot-2024-07-24-alle-23.59.31.png" title="Screenshot-2024-07-24-alle-23.59.31.png"><img src="/user_uploads/thumbnail/1549/8gAx74Q6K7ERNGbn0gbqLPi0/Screenshot-2024-07-24-alle-23.59.31.png/840x560.webp"></a></div>



<a name="453805101"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453805101" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453805101">(Jul 24 2024 at 22:04)</a>:</h4>
<p>Broadcasting in this case isn't probably a smart way to speed up calculations since a lot of gaussians are totally useless for the calculations of the probability for the current examples, but only the closest one to the current example are relevant.</p>



<a name="453948030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453948030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453948030">(Jul 25 2024 at 13:23)</a>:</h4>
<p>I have solved the broadcasting issue that run out memory and I have first results. For the moment I am trying with only 10k rays because the calculation of probability is pretty slow.</p>
<p>Here the best epoch of the previous NIF network with only 10k rays:</p>
<p>F1: 0.880218316493941 <br>
Accuracy: 0.9283117186132877 <br>
Precision: 0.9087676930301201 <br>
Recall: 0.8534080886985007</p>
<p>Here, instead the best epoch with this new gaussian splatting network with 10K rays and only 1k gaussians embeddings (I decided to lower the number of gaussians to better explain the power of this model):</p>
<p>F1 Score: 0.9155<br>
Accuracy: 0.9261<br>
Precision: 0.9316<br>
Recall: 0.9000</p>
<p>As you can notice, the gaussian splatting architecture has more power than the NIF architecture BUT it is way slower. <br>
The interesting part is that I achieved this result in only 11 epochs, so the training is not slow but the inference is slow (the action from the start of the neural network to giving back the prediction).</p>
<p>For this reason, I will now focus on speeding up the gaussian splatting architecture. I believe I should read some papers about real-time renderings with gaussian splatting so as to achieve this speed up.</p>
<p>One idea I have is cutting some gaussians basing on the input I want to predict. (ie the furthest ones from the ray I want to predict).</p>
<p>P.S: the results I have showed here are not close to the ones of the previous week (accuracy: 0.994 and F1: 0.991) just because they were achieved with 1 Million examples. Here I use only 10k rays just to compare NIF architecture with Gaussian Splatting.</p>



<a name="454353169"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454353169" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454353169">(Jul 26 2024 at 18:38)</a>:</h4>
<p>Today I had implemented parallelization of inference process and the training process is much faster. <br>
However, I had another problem with the covariance matrix. To calculate the pdf of a gaussian we need to invert the covariance matrix but when it is close to singularity, it is not possible to invert it. The problem is that the covariance matrix for all the gaussians has small values due to the nature of the problem (if you imagine each gaussian as an ellipsoid in 3D, it will have very small magnitude). <br>
To mitigate this problem I decided to use double precision (float64) and for the moment it seems to perform better.</p>



<a name="454353587"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454353587" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454353587">(Jul 26 2024 at 18:42)</a>:</h4>
<p>Do you know any other method to solve this issue of matrix ill-conditioning?</p>



<a name="454354000"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454354000" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454354000">(Jul 26 2024 at 18:46)</a>:</h4>
<p>Apart from this, tomorrow I will train with more examples to see the true results of this model.</p>



<a name="454539480"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454539480" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454539480">(Jul 27 2024 at 23:13)</a>:</h4>
<p>Today I had further speed up the inference process by taking only the closest gaussians to the example to predict. I had also tried with more examples (100k) and the metric F1 improves even to 94-95%. However, it seems more difficult to improve this result with the current architecture. My opinion is due to the number of gaussians that now are fixed for all the training. The original paper (3DGS) uses instead a variable number of gaussians that can be lowered during the training process (if some gaussians have a very small variance) or it can be increased if the accuracy is low.</p>



<a name="454544610"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454544610" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454544610">(Jul 28 2024 at 00:10)</a>:</h4>
<p>That's sounding a lot better.  I think it'll still need to get into the 99% realm, but that's a distinct improvement.  What's that 94%-95% look like?</p>



<a name="454544714"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454544714" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454544714">(Jul 28 2024 at 00:11)</a>:</h4>
<p>By the way, had a lovely discussion with one of the authors of AMD's Neural Intersection Function paper today.  He said they've made some headway on generalizing themselves, but that's obviously a hard problem.  He's probably going to publish on it next year.</p>



<a name="454544906"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454544906" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454544906">(Jul 28 2024 at 00:15)</a>:</h4>
<p>One thought I had, and it's obviously in a different direction but maybe applicable is what if we try integrating over multiple networks.  That is, use the simple network they demonstrated works well for a single view, but then lets create one for 32 (or 32768) views, get estimated in-hit points from all of them, and integrate spatially.</p>



<a name="454545008"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454545008" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454545008">(Jul 28 2024 at 00:16)</a>:</h4>
<p>That's actually not terribly dissimilar from the NeRF approach, but the goal would not be a radiance field.  It would be like a surface occupancy field, or a point cloud with weights.</p>



<a name="454604656"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454604656" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454604656">(Jul 28 2024 at 11:42)</a>:</h4>
<p>This is really possible. I recently saw some algorithms for interpolation between multiple pictures. Maybe we can predict in key directions and then make differences in other directions.</p>



<a name="454612969"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454612969" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454612969">(Jul 28 2024 at 13:27)</a>:</h4>
<p>If the direction is contant, network is learning a func like:<br>
<a href="/user_uploads/1549/FirF5i_t38_4wtaOioudCpRS/屏幕截图-2024-07-28-212551.png">2024-07-28-212551.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/FirF5i_t38_4wtaOioudCpRS/屏幕截图-2024-07-28-212551.png" title="2024-07-28-212551.png"><img data-original-dimensions="1281x705" src="/user_uploads/thumbnail/1549/FirF5i_t38_4wtaOioudCpRS/屏幕截图-2024-07-28-212551.png/840x560.webp"></a></div>



<a name="454613104"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454613104" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454613104">(Jul 28 2024 at 13:29)</a>:</h4>
<p>Interpolated fits between different perspectives have been done before:<br>
<a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png">2024-07-28-212847.png</a><br>
from <a href="https://arxiv.org/pdf/2211.00722">VIINTER: View Interpolation with Implicit Neural Representations of Images</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png" title="2024-07-28-212847.png"><img data-original-dimensions="1696x558" src="/user_uploads/thumbnail/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png/840x560.webp"></a></div>



<a name="454617963"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454617963" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454617963">(Jul 28 2024 at 14:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454544610">ha scritto</a>:</p>
<blockquote>
<p>That's sounding a lot better.  I think it'll still need to get into the 99% realm, but that's a distinct improvement.  What's that 94%-95% look like?</p>
</blockquote>
<p>I have not rendered any frame for gaussian splatting network yet because if the percentage are under 0.97 - 0.98, the predicted image is very far from the true one. I prefer first to achieve better results and then plotting it.</p>



<a name="454618704"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454618704" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454618704">(Jul 28 2024 at 14:35)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454544906">ha scritto</a>:</p>
<blockquote>
<p>One thought I had, and it's obviously in a different direction but maybe applicable is what if we try integrating over multiple networks.  That is, use the simple network they demonstrated works well for a single view, but then lets create one for 32 (or 32768) views, get estimated in-hit points from all of them, and integrate spatially.</p>
</blockquote>
<p>This idea is not far from the idea of grid encoding of direction which I have already tried without any improvement. In that case I used embeddings for each direction, you suggest using a network for each direction. I can try it. <span aria-label="thumbs up" class="emoji emoji-1f44d" role="img" title="thumbs up">:thumbs_up:</span></p>



<a name="454620623"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454620623" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454620623">(Jul 28 2024 at 14:54)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454613104">ha scritto</a>:</p>
<blockquote>
<p>Interpolated fits between different perspectives have been done before:<br>
<a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png">2024-07-28-212847.png</a><br>
from <a href="https://arxiv.org/pdf/2211.00722">VIINTER: View Interpolation with Implicit Neural Representations of Images</a></p>
</blockquote>
<p>This could work but it means that  we have to change the sampling to fixed view sampling. I have some doubts about the number of views we should sample because:<br>
If we choose for example 1 million rays in the training set and we choose  a reasonable number of 1000 rays for each view this means that we have a total of 1000 views.<br>
If we distribute uniformly these views around the bounding sphere it means that, remember that theta goes from 0 to pi and phi goes from 0 to 2pi:<br>
In my case I can use half of phi because in my case the problem is simpler and the direction is invariant to orientation (so I have theta that goes from 0 to pi and phi that goes from 0 to pi):<br>
Theta x phi = 3,14 x 3,14 = 9,8596 -&gt; total space<br>
Uniform distribution of views:<br>
9,8596/1000 views = 0,009859 rad = 0,56° between two views. <br>
I think it is a reasonable error and it can be easily interpolated.<br>
In your case, however, you can't reduce the range of phi (because rgb is not invariant to orientations), so you will have:<br>
Theta x phi = 3,14 x 6,28 = 19,719 -&gt; total space<br>
19,719/1000 views = 0,0197 rad = 1,128° between two views. <br>
An error of 1° is reasonable also in your case and if my calculations are exact, it could work even in your case but the error is the double of mine.</p>



<a name="454620794"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454620794" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454620794">(Jul 28 2024 at 14:57)</a>:</h4>
<p>I believe we should try this approach using NIF architecture and then interpolating them.</p>



<a name="454622260"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454622260" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454622260">(Jul 28 2024 at 15:10)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span>  I have a doubt about rays and pixels: if we want to render a frame of 100x100 it means that the algorithm sample for each pixel a ray (for a total of 10k rays) or is it different?</p>



<a name="454677762"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454677762" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454677762">(Jul 28 2024 at 23:13)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454617963">said</a>:</p>
<blockquote>
<p>I have not rendered any frame for gaussian splatting network yet because if the percentage are under 0.97 - 0.98, the predicted image is very far from the true one. I prefer first to achieve better results and then plotting it.</p>
</blockquote>
<p>That is absolutely not best practice and not recommended to ignore the predicted images solely based on having low percentages.  Not looking gives you no information.  Looking may give no information, or may provide helpful clues as to what isn't encoding well.  </p>
<p>It can be high frequency detail, it can be a straight up bug where values are simply shifted, it can be low frequency undulations, and more.  It's not in your interest to ignore them even if 19 times out of 20 it's just a "drunk wet mess".</p>



<a name="454678116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454678116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454678116">(Jul 28 2024 at 23:18)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454620794">said</a>:</p>
<blockquote>
<p>I believe we should try this approach using NIF architecture and then interpolating them.</p>
</blockquote>
<p>I will just reiterate what we'd discussed earlier, that there should be two different approaches being taken (in general), or even better two different goals (e.g., 3d shape vs 2d image).  There is value in exploring the same method with different implementation detail (on the off chance there is some detail that matters more than anticipated).</p>



<a name="454678542"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454678542" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454678542">(Jul 28 2024 at 23:22)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454618704">said</a>:</p>
<blockquote>
<p>This idea is not far from the idea of grid encoding of direction which I have already tried without any improvement. In that case I used embeddings for each direction, you suggest using a network for each direction. I can try it. <span aria-label="thumbs up" class="emoji emoji-1f44d" role="img" title="thumbs up">:thumbs_up:</span></p>
</blockquote>
<p>It's not far off, but the separate networks is the key.  AMD really proved that surface illumination can be almost perfectly encoded for a given view.  Maybe if we were to first reproduce their research, that would give more confidence, but lacking that it's not terribly unexpected.</p>
<p>Now that said, I don't think there's a whole lot of difference with random rays in random dirs -- naively I think that can work with the right network and right amount of training.  Remains to be proven though.  The idea with the 32+ grid views, however, is a compromise, banking on the notion that a single view should converge that view.  In other analysis work we're involved with, there's mathematical proofs that lend evidence towards 32 views being a sweet spot approximation for complete random, converging much faster than pure random.</p>



<a name="454678740"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454678740" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454678740">(Jul 28 2024 at 23:25)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454620623">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454613104">ha scritto</a>:</p>
<blockquote>
<p>Interpolated fits between different perspectives have been done before:<br>
<a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png">2024-07-28-212847.png</a><br>
from <a href="https://arxiv.org/pdf/2211.00722">VIINTER: View Interpolation with Implicit Neural Representations of Images</a></p>
</blockquote>
<p>This could work but it means that  we have to change the sampling to fixed view sampling. I have some doubts about the number of views we should sample because:<br>
If we choose for example 1 million rays in the training set and we choose  a reasonable number of 1000 rays for each view this means that we have a total of 1000 views.<br>
If we distribute uniformly these views around the bounding sphere it means that, remember that theta goes from 0 to pi and phi goes from 0 to 2pi:<br>
In my case I can use half of phi because in my case the problem is simpler and the direction is invariant to orientation (so I have theta that goes from 0 to pi and phi that goes from 0 to pi):<br>
Theta x phi = 3,14 x 3,14 = 9,8596 -&gt; total space<br>
Uniform distribution of views:<br>
9,8596/1000 views = 0,009859 rad = 0,56° between two views. <br>
I think it is a reasonable error and it can be easily interpolated.<br>
In your case, however, you can't reduce the range of phi (because rgb is not invariant to orientations), so you will have:<br>
Theta x phi = 3,14 x 6,28 = 19,719 -&gt; total space<br>
19,719/1000 views = 0,0197 rad = 1,128° between two views. <br>
An error of 1° is reasonable also in your case and if my calculations are exact, it could work even in your case but the error is the double of mine.</p>
</blockquote>
<p>Again, I would just caution whether we're following research that is attempting to capture shape in the embedding or whether the goal is capturing the shape just barely enough that color, i.e., a visual image can be constructed that "looks good enough".  On quick read, that VINTER paper appears to be the latter, but I'd have to read it in more detail.</p>



<a name="454679031"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454679031" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454679031">(Jul 28 2024 at 23:28)</a>:</h4>
<p>As for total number of views, I think you could try as coarse as 45-degree increments.  Resolution will need to be as fine as the smallest detail, which depends on the model size and detail complexity.  I'd personally start at 1024x1024, about 1M per view.</p>



<a name="454679122"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454679122" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454679122">(Jul 28 2024 at 23:29)</a>:</h4>
<p>That 1024^2 resolution at 45-degree probably means something like 256 or 512 resolution alignment, whatever that cell size resolves to.</p>



<a name="454764857"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454764857" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454764857">(Jul 29 2024 at 08:52)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454677762">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454617963">said</a>:</p>
<blockquote>
<p>I have not rendered any frame for gaussian splatting network yet because if the percentage are under 0.97 - 0.98, the predicted image is very far from the true one. I prefer first to achieve better results and then plotting it.</p>
</blockquote>
<p>That is absolutely not best practice and not recommended to ignore the predicted images solely based on having low percentages.  Not looking gives you no information.  Looking may give no information, or may provide helpful clues as to what isn't encoding well.  </p>
<p>It can be high frequency detail, it can be a straight up bug where values are simply shifted, it can be low frequency undulations, and more.  It's not in your interest to ignore them even if 19 times out of 20 it's just a "drunk wet mess".</p>
</blockquote>
<p>Yes, you are totally right. I did not considered to render it because I got that result with only 100K rays and I wanted first to train the NN with at least 1 million rays. Thanks for the advise.</p>



<a name="454766161"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454766161" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454766161">(Jul 29 2024 at 08:57)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454678542">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454618704">said</a>:</p>
<blockquote>
<p>This idea is not far from the idea of grid encoding of direction which I have already tried without any improvement. In that case I used embeddings for each direction, you suggest using a network for each direction. I can try it. <span aria-label="thumbs up" class="emoji emoji-1f44d" role="img" title="thumbs up">:thumbs_up:</span></p>
</blockquote>
<p>It's not far off, but the separate networks is the key.  AMD really proved that surface illumination can be almost perfectly encoded for a given view.  Maybe if we were to first reproduce their research, that would give more confidence, but lacking that it's not terribly unexpected.</p>
<p>Now that said, I don't think there's a whole lot of difference with random rays in random dirs -- naively I think that can work with the right network and right amount of training.  Remains to be proven though.  The idea with the 32+ grid views, however, is a compromise, banking on the notion that a single view should converge that view.  In other analysis work we're involved with, there's mathematical proofs that lend evidence towards 32 views being a sweet spot approximation for complete random, converging much faster than pure random.</p>
</blockquote>
<p>I was wondering... Isn't the limit of the previous NN (NIF network which I got 0.994 for accuracy) was simply that the number of examples in the training set was too low? Maybe we should try with even more samples (more than 1 million) to see how it works.</p>



<a name="454956525"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454956525" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454956525">(Jul 29 2024 at 21:45)</a>:</h4>
<p>Today I had implemented the adaptive learning for Gaussian splatting architecture. I want first to finish and evaluate this architecture before trying with multiple NIFs.</p>



<a name="455319987"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455319987" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455319987">(Jul 31 2024 at 08:38)</a>:</h4>
<p>After many optimizations, I got a pretty good result(grid net, fix direction)<br>
<a href="/user_uploads/1549/RTCyYXBw1e7ZcOaqRuzzZ8dQ/屏幕截图-2024-07-31-163626.png">2024-07-31-163626.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/RTCyYXBw1e7ZcOaqRuzzZ8dQ/屏幕截图-2024-07-31-163626.png" title="2024-07-31-163626.png"><img data-original-dimensions="757x796" src="/user_uploads/thumbnail/1549/RTCyYXBw1e7ZcOaqRuzzZ8dQ/屏幕截图-2024-07-31-163626.png/840x560.webp"></a></div>



<a name="455421932"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455421932" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455421932">(Jul 31 2024 at 16:20)</a>:</h4>
<p><span class="user-mention" data-user-id="700180">@fall Rainy</span> please elaborate, (and point to latest code!) what's the resolution of the grid net, what are the layers, how many epochs, how long did training take, how long does lookup take, etc...</p>



<a name="455494134"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455494134" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455494134">(Jul 31 2024 at 22:09)</a>:</h4>
<p>Really cool paper implementation on how to encode BREP in a NNet... <a href="https://github.com/samxuxiang/BrepGen">https://github.com/samxuxiang/BrepGen</a></p>



<a name="455494519"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455494519" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455494519">(Jul 31 2024 at 22:12)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455494134">said</a>:</p>
<blockquote>
<p>Really cool paper implementation on how to encode BREP in a NNet... <a href="https://github.com/samxuxiang/BrepGen">https://github.com/samxuxiang/BrepGen</a></p>
</blockquote>
<p>I have some experience with diffusion models for 3D. I did a diffusion network for automatic retopology (for my university).</p>



<a name="455494661"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455494661" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455494661">(Jul 31 2024 at 22:13)</a>:</h4>
<p>Regarding Gaussian splatting, I am not so convinced about metrics, tomorrow I will render some frames to see graphical results…</p>



<a name="455558171"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455558171" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455558171">(Aug 01 2024 at 06:02)</a>:</h4>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>



<a name="455619388"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455619388" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455619388">(Aug 01 2024 at 11:07)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">ha scritto</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>This is fantastic, I just tried the software of <a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a> (which is the base code they use) and the training time is of the order of seconds even with my poor GTX 1060!!</p>



<a name="455626048"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455626048" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> starseeker <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455626048">(Aug 01 2024 at 11:48)</a>:</h4>
<p>Nuts.  instant-ngp code license is non-commercial only</p>



<a name="455627431"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455627431" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455627431">(Aug 01 2024 at 11:57)</a>:</h4>
<p><span class="user-mention silent" data-user-id="112516">starseeker</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455626048">said</a>:</p>
<blockquote>
<p>Nuts.  instant-ngp code license is non-commercial only</p>
</blockquote>
<p>It’s not so bad, all we need to do is understand their paper and the one that Sean sent. The coding part shouldn’t be difficult even if we have to code from 0.</p>



<a name="455657387"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455657387" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455657387">(Aug 01 2024 at 14:00)</a>:</h4>
<p>Yeah, the implementation seems pretty straightforward.  The main limitation is they didn't get a performance gain.  They train for a few minutes, then ray query performance is on par with the ray tracing time.  The one big gain they saw was getting that on-par ray tracing time with an order of magnitude less memory use.  So exceptional compression in the latent space.</p>



<a name="455659182"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659182" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659182">(Aug 01 2024 at 14:08)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455421932">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> please elaborate, (and point to latest code!) what's the resolution of the grid net, what are the layers, how many epochs, how long did training take, how long does lookup take, etc...</p>
</blockquote>
<p>There are three resolutions: <br>
first,I give up bilinear interpolation and try to learn a matrix to express the relationship between neighboring vectors<br>
second, I consider neighboring vectors in the range 7&times;7 instead of 2&times;2<br>
third, I use a threshold to reduce noise.<br>
here is my codes: <a href="https://github.com/Rainy-fall-end/Rendernn/blob/main/networks/gridnet3.py">https://github.com/Rainy-fall-end/Rendernn/blob/main/networks/gridnet3.py</a><br>
100,000 points need to be sampled, but the model actually converges when <strong>20,000</strong> points are used，The training will take 2 minutes total.(4060)<br>
The yellow curve is the improved gridnet, the purple one is the original gridnet. <br>
<a href="/user_uploads/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png">2024-08-01-220614.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png" title="2024-08-01-220614.png"><img data-original-dimensions="1623x703" src="/user_uploads/thumbnail/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png/840x560.webp"></a></div>



<a name="455659364"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659364" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659364">(Aug 01 2024 at 14:09)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">said</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>But this one looks so much better than mine....</p>



<a name="455659469"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659469" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659469">(Aug 01 2024 at 14:09)</a>:</h4>
<p>Cool, thanks!  I'll take a look in more detail.  Looks like it converges pretty quickly?  How long did it take to get to step 200?</p>



<a name="455659590"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659590" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659590">(Aug 01 2024 at 14:10)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455659364">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">said</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>But this one looks so much better than mine....</p>
</blockquote>
<p>Don't worry about that -- this is very ripe area of research.</p>



<a name="455659621"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659621" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659621">(Aug 01 2024 at 14:10)</a>:</h4>
<p>About 30 seconds.</p>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455659469">said</a>:</p>
<blockquote>
<p>Cool, thanks!  I'll take a look in more detail.  Looks like it converges pretty quickly?  How long did it take to get to step 200?</p>
</blockquote>



<a name="455659622"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659622" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659622">(Aug 01 2024 at 14:10)</a>:</h4>
<p>It also means it's worth exploring all avenues as the details matter.</p>



<a name="455660576"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455660576" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455660576">(Aug 01 2024 at 14:15)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455619388">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">ha scritto</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>This is fantastic, I just tried the software of <a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a> (which is the base code they use) and the training time is of the order of seconds even with my poor GTX 1060!!</p>
</blockquote>
<p>This looks like it's implemented in C++, are you going to reproduce it in pytorch?</p>



<a name="455660836"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455660836" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455660836">(Aug 01 2024 at 14:16)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455660576">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455619388">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">ha scritto</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>This is fantastic, I just tried the software of <a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a> (which is the base code they use) and the training time is of the order of seconds even with my poor GTX 1060!!</p>
</blockquote>
<p>This looks like it's implemented in C++, are you going to reproduce it in pytorch?</p>
</blockquote>
<p>I am still understanding all the ideas of those two papers, but yes probably I will reproduce in pytorch.</p>



<a name="455686227"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455686227" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455686227">(Aug 01 2024 at 15:53)</a>:</h4>
<p>The N-BVH paper was an outstanding talk -- will see if I can get a copy, but it's a direct response to AMD's NIF paper.   They key insight was to not use the ray+dir but to instead use 3 sample points along the ray on the interior of the bounding volume along with a BVH.<br>
<a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>



<a name="455686661"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455686661" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455686661">(Aug 01 2024 at 15:55)</a>:</h4>
<p>The key insight of using interior points was demonstrated with just 3-10 sample points which of course made training slower as points are added, but achieved essentially perfect occupancy recall even with high frequency detail.  Adding in a BVH was a training optimization so they could reduce it back down to just 3 points per BVH node.</p>



<a name="455763730"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455763730" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455763730">(Aug 01 2024 at 21:59)</a>:</h4>
<p>I was studying that paper and had a few questions:</p>
<ul>
<li>They mention using a batch size of 2^18 rays, which is 262,144.</li>
<li>They use a total of 100 batches.</li>
</ul>
<p>This means their training set consists of 2^18×100, equating to approximately 26 million rays. Moreover, they state that the training time is at most 2-3 minutes.</p>
<p>I just discovered that it is indeed possible to use such a large batch size (I had been training NIF with a batch size of just 512 rays until now...). However, theory suggests that using a large batch size can increase variance error. Likely, with such a large training set, they do not encounter this issue.</p>
<p>What puzzles me most is how they can achieve convergence in just about 2-3 minutes.</p>
<p>To investigate, I increased the batch size for the NIF model (with which I previously achieved an accuracy of 0.994). As expected, the model trains faster (20 minutes for 1 million rays), and the performance metrics remained roughly the same (just a little worse).</p>



<a name="455764243"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455764243" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455764243">(Aug 01 2024 at 22:02)</a>:</h4>
<p>However, convergence for NIF is much slower than their approach, meaning that training a simple NIF requires more time and results in lower accuracy. Likely, the bounding volume hierarchies approach they use significantly helps the neural network.</p>



<a name="455811517"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455811517" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455811517">(Aug 02 2024 at 03:17)</a>:</h4>
<p>That 262144 is almost certainly a 512x512 grid, 100 different views</p>



<a name="455811606"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455811606" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455811606">(Aug 02 2024 at 03:17)</a>:</h4>
<p>Now have to take performance with a grain of salt.  I didn't see the hardware, but it they're on a high-end GPU, that might be an hour of training on a CPU..</p>



<a name="455812755"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455812755" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455812755">(Aug 02 2024 at 03:24)</a>:</h4>
<p>In their talk the BVH optimization using 3 samples vs 10 samples cut the training time roughly in half (1min)</p>



<a name="455868509"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455868509" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455868509">(Aug 02 2024 at 08:17)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455811606">ha scritto</a>:</p>
<blockquote>
<p>Now have to take performance with a grain of salt.  I didn't see the hardware, but it they're on a high-end GPU, that might be an hour of training on a CPU..</p>
</blockquote>
<p>They used an RTX 3090</p>



<a name="455868781"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455868781" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455868781">(Aug 02 2024 at 08:18)</a>:</h4>
<p>How do you estimate that it would be an hour on a CPU?</p>



<a name="455917973"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455917973" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455917973">(Aug 02 2024 at 12:05)</a>:</h4>
<p>I decided to implement first the multi-resolution hash grid and validate it, then on top of this I will add the BVH approach so as to integrate rays in the 3D grid.</p>



<a name="455987086"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455987086" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455987086">(Aug 02 2024 at 17:09)</a>:</h4>
<p>I found this wonderful repository <a href="https://github.com/ashawkey/torch-ngp">https://github.com/ashawkey/torch-ngp</a> and I am using this as a base code for the multi-resolution hash grid.</p>



<a name="456042543"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456042543" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456042543">(Aug 02 2024 at 21:11)</a>:</h4>
<p>I implemented the multi-resolution hash grid and I tested it on top of my previous NIF network. It's incredible how it converges in just few seconds even on my poor gpu.<br>
It achieves only 96% of F1 but it was expected since this encoding is not appropriated for rays+dir input (as we have in NIF) but they are appropriated for 3D points (like in NVBH).<br>
Tomorrow I will focus on this part <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>



<a name="456199833"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456199833" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456199833">(Aug 03 2024 at 18:06)</a>:</h4>
<p><a href="/user_uploads/1549/-Weq4In9RbiGIix2jJyXzhBH/Figure_1.png">Figure_1.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/-Weq4In9RbiGIix2jJyXzhBH/Figure_1.png" title="Figure_1.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/-Weq4In9RbiGIix2jJyXzhBH/Figure_1.png/840x560.webp"></a></div><p><a href="/user_uploads/1549/AQ1sAr9p6ma0ECmaNWiwrNzi/Figure_2.png">Figure_2.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/AQ1sAr9p6ma0ECmaNWiwrNzi/Figure_2.png" title="Figure_2.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/AQ1sAr9p6ma0ECmaNWiwrNzi/Figure_2.png/840x560.webp"></a></div><p>Today I tried the multi-resolution hash grid sampling N points along the the ray. In this picture I sampled 70 points along each ray. I want to mention that this is without the BVH approach but only the multi-grid resolution. The metric F1 is about 0.985 and it converges in few seconds. The training set was about 3 million rays and the picture is 512x512. I noticed that increasing the number of the sampling points, the metrics are better (and without the BVH approach I have to use a lot of sampling points).</p>



<a name="456200003"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456200003" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456200003">(Aug 03 2024 at 18:07)</a>:</h4>
<p>Before implementing the BVH approach I want to try with more samples (like the paper -&gt; 26 millions).</p>



<hr><p>Last updated: Aug 04 2024 at 00:43 UTC</p>
</html>