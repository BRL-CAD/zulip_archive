<html>
<head><meta charset="utf-8"><title>Neural Rendering · Google Summer of Code · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/index.html">Google Summer of Code</a></h2>
<h3>Topic: <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html">Neural Rendering</a></h3>

<hr>

<base href="https://brlcad.zulipchat.com">

<head><link href="https://brl-cad.github.io/zulip_archive/style.css" rel="stylesheet"></head>

<a name="424426002"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424426002" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424426002">(Mar 02 2024 at 16:42)</a>:</h4>
<p>Hi <span class="user-mention" data-user-id="694938">@Senthil Palanisamy</span>, lets continue the discussion here.  Can you tell me more about your background and what you understand about this effort?  Have you read the AMD paper?</p>



<a name="424429528"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424429528" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424429528">(Mar 02 2024 at 17:27)</a>:</h4>
<p>(deleted)</p>



<a name="424455092"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424455092" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Senthil Palanisamy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424455092">(Mar 02 2024 at 23:36)</a>:</h4>
<p>Hi Sean, Thanks for the message. </p>
<p><strong>About my background:</strong> I come from a geometric vision background where I worked more than 6 years, to go along with my masters in robotics from Northwestern.  I have developed solutions to problems like Stereo visual Odometry, Depth data based SLAM / TSDF fusion of depth maps into a volumetric volume to generate geometry, Extrinsic sensor calibration algorithms (the act of optimizing solutions to where sensors are located). I have done a few deep learning works as well like deep reinforcement policy  learning for a knot tieing, weed localization and human character recgonition. I can send you my resume to any mail id of interest, if you want to know about my background further. Though I don't actively have a graphics background, I do understand the broader details and am able to grasp quickly to execute ideas. My programming languages of comfort are C++ and python (though I do think I can pick up any language within a reasonable time)</p>
<p><strong>About the work</strong>: I did spent a few hours trying to understand the work. Here is my summary - A classic ray tracing pipeline on BVH for rendering objects is slow. One of the deep learning ways to speed this up is to  train a MLP to be a neural intersection function - a network that primarily predicts occupancy as a probability (0-1), but it can be trained to predict other properties as well like shading /  reflectence. This network can be trained directly on position and ray directions, but it does not practically work well. So, the solution is to learn some feature embeddings for position and direction, which then feed into MLP. Each of position and direction are points in R^3, but this leads to ray duplicates, so they can be compactly represented as points in R^2, by using spherical co-ordinates and substituting the ray origin with ray intersection. Raycasting is usually done in multi bounces, where secondary rays are traced from the primary ray. So there are two NIFs one (outer NIF) predicting the primary intersection, and the other (inner NIF) predicting occupancy from the secondary intersection. The inner NIF takes ray distance embedding as input in addition to position and direction embeddings. It seems like a classic tracing tracing scheme employs two hierarchies in BVH to trace rays. The top BVH tracing is cheap while the bottom BVH tracking is expensive. NIFs replace the bottom BVH part, while the top BVH tracing is done through classical means. The outer NIF just predicts occupancy while the inner NIF predicts other properties in addition to occupancy.</p>
<p><strong>Some open questions I am still trying to find answers to</strong></p>
<ol>
<li>What is the feature embedding scheme for position and direction? I know that sine and cosine bases (fourier analysis motivated) is used a lot in works like nerfs, but I have not got to the bottom of what embedding is used here</li>
<li>It seems like the networks used here are AMD specific C++ libraries. Is this something that we will use in this work? Or is the idea to use a more popular library like pytorch.</li>
</ol>
<p><strong>My personal motivation for taking this work</strong></p>
<ol>
<li>I have never contributed to open source and I was scouting for places to begin my open source journey. Contributing to open source increases my visibility and exposes me to learn a lot more than from just contributing to the private repos that I work for.</li>
<li>I want to work on a geometric deep learning project to update myself to the SOTA</li>
</ol>



<a name="424676516"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424676516" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424676516">(Mar 04 2024 at 15:06)</a>:</h4>
<p><span class="user-mention" data-user-id="694938">@Senthil Palanisamy</span> Thank you for the excellent introduction.  From your background, it sounds like you could probably propose a couple different projects that would align with needs (like a slam-based object reconstruction using ray tracing), which is all outstanding background for working on neural rendering.  Obviously a lot of related concepts.  As for your resume, you can just submit that when you submit a proposal (which you can/should do early and then continuously update, whenever it opens).  Given the nature of GSoC, resume's and the project write-up itself are only a small fraction of selection criteria.  It's communication that matters most (both here and via code).</p>
<p>I think your understanding of the project is right on track and you did a great job summarizing AMD's work.  They essentially showed that it can be faster, so now my question is whether it can be faster and more generally applicable for a set of conditions like expensive geometries and reasonably precise hit points. Can we actually use it as an acceleration structure in practice, or is the training phase entirely impractical; what sort of net is needed to capture all the necessary detail; is the two-layer network adequate; are the two NIFs actually necessary; ... lots of open questions many of which are hand-waved in the paper and proved challenging in our previous investigations by a team at TAMU.</p>
<p>As to your questions, if I'm understanding you correctly, then 1) is really just a dimensionality reduction so lookups can be fast and fewer parameters in the latent space are needed for encoding.  Instead of using 6 float/double values for the input layer (xyz pos + ijk dir), they use 4 float values (az/el pos + az/el dir).  There may be more nuance implied for feature embedding, though, so there may be work needed to understand it if changes are to be made.  I'm a little surprised I didn't see residual linkages, and that they got away with such simple topology, but then we have yet to reproduce  their results either. As for 2) the did rely on libs for performance and they certainly can be used but they're not a focus or requirement.  The fundamental question is is this approach even feasible as an acceleration approach to represent a given geometry model.  That has both elements of accuracy and performance, but can be proven without making it production-ready.  Libs like pytorch can certainly be used.  In fact, the previous team fully bridged from C to Py to C during ray-tracing which was of course painfully slow, but they weren't successful in getting accurate hit points so the question is still an open one.</p>



<a name="424707867"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424707867" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Senthil Palanisamy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424707867">(Mar 04 2024 at 17:23)</a>:</h4>
<p>Thanks for the response. The grid look up makes sense now. I was intially under the misunderstanding that some network converts position, direction -&gt; position, direction embedding. But it does make sense that it is just a grid that is trained as well in the training process. I have a few follow up questions</p>
<ol>
<li>What kind of training practically are we talking of? Since this is a CAD product, is the idea that the network has to train real time as the user possibly edits the model to update the rendering in real time? Or is the idea the training can be done once, in a somewhat offline fashion (like a few minutes or few 10s of minutes) and then can be used for rendering (where the user is assumed to not edit)</li>
<li>As for the implementation is concerned, the network itself looks simple and innocuous, each NIF is a MLP - the outer is a 2 layer MLP with 64 units in each layer, while the inner NIF is a two layer MLP with 48 units in each layer, I am just trying to get my head around how the training data is generated and from what sources,  to set up this training problem. I should be able to code this up once I figure out the training data.</li>
<li>You mentioned something about another project - "slam-based object reconstruction using ray tracing", Can you point me to any thread or resources to understand this better? I would love to know details about this.</li>
</ol>



<a name="424801041"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/424801041" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#424801041">(Mar 05 2024 at 05:59)</a>:</h4>
<p>It's not really a grid lookup.  It's just a different way to express a vector.  For the neural net, it's less input data and thus less latent space nodes are needed to encode.  It's still just a vector though, a clever optimization.  We even coincidentally have an image depicting both (the vector can point outwards or inwards): <a href="https://brlcad.org/gallery/picture.php?/4">https://brlcad.org/gallery/picture.php?/4</a></p>
<ol>
<li>
<p>The latter. A given model will get "baked" such that a NN is trained, ideally in just a couple minutes,  and then is available+valid for use until the geometry changes.</p>
</li>
<li>
<p>The training data should come directly from the ray tracer (either in advance or streamed real-time).  Imagine shooting a million rays at an object from it's bounding sphere, some hit, some miss.  Each hit is not just the first hit but all the possible hits along the path.  That's the training corpus.  Rays input, hit list output.  We can probably shoot rays faster than the net can train an epoch, so you'd probably want to just stream rays as fast as it can train.  Alternatively, shoot a million, train, shoot another million, train, etc.<br>
<a href="/user_uploads/1549/NkXAc6hfckCsEFq5EfLJEnb0/rppvalidation_dirs.png">rppvalidation_dirs.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/NkXAc6hfckCsEFq5EfLJEnb0/rppvalidation_dirs.png" title="rppvalidation_dirs.png"><img src="/user_uploads/1549/NkXAc6hfckCsEFq5EfLJEnb0/rppvalidation_dirs.png"></a></div></li>
<li>
<p>there's no threads on the topic.  general idea though would be to propose something CAD-related involving slam like making a portable 3D CAD scanner app. e.g., try to output CAD instead of just point clouds or meshes.  maybe hook into iphone lidar sensor.   could also be slam and point cloud based, but then imports into BRL-CAD on the fly for processing.  lots of possibilities.</p>
</li>
</ol>
<p>You'd have to really make a strong case for your project regardless.  Needs to have a compelling benefit that ties into CAD specifically, not just 3D or vision or graphics-related.</p>



<a name="425358037"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/425358037" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Senthil Palanisamy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#425358037">(Mar 07 2024 at 17:26)</a>:</h4>
<p>Thanks for the clarification. I went back and spent more time. I think I am getting closer to the true understanding. Its funny my understanding about the work keeps getting refined and is probably starting to converge. So it seems like the grid encoding is done on a per object basis - the inputs for both for the outer and inner network, while the networks itself are object agnostic occupancy predictors. So we would end up having two encoded grids (one for outer and one for innter) for each unique object and two network that are sort of object agnostic, but acts on any given object to predict occupancy. </p>
<p>In order to accomplish this, I would need to modify the ray tracing pipeline on our system - record input data - for both outer and inner network and then attempt to train those networks</p>
<p>So my two action items are</p>
<ol>
<li>Modify the existing pipeline to record data</li>
<li>Work on the network that can train on this</li>
</ol>
<p>I think I can do action 2 pretty independently (the networks are simple) but to do 1, I would need some directions on how I can do this. What's the fastest way to get there? Are there any documents /sections of code in our repository that I can go through to better understand how to do this? Also, I will try to setup BRL CAD (<a href="https://github.com/BRL-CAD/brlcad">https://github.com/BRL-CAD/brlcad</a>) in the first place, which I will get started with</p>
<p>I know we are interested in the core hypothesis of - is this fast enough? If there is a way to get this data, without having to collect it ourselves (may be any opensource datasets that can be directly plugged in), if any such options exist, the core hypothesis on speed can be validated quicker? Any thoughts on this</p>



<a name="429793730"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/429793730" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#429793730">(Mar 27 2024 at 06:42)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> and others, I have uploaded information and materials relevant to the neural rendering project to <a href="https://brlcad.org/design/neural">https://brlcad.org/design/neural</a></p>



<a name="430048328"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430048328" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430048328">(Mar 28 2024 at 11:41)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> I looked over your proposal update and it looks really pretty good.  I like that you identified some potential errors in the tamu team's approach.   I think overall you have a good plan. </p>
<p>That said, I think you could make your proposal even better by more clearly identifying what the results of your project will be exactly.  I love that you dedicated time to writing up results -- it's reasonable to spend time getting a paper out of this work given the nature of the work.  In additional to a technical paper, though, what precisely will be the resulting products of your work in addition to things learned, which will be documented and which you underscored in your writeup.</p>



<a name="430048607"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430048607" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430048607">(Mar 28 2024 at 11:43)</a>:</h4>
<p>Is the goal to implement a non-grid sampling method, train on that, and demonstrate the efficacy of using that method with "rt" or something similar?  The tamu team resorted to a fixed view silhouette rendering via "rt" as their output target given they couldn't fully achieve generalization to 3D.</p>



<a name="430048840"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430048840" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430048840">(Mar 28 2024 at 11:45)</a>:</h4>
<p>You mention nerf and potentially using different networks -- could definitely write more on what you mean there.  I do suspect that the simple 2-layer FCN is inadequate for full generalization, but AMD's results certainly suggest otherwise may be possible.</p>



<a name="430050286"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430050286" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430050286">(Mar 28 2024 at 11:52)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Thank you for reading. Essentially, the goal is to achieve generalization, so we will try an approach aimed at improving the bounding box approach. However, even by adding this, I suspect that the neural network implemented by the students may not be sufficient to ensure good generalization for any view and thus for any arbitrary ray. For this reason, I believe (but it needs to be verified after obtaining the results of the first part) that it is reasonable to consider modifying the neural network with others more powerful to encode more information about the geometry of the 3D object. In any case, I will provide a better explanation in the proposal. Thank you.</p>



<a name="430050760"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430050760" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430050760">(Mar 28 2024 at 11:54)</a>:</h4>
<p>An approach I think would be considerably more effective is generating training data based on spherical sampling.  That in practice does a very good job to sample the volume unbiased and converges through potential shotlines.  It's pretty simple to generate -- I just did that in our new "rtsurf" application.</p>



<a name="430050913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430050913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430050913">(Mar 28 2024 at 11:55)</a>:</h4>
<p>Ends up looking a bit like this:<br>
<a href="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png">rppvalidation_dirs.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png" title="rppvalidation_dirs.png"><img src="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png"></a></div>



<a name="430051414"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430051414" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430051414">(Mar 28 2024 at 11:58)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/430050913">ha scritto</a>:</p>
<blockquote>
<p>Ends up looking a bit like this:<br>
<a href="/user_uploads/1549/ksk6tkZoPOh8aEOEwT9AtASh/rppvalidation_dirs.png">rppvalidation_dirs.png</a></p>
</blockquote>
<p>yes i think it's the same of the bounding box approach used by tamu students or am I wrong?<br>
<a href="/user_uploads/1549/r0S--pVCJ3nqBeJL1barFFe6/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/r0S--pVCJ3nqBeJL1barFFe6/image.png" title="image.png"><img src="/user_uploads/1549/r0S--pVCJ3nqBeJL1barFFe6/image.png"></a></div>



<a name="430051517"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430051517" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430051517">(Mar 28 2024 at 11:58)</a>:</h4>
<p>I don't know why they call it bounding box even though it seems more like a sphere.</p>



<a name="430052785"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430052785" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430052785">(Mar 28 2024 at 12:04)</a>:</h4>
<p>So it seems that Tamu students have previously employed this method to generate training data, but encountered issues with its generalization. I believe that the neural network might be lacking in its ability to extract all pertinent information from the geometry.</p>



<a name="430053474"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430053474" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430053474">(Mar 28 2024 at 12:07)</a>:</h4>
<p>I have not looked into their code to see whether they're actually evaluating the bounding box or bounding sphere, but I do recall them saying all rays sample through the origin so it's not an unbiased sampling regardless.</p>



<a name="430053747"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430053747" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430053747">(Mar 28 2024 at 12:08)</a>:</h4>
<p>that image there could also simply be hits on a sphere in a bounding box, heh.  would have to double check that as well.</p>



<a name="430054563"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430054563" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430054563">(Mar 28 2024 at 12:13)</a>:</h4>
<p>That is, I believe they were sampling the geometry like this:  <a href="/user_uploads/1549/TLh7Bb0AEw2wdPF0pP9pUy4x/samples.png">samples.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/TLh7Bb0AEw2wdPF0pP9pUy4x/samples.png" title="samples.png"><img src="/user_uploads/1549/TLh7Bb0AEw2wdPF0pP9pUy4x/samples.png"></a></div><p>The general assumption being they were sampling and trying to reconstruct simple shapes like a box, sphere, torus, etc.</p>



<a name="430054708"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430054708" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430054708">(Mar 28 2024 at 12:14)</a>:</h4>
<p>i.e., <a href="/user_uploads/1549/pMsyrJjZ86LIxqmXAVd5-uwW/box.png">box.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/pMsyrJjZ86LIxqmXAVd5-uwW/box.png" title="box.png"><img src="/user_uploads/1549/pMsyrJjZ86LIxqmXAVd5-uwW/box.png"></a></div>



<a name="430077955"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430077955" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430077955">(Mar 28 2024 at 14:19)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> you were right. I studied better what they did as sampling methods and it seems they used these two approaches: one is a grid approach (and ok we all agree it can't be used for generalization), the second is a mixed bounding box exactly like you said (ray origins were selected from a bounding sphere around the geometry, as well as from within the bounding sphere itself). <br>
But there was another approach they never tested, the "pure" bounding sphere approach: this<br>
method find a random point at radius distance away from the center of the geometry. This would serve as the ray origin. Then, it would find a different, random point at radius distance away from the origin. It would then determine the direction between the two points to determine the direction vector of the ray. It's pretty clear that this is the approach you suggested.<br>
This morning I had understood that they had used this latest approach (so I assumed that neither with this sampling they could generalize), but I was wrong. So, this changes everything because there might not be a need to implement any more sophisticated neural network (but it all depends on the results we will have on thanks to this different spherical sampling).</p>



<a name="430087784"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/430087784" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#430087784">(Mar 28 2024 at 15:00)</a>:</h4>
<p><span class="user-mention" data-user-id="102939">@Daniel Rossberg</span> I have updated my proposal and submitted it. I am looking forward for hearing from you. <br>
Thanks</p>



<a name="440303717"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/440303717" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#440303717">(May 23 2024 at 11:36)</a>:</h4>
<p>While looking through previous work(<a href="https://brlcad.org/design/neural/">https://brlcad.org/design/neural/</a>), I noticed this <a href="https://colab.research.google.com/drive/1WtY_IdgLojdbwzfachHtpOIim7n1XPbg?usp=sharing#scrollTo=jLLlkJfDP-tN">file</a> to what looks like a python version of the NIF implementation. Perhaps I could start by converting this job to a C++ version?Then in the meantime, I'll try to optimize it.</p>



<a name="440312021"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/440312021" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#440312021">(May 23 2024 at 12:28)</a>:</h4>
<p>(deleted)</p>



<a name="443607575"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/443607575" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#443607575">(Jun 09 2024 at 15:34)</a>:</h4>
<p>I have some thoughts on why AMD chose a simple neural network. Recently, while deploying a Transformer model, I found that when there are too many parameters, the model's speed also noticeably decreases. Therefore, overly complex neural networks may sacrifice some efficiency.</p>



<a name="444221101"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/444221101" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#444221101">(Jun 12 2024 at 12:22)</a>:</h4>
<p>I have a question about '''rt_shootray()".  When calling <code>rt</code> with default parameters, does it call <code>rt_shootray</code> only once for each pixel to calculate the RGB value, and does it not use the Monte Carlo algorithm at all during the process?</p>



<a name="444265054"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/444265054" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#444265054">(Jun 12 2024 at 15:27)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/443607575">said</a>:</p>
<blockquote>
<p>I have some thoughts on why AMD chose a simple neural network. Recently, while deploying a Transformer model, I found that when there are too many parameters, the model's speed also noticeably decreases. Therefore, overly complex neural networks may sacrifice some efficiency.</p>
</blockquote>
<p>Yes, and I mentioned something to that effect -- it was absolutely made that simple in order to achieve their realtime performance goal.  What's still particularly amazing though is that it achieved such precise matching output on such a complex scene with so few parameters.</p>



<a name="444266014"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/444266014" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#444266014">(Jun 12 2024 at 15:31)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/444221101">said</a>:</p>
<blockquote>
<p>I have a question about '''rt_shootray()".  When calling <code>rt</code> with default parameters, does it call <code>rt_shootray</code> only once for each pixel to calculate the RGB value, and does it not use the Monte Carlo algorithm at all during the process?</p>
</blockquote>
<p>It will call rt_shootray one for each primary ray -- which typically results in secondary rays as well for reflection, specular, light/shadow samples, etc.  Rt is not a montecarlo renderer, but there are options like -H for hypersampling where there will be multiple samples per pixel.  There are also different lighting modes and different renderers that employ different methods.  For example -l7 uses photon mapping and the 'art' ray tracer is a PBR renderer based on appleseed.</p>



<a name="445278798"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445278798" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445278798">(Jun 18 2024 at 06:14)</a>:</h4>
<p>After the rendering is complete, I want to plot some sampling points. I think I should operate on this object. Is there any related function?</p>
<div class="codehilite" data-code-language="C++"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">fb</span><span class="w"> </span><span class="o">*</span><span class="n">fbp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">FB_NULL</span><span class="p">;</span><span class="w"> </span><span class="cm">/* Framebuffer handle */</span>
</code></pre></div>



<a name="445459785"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445459785" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445459785">(Jun 18 2024 at 20:56)</a>:</h4>
<p>If rendering is complete do you mean 2d plotting over the image??  Or are you wanting to plot 3D points and render them as well?</p>



<a name="445460135"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445460135" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445460135">(Jun 18 2024 at 20:58)</a>:</h4>
<p>If you’re just wanting to visualize some diagnostic info for debugging, you can make geometry (eg point cloud or spheres) and view that in mged or with rt, you can plot to 3D with annotation points, you could manually project 3D points to 2d and draw them</p>



<a name="445495215"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/445495215" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#445495215">(Jun 19 2024 at 02:19)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/445460135">said</a>:</p>
<blockquote>
<p>If you’re just wanting to visualize some diagnostic info for debugging, you can make geometry (eg point cloud or spheres) and view that in mged or with rt, you can plot to 3D with annotation points, you could manually project 3D points to 2d and draw them</p>
</blockquote>
<p>Sorry for not being clear. I just want to visualize these points, and I will try to plot them in a 3D view.</p>



<a name="446189703"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446189703" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Erik <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446189703">(Jun 21 2024 at 22:54)</a>:</h4>
<p>Happy Friday! did you figure out how to plot the points? Is there enough progress for a little show&amp;tell?</p>



<a name="446367597"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446367597" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446367597">(Jun 23 2024 at 04:37)</a>:</h4>
<p><span class="user-mention silent" data-user-id="103542">Erik</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/446189703">said</a>:</p>
<blockquote>
<p>Happy Friday! did you figure out how to plot the points? Is there enough progress for a little show&amp;tell?</p>
</blockquote>
<p>I'm sorry for the late reply. I completed the drawing in a strange way...</p>



<a name="446367611"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446367611" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446367611">(Jun 23 2024 at 04:37)</a>:</h4>
<p>I do have some results to report, and I would like to know if my direction is correct. Is next Wednesday or Thursday okay?</p>



<a name="446797805"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446797805" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446797805">(Jun 25 2024 at 07:22)</a>:</h4>
<p>where is the center of model bounding sphere?</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>0.5</mn><mo stretchy="false">(</mo><mi>m</mi><mi>d</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>m</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>m</mi><mi>d</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">?</mo></mrow><annotation encoding="application/x-tex">0.5(mdl\_min+mdl\_max)?</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord">0.5</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">min</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mclose">)?</span></span></span></span></span></p>
<div class="codehilite"><pre><span></span><code>struct rt_i{
...
/* THESE ITEMS ARE AVAILABLE FOR APPLICATIONS TO READ */
point_t             mdl_min;        /**&lt; @brief  min corner of model bounding RPP */
point_t             mdl_max;        /**&lt; @brief  max corner of model bounding RPP */
point_t             rti_pmin;       /**&lt; @brief  for plotting, min RPP */
point_t             rti_pmax;       /**&lt; @brief  for plotting, max RPP */
double              rti_radius;     /**&lt; @brief  radius of model bounding sphere */
struct db_i *       rti_dbip;       /**&lt; @brief  prt to Database instance struct */
</code></pre></div>



<a name="446798094"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446798094" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446798094">(Jun 25 2024 at 07:24)</a>:</h4>
<p>And please let me know when will you're available to meet. I will be free after Tuesday.</p>



<a name="446895409"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/446895409" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#446895409">(Jun 25 2024 at 14:09)</a>:</h4>
<p>I have finished a few sample methods , this is uniform sphere sample:<br>
<a href="/user_uploads/1549/PRn-rHvwlNCdeXaXjWHdCpfu/sample.png">sample.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/PRn-rHvwlNCdeXaXjWHdCpfu/sample.png" title="sample.png"><img src="/user_uploads/1549/PRn-rHvwlNCdeXaXjWHdCpfu/sample.png"></a></div>



<a name="447031678"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447031678" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Erik <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447031678">(Jun 26 2024 at 00:52)</a>:</h4>
<p>I can make time on Wednesday, or on Thursday until 1630EDT, or Friday after 0830EDT. But I think Sean is more aware of what's going on and it'd be more valuable to have him present? <br>
the center of the bounding sphere is the same as the bounding box, um, I think the AABB is used more than the sphere. iirc, when I did the metaball primitive, I did a bounding box, then just said the bounding sphere was the same center and had  a radius equal to the distance from  a corner of the bounding box to the center?</p>



<a name="447103961"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447103961" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447103961">(Jun 26 2024 at 04:16)</a>:</h4>
<p>Okay, I'll ask Sean when he's available.</p>
<p><span class="user-mention silent" data-user-id="103542">Erik</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/447031678">said</a>:</p>
<blockquote>
<p>I can make time on Wednesday, or on Thursday until 1630EDT, or Friday after 0830EDT. But I think Sean is more aware of what's going on and it'd be more valuable to have him present? <br>
the center of the bounding sphere is the same as the bounding box, um, I think the AABB is used more than the sphere. iirc, when I did the metaball primitive, I did a bounding box, then just said the bounding sphere was the same center and had  a radius equal to the distance from  a corner of the bounding box to the center?</p>
</blockquote>



<a name="447164652"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447164652" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447164652">(Jun 26 2024 at 09:15)</a>:</h4>
<p>There looks to be a small error in rt/worker.c:  there is no need to statistic <strong> colorsum </strong> for normal sample, just do it in hyper sample</p>
<div class="codehilite" data-code-language="C"><pre><span></span><code><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hypersample</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="p">...</span>
<span class="n">VADD2</span><span class="p">(</span><span class="n">colorsum</span><span class="p">,</span><span class="w"> </span><span class="n">colorsum</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">a_color</span><span class="p">);</span>

<span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="cm">/* hypersampling, so iterate */</span>
</code></pre></div>



<a name="447193979"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447193979" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Vidit Jain <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447193979">(Jun 26 2024 at 11:37)</a>:</h4>
<p><span class="user-mention" data-user-id="102939">@Daniel Rossberg</span>  <span class="user-mention" data-user-id="252475">@Himanshu</span>  I have created a new pull request addressing the selectPrimitive feature's bug <a href="https://github.com/BRL-CAD/arbalest/pull/51">here</a></p>



<a name="447396149"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/447396149" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#447396149">(Jun 27 2024 at 06:26)</a>:</h4>
<p><span class="user-mention" data-user-id="103542">@Erik</span> Is June 28 11.30(EDT) OK for you?</p>



<a name="448092373"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448092373" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448092373">(Jun 30 2024 at 09:14)</a>:</h4>
<p>I finished the whole process of neural network rendering and generated a not-so-good rgb map：<br>
<a href="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png">render.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png" title="render.png"><img src="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png"></a></div>



<a name="448099591"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448099591" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448099591">(Jun 30 2024 at 10:18)</a>:</h4>
<p>why the direction of ray keep const when rendering? According to ray tracing algorithm, each ray should have a different direction: <br>
<a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png">RaysViewportSchema.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png" title="RaysViewportSchema.png"><img src="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png"></a></div>



<a name="448123324"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448123324" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448123324">(Jun 30 2024 at 14:46)</a>:</h4>
<p>Is there a function to calculate the intersection of a ray and a sphere?</p>



<a name="448222663"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448222663" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448222663">(Jul 01 2024 at 05:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448099591">said</a>:</p>
<blockquote>
<p>why the direction of ray keep const when rendering? According to ray tracing algorithm, each ray should have a different direction: <br>
<a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png">RaysViewportSchema.png</a></p>
</blockquote>
<p>I get it , the default is to use parallel projection</p>



<a name="448341781"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448341781" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448341781">(Jul 01 2024 at 14:01)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448123324">said</a>:</p>
<blockquote>
<p>Is there a function to calculate the intersection of a ray and a sphere?</p>
</blockquote>
<p>I implemented the algorithm myself</p>



<a name="448846756"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448846756" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448846756">(Jul 03 2024 at 13:15)</a>:</h4>
<p>I found an interesting parper:NeRF: Representing Scenes as  Neural Radiance Fields for View Synthesis(<a href="https://dl.acm.org/doi/abs/10.1145/3503250">https://dl.acm.org/doi/abs/10.1145/3503250</a>)</p>



<a name="448853370"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448853370" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448853370">(Jul 03 2024 at 13:41)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448846756">ha scritto</a>:</p>
<blockquote>
<p>I found an interesting parper:NeRF: Representing Scenes as  Neural Radiance Fields for View Synthesis(<a href="https://dl.acm.org/doi/abs/10.1145/3503250">https://dl.acm.org/doi/abs/10.1145/3503250</a>)</p>
</blockquote>
<p>Why do you think it is interesting?</p>



<a name="448863224"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448863224" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448863224">(Jul 03 2024 at 14:24)</a>:</h4>
<p>The Positional encoding,  according to Rahaman's work <a href="https://arxiv.org/abs/1806.08734">On the Spectral Bias of Neural Networks</a>, deep networks are biased towards learning lower frequency functions. They use positional encoding methods to solve this problem.</p>



<a name="448900107"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448900107" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448900107">(Jul 03 2024 at 16:38)</a>:</h4>
<p><a href="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg">IMG_1921.jpeg</a><br>
this is the ground truth</p>
<div class="message_inline_image"><a href="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg" title="IMG_1921.jpeg"><img src="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg"></a></div>



<a name="448900278"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448900278" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448900278">(Jul 03 2024 at 16:39)</a>:</h4>
<p><a href="/user_uploads/1549/uMhAaXGt-u3MRQyJvV2NV3H4/IMG_1922.jpeg">IMG_1922.jpeg</a><br>
And this is with neural network prediction (bounding box). There are some issues to resolve</p>
<div class="message_inline_image"><a href="/user_uploads/1549/uMhAaXGt-u3MRQyJvV2NV3H4/IMG_1922.jpeg" title="IMG_1922.jpeg"><img src="/user_uploads/1549/uMhAaXGt-u3MRQyJvV2NV3H4/IMG_1922.jpeg"></a></div>



<a name="448900529"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448900529" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448900529">(Jul 03 2024 at 16:41)</a>:</h4>
<p>Probably they are mainly with rendering and not with the NN itself</p>



<a name="448901952"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/448901952" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#448901952">(Jul 03 2024 at 16:49)</a>:</h4>
<p>Or maybe the number of samples in the dataset are too low.</p>



<a name="449297977"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449297977" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449297977">(Jul 05 2024 at 12:09)</a>:</h4>
<p>I solved the issue with the rendering and got improvements</p>



<a name="449297987"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449297987" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449297987">(Jul 05 2024 at 12:09)</a>:</h4>
<p><a href="/user_uploads/1549/adq2ZvACbgm9ME6bkj2zezyB/IMG_1929.jpeg">IMG_1929.jpeg</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/adq2ZvACbgm9ME6bkj2zezyB/IMG_1929.jpeg" title="IMG_1929.jpeg"><img src="/user_uploads/1549/adq2ZvACbgm9ME6bkj2zezyB/IMG_1929.jpeg"></a></div>



<a name="449298375"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449298375" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449298375">(Jul 05 2024 at 12:10)</a>:</h4>
<p>With n=100'000 rays I got 0.94% of accuracy which is not bad but the major problem is that with bounding sphere approach we need to sample a lot of rays in order to achieve a good accuracy for every angle of the camera.</p>



<a name="449298872"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449298872" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449298872">(Jul 05 2024 at 12:13)</a>:</h4>
<p>The problem isn't with the Neural Network because I have a 0.99 accuracy with Training Set, but since we have an infinite number of rays that goes in all the directions in the bounding sphere, I think it is not possible to achieve the same results with the rendering without changing something because otherwise we need to sample an infinite number of rays to give to the NN (and of course it is not possible).</p>



<a name="449299212"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449299212" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449299212">(Jul 05 2024 at 12:15)</a>:</h4>
<p>So we must be smarter than this and try to change representations of the input features or trying different architectures of NN</p>



<a name="449299318"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449299318" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449299318">(Jul 05 2024 at 12:16)</a>:</h4>
<p>But first I want to try with n=1 million samples to see how good are the performances.</p>



<a name="449299951"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449299951" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449299951">(Jul 05 2024 at 12:20)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448900107">ha scritto</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/P9drWOCeKtYxqLMuDm4nnvp7/IMG_1921.jpeg">IMG_1921.jpeg</a><br>
this is the ground truth</p>
</blockquote>
<p>Remember that this is the ground truth.</p>



<a name="449318723"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449318723" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449318723">(Jul 05 2024 at 13:55)</a>:</h4>
<p><a href="/user_uploads/1549/r-ScLIaNys2JvMxwkVH66F9J/IMG_1930.jpeg">IMG_1930.jpeg</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/r-ScLIaNys2JvMxwkVH66F9J/IMG_1930.jpeg" title="IMG_1930.jpeg"><img src="/user_uploads/1549/r-ScLIaNys2JvMxwkVH66F9J/IMG_1930.jpeg"></a></div>



<a name="449318885"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449318885" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449318885">(Jul 05 2024 at 13:56)</a>:</h4>
<p>This is with 1 million rays, I got the best epoch with 0.986 % of accuracy. We are on the right path :)</p>



<a name="449330639"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449330639" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449330639">(Jul 05 2024 at 14:58)</a>:</h4>
<p>I use a deep resnet to learn rgb value. The left is the result of neural rendering and the right is normal rendering<br>
<a href="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png">res_net.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png" title="res_net.png"><img src="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png"></a></div>



<a name="449330816"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449330816" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449330816">(Jul 05 2024 at 14:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449330639">ha scritto</a>:</p>
<blockquote>
<p>I use a deep resnet to learn rgb value. The left is the result of neural rendering and the right is normal rendering<br>
<a href="/user_uploads/1549/uf9jPQ3xnxGHfn2dY-EsoxuB/微信图片_20240705225713.png">res_net.png</a></p>
</blockquote>
<p>Which sampling approach have you used?</p>



<a name="449331053"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331053" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331053">(Jul 05 2024 at 15:00)</a>:</h4>
<p>Random sample, with 1million rays which have the same direction and hit the bounding sphere</p>



<a name="449331190"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331190" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331190">(Jul 05 2024 at 15:01)</a>:</h4>
<p>I want to improve network first and then sample method</p>



<a name="449331352"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331352" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331352">(Jul 05 2024 at 15:02)</a>:</h4>
<p>Mh ok so it cannot be generalized with every angle at the moment... Predicting rgb is much more difficult, I see...</p>



<a name="449331376"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331376" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331376">(Jul 05 2024 at 15:02)</a>:</h4>
<p>The current network fits a continuous function, but the objective function is not actually continuous..</p>



<a name="449331502"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449331502" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449331502">(Jul 05 2024 at 15:02)</a>:</h4>
<p>We need a new structure...</p>



<a name="449333208"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449333208" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449333208">(Jul 05 2024 at 15:10)</a>:</h4>
<p>I don't know if it can improve the results, but have you tried giving to the network only the rays that hit the  object and not all the rays?<br>
This can be done because first we predict with "my" network if it has hitted or not, so "your" network should predict only the ones that hit the object</p>



<a name="449333774"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449333774" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449333774">(Jul 05 2024 at 15:13)</a>:</h4>
<p>This a direction. I will try it later</p>



<a name="449333873"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449333873" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449333873">(Jul 05 2024 at 15:13)</a>:</h4>
<p>Can you tell which object you've hit?</p>



<a name="449334154"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449334154" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449334154">(Jul 05 2024 at 15:15)</a>:</h4>
<p>This would be very helpful to me, maybe I could train two networks</p>



<a name="449335156"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449335156" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449335156">(Jul 05 2024 at 15:19)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449333873">ha scritto</a>:</p>
<blockquote>
<p>Can you tell which object you've hit?</p>
</blockquote>
<p>Regarding this, we must decide if we have to train one network for each object or not... I think  deciding all this in a meeting would be more appropriate.</p>



<a name="449335299"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449335299" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449335299">(Jul 05 2024 at 15:20)</a>:</h4>
<p>OK, let's decide this later</p>



<a name="449613007"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449613007" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449613007">(Jul 07 2024 at 06:42)</a>:</h4>
<p>I got a great result with gridnet:<br>
<a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png">grid_methos</a><br>
here is the loss:<br>
<a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png">loss</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png" title="grid_methos"><img src="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png" title="loss"><img src="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png"></a></div>



<a name="449614206"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449614206" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449614206">(Jul 07 2024 at 06:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449613007">ha scritto</a>:</p>
<blockquote>
<p>I got a great result with gridnet:<br>
<a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png">grid_methos</a><br>
here is the loss:<br>
<a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png">loss</a></p>
</blockquote>
<p>Very good. This is grid + resnet?</p>



<a name="449615980"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449615980" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449615980">(Jul 07 2024 at 07:24)</a>:</h4>
<p>Just grid net. I will add resnet later.</p>



<a name="449616299"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449616299" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449616299">(Jul 07 2024 at 07:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449615980">ha scritto</a>:</p>
<blockquote>
<p>Just grid net. I will add resnet later.</p>
</blockquote>
<p>What is the mean absolute error?I think it would be easier to understand how good is this model.</p>



<a name="449616407"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449616407" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449616407">(Jul 07 2024 at 07:30)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/449613007">ha scritto</a>:</p>
<blockquote>
<p>I got a great result with gridnet:<br>
<a href="/user_uploads/1549/K98ISdwSDeqXntg_Hov3rESp/微信图片_20240707144043.png">grid_methos</a><br>
here is the loss:<br>
<a href="/user_uploads/1549/tOkJMFHecvWhXo_DsJ_0DK9m/微信图片_20240707144141.png">loss</a></p>
</blockquote>
<p>And why do you think  there are those white dots (noise) ?</p>



<a name="449616444"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449616444" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449616444">(Jul 07 2024 at 07:31)</a>:</h4>
<p>Anyway, seeing your results, I think I will also add this grid method, I think it would improve my network too.</p>



<a name="449825650"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449825650" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449825650">(Jul 08 2024 at 10:03)</a>:</h4>
<p>I tried with grid encoding but my network does not seem to improve any further. I will try different sampling approach.</p>



<a name="449828956"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449828956" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449828956">(Jul 08 2024 at 10:21)</a>:</h4>
<p>I think that grid encoding is appropriate only when the direction of the rays is fixed, because if you divide your sphere in 256*256 = 65536 cells, then each cell will have an average number of 15 rays to be trained (if your training set has 1 million rays). The problem is that if your direction is fixed, then 15 rays for each cell can be acceptable but if the direction isn't fixed, then 15 is a very small number of rays to train.<br>
I tried also with a different size of grid (20x20, 50x50, 100x100) and the NN performs like before more or less (98% accuracy with 20x20).<br>
I also implemented different grid versions  in the same NN (20x20, 50x50, 100x100, 256x256) and combined them together with some weights, but I got the same results...<br>
So this makes me think that grid encoding isn't appropriate when rays are not fixed.</p>



<a name="449937826"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449937826" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449937826">(Jul 08 2024 at 17:38)</a>:</h4>
<p>Today I improved results to 0.991 (test set) using a different optimizer.</p>



<a name="449953919"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449953919" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449953919">(Jul 08 2024 at 18:49)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448099591">said</a>:</p>
<blockquote>
<p>why the direction of ray keep const when rendering? According to ray tracing algorithm, each ray should have a different direction: <br>
<a href="/user_uploads/1549/dD6UbTaZBMD1b4ynfeUIJh9m/RaysViewportSchema.png">RaysViewportSchema.png</a></p>
</blockquote>
<p>There are two different kinds of cameras -- perspective and orthogonal.  Orthogonal is default for most engineering purposes and perspective is what you want for visualizations approximating human vision.  Perspective rays (typically) diverge.  Ortho are parallel grids. </p>
<p>For volumetric encoding, you almost certainly will want ortho or unbiased random.</p>



<a name="449954153"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/449954153" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#449954153">(Jul 08 2024 at 18:50)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/448092373">said</a>:</p>
<blockquote>
<p>I finished the whole process of neural network rendering and generated a not-so-good rgb map：<br>
<a href="/user_uploads/1549/C7uS7O5qsj76boNEH3OoxFjU/render.png">render.png</a></p>
</blockquote>
<p>That's actually not "terrible".  Not great but not terrible to say the least.  It's clearly recognizable.</p>



<a name="450216289"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450216289" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450216289">(Jul 09 2024 at 16:18)</a>:</h4>
<p>I also use a 4-Dimensions network to train, the inputs are both direction and position:<br>
<a href="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png">net.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png" title="net.png"><img src="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png"></a></div>



<a name="450457252"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450457252" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450457252">(Jul 10 2024 at 13:46)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450216289">said</a>:</p>
<blockquote>
<p>I also use a 4-Dimensions network to train, the inputs are both direction and position:<br>
<a href="/user_uploads/1549/3-6KdipvOSsCxWHiqXExe85L/net.png">net.png</a></p>
</blockquote>
<p>That's clearly "seeing" the model in some sense, even getting some of the surfacing right but in a dream state.  How many training epochs is that?</p>
<p>One thing you could try is to reduce the input dimensionality to just azimuth and elevation (2 floats).  That's a much smaller space to optimize across and will result in the same centered visual for our current purposes.</p>



<a name="450458097"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450458097" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450458097">(Jul 10 2024 at 13:50)</a>:</h4>
<p>Oh, I have convert both direction and position to azimuth and elevation, so there are just four float inputs. It takes me one hour to train(with a 4060 GPU)</p>



<a name="450458373"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450458373" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450458373">(Jul 10 2024 at 13:52)</a>:</h4>
<p>I use a grid which has a shape of 128<em>128</em>64*64 to train.  That's the maximum number of ginsengs my GPU can handle.</p>



<a name="450458592"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450458592" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450458592">(Jul 10 2024 at 13:53)</a>:</h4>
<p>I noticed this paper: <a href="https://arxiv.org/pdf/2003.08934">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a>, they used a A100 to train and it costs more than two days.</p>



<a name="450459161"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450459161" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450459161">(Jul 10 2024 at 13:55)</a>:</h4>
<p>I'm trying to improve my net from the sampling methodology. Since I know more about active learning, I might train another network for sampling</p>



<a name="450469913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450469913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450469913">(Jul 10 2024 at 14:33)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450458592">ha scritto</a>:</p>
<blockquote>
<p>I noticed this paper: <a href="https://arxiv.org/pdf/2003.08934">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a>, they used a A100 to train and it costs more than two days.</p>
</blockquote>
<p>Yeah, this paper and its related works are the state of the art about neural rendering.</p>



<a name="450806288"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450806288" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450806288">(Jul 11 2024 at 20:31)</a>:</h4>
<p>Close to state of the art -- I listened to that paper when it came out back in 2020.  There's been a lot of work on NeRFs since then and a lot of advancements.  That's still a rather different approach altogether that thus far hasn't generalized very well.  That's why the newer AMD research is more the basis for this work.</p>



<a name="450810201"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450810201" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450810201">(Jul 11 2024 at 20:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450806288">ha scritto</a>:</p>
<blockquote>
<p>Close to state of the art -- I listened to that paper when it came out back in 2020.  There's been a lot of work on NeRFs since then and a lot of advancements.  That's still a rather different approach altogether that thus far hasn't generalized very well.  That's why the newer AMD research is more the basis for this work.</p>
</blockquote>
<p>Do you know why was there a need to try a different approach rather than NeRFs?</p>



<a name="450812109"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450812109" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450812109">(Jul 11 2024 at 21:13)</a>:</h4>
<p>Well fundamentally, nerfs are based on trying to obtain output visualizations of a 3D object based on just having some 2D view points (pictures).  They only use the 3D in the test and evaluation phase, but the model is generally unknown or non-existent.</p>



<a name="450812416"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450812416" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450812416">(Jul 11 2024 at 21:15)</a>:</h4>
<p>We have the 3D models.  They aren't the unknown in our case.  Our situation is really needing to know precisely where the 3D object is for given (unknown) view points.  That's where the optimization and needs are a bit different.  It's more about encoding and/or estimating a given model from the known model, but sufficiently abstracted that we can get accurate queries really fast.</p>



<a name="450812801"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450812801" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450812801">(Jul 11 2024 at 21:17)</a>:</h4>
<p>We could certainly build up and train a NeRF by feeding it a set of renderings for the 3D model, to see if it can generalize it well enough, but every approach I've seen thus far is about achieving optically adequate results, not necessarily something that would pass any fidelity comparison with the ground truth 3D model.</p>



<a name="450815937"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/450815937" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#450815937">(Jul 11 2024 at 21:32)</a>:</h4>
<p>Ok, understood. However, I believe that AMD research still lacks comprehensive volumetric information about 3D models, preventing the NN from predicting rays hit/miss with 100% precision if we wanna achieve full generalization. Perhaps we can draw inspiration from NeRF and its related works. I plan to update my work on GitHub tomorrow so that you can review and test what I have done so far.</p>



<a name="451038141"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451038141" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451038141">(Jul 12 2024 at 17:46)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Here there is the repo <a href="https://github.com/bralani/rt_volume/tree/neural_rendering">https://github.com/bralani/rt_volume/tree/neural_rendering</a>. Please be sure you follow in order these steps:</p>
<p>Installation:</p>
<p>1) Download libtorch from here <a href="https://pytorch.org/">https://pytorch.org/</a> paying attention to build "preview nightly" and remember the version you have installed (debug or release):<br>
<a href="/user_uploads/1549/cs8UI0afE68eGit_YprQNA4b/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/cs8UI0afE68eGit_YprQNA4b/image.png" title="image.png"><img src="/user_uploads/1549/cs8UI0afE68eGit_YprQNA4b/image.png"></a></div><p>2) Unzip the folder and put the libtorch folder wherever you want and then go to src\rt\CMakeLists.txt, line 56 and change these three paths with your libtorch path:<br>
<a href="/user_uploads/1549/lSIfYYz08dyAGMJJlHun7s5K/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/lSIfYYz08dyAGMJJlHun7s5K/image.png" title="image.png"><img src="/user_uploads/1549/lSIfYYz08dyAGMJJlHun7s5K/image.png"></a></div><p>3) Now be sure to build "rt_trainneural" with "Debug" version if you have installed libtorch "Debug" or with "Release" if you have installed "Release" libtorch.</p>
<p>4) This step is not always required but in my case it was essential otherwise there were some issues in the execution: go to path_libtorch\lib, copy all the files inside this folder and paste these files in the build/bin (where there is the .exe) of brl-cad.</p>
<p>Ok now we can finally run the code with two steps:</p>
<p>Go to rt/train_neural.cpp and see these options:<br>
<a href="/user_uploads/1549/Q5q8p-QQUbsZbaIqgTFJUmO_/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/Q5q8p-QQUbsZbaIqgTFJUmO_/image.png" title="image.png"><img src="/user_uploads/1549/Q5q8p-QQUbsZbaIqgTFJUmO_/image.png"></a></div><p>TRAINING:<br>
1)  In the first step we generate the dataset with bounding sphere sampling (so make sure that opts.generate_dataset is true), set your db and obj as you want and set also the num of rays you want to generate (I suggest 1 million). Run the code.<br>
2) You should see a file "train_neural.json" and "test_neural.txt" inside the path you have run the file (build/bin). <br>
3) Go to rt/train.py and set on top your variables:<br>
<a href="/user_uploads/1549/CIY8U07xrP71pBjgOZJvlry5/image.png">image.png</a><br>
4) Run the script, the NN will stop on epoch 200 but on each epoch it validate on test set and if the accuracy of current epoch is higher than all the previous, it overwrites the model "<a href="http://model_sph.pt">model_sph.pt</a>".</p>
<div class="message_inline_image"><a href="/user_uploads/1549/CIY8U07xrP71pBjgOZJvlry5/image.png" title="image.png"><img src="/user_uploads/1549/CIY8U07xrP71pBjgOZJvlry5/image.png"></a></div><p>RENDERING:<br>
1) Go back to rt/train_neural.cpp, set opts.generate_dataset = false, set properly opts.model_path with the path of the model trained, adjust the azimuth and elevation as you wish (to perform render) and then set opts.neural_render=0 if you want the ground truth rendering, otherwise set to 1 if you want to perform your neural rendering. :)</p>



<a name="451039002"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039002" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039002">(Jul 12 2024 at 17:52)</a>:</h4>
<p>I guarantee that it works in Windows, I have not tried with any other OS.</p>



<a name="451039115"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039115" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039115">(Jul 12 2024 at 17:53)</a>:</h4>
<p>I have also a Mac M1 but I have always a lot of errors when I try to build BRL-CAD...</p>



<a name="451039490"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039490" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039490">(Jul 12 2024 at 17:56)</a>:</h4>
<p>Awesome, thank you <span class="user-mention" data-user-id="702819">@Matteo Balice</span> I'll definitely be taking a deeper look at it later today, and see if I can get it up and running.  I'm on M2, so will see if there are issues.</p>



<a name="451039550"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039550" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039550">(Jul 12 2024 at 17:56)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> on Mac, you must enable -DBRLCAD_BUNDLED_LIBS=ON or the build will fail when it tries to use the system Tcl/Tk</p>



<a name="451039559"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039559" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039559">(Jul 12 2024 at 17:56)</a>:</h4>
<p>(during cmake)</p>



<a name="451039634"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039634" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039634">(Jul 12 2024 at 17:57)</a>:</h4>
<p>I already have pytorch installed and a brl-cad build, so should hopefully all just work!</p>



<a name="451039931"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451039931" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451039931">(Jul 12 2024 at 17:59)</a>:</h4>
<p>Ahh ok I will try it now so you don't have any issues tomorrow on your M2. <br>
I have also prepared a small script here that tries to find CUDA if you have a GPU or metal acceleration if you have any "M" series of Mac:<br>
<a href="/user_uploads/1549/RRPOkm_KlCg0rn9SRVTjdThx/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/RRPOkm_KlCg0rn9SRVTjdThx/image.png" title="image.png"><img src="/user_uploads/1549/RRPOkm_KlCg0rn9SRVTjdThx/image.png"></a></div>



<a name="451069638"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451069638" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451069638">(Jul 12 2024 at 20:35)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/450815937">said</a>:</p>
<blockquote>
<p>Ok, understood. However, I believe that AMD research still lacks comprehensive volumetric information about 3D models, preventing the NN from predicting rays hit/miss with 100% precision if we wanna achieve full generalization. Perhaps we can draw inspiration from NeRF and its related works. I plan to update my work on GitHub tomorrow so that you can review and test what I have done so far.</p>
</blockquote>
<p>I'd like to hear more what you meant by this -- encoding comprehensive volumetric information isn't the goal, but some faithful encoding.  A prediction with some general precision assertion (hopefully).  Similar in the text space, we want a reasonably accurate response to an input prompt that is more than vague (blurry) writing. </p>
<p>Issue I have with radiance fields is the method isn't exactly aligned well with our available training data.  We'd literally throw away information to then try to reconstitute it.  The method is really a whole field that's trying to construct 3D where it did not exist previously (i.e., from photos or scans).</p>



<a name="451070030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070030">(Jul 12 2024 at 20:37)</a>:</h4>
<p>From my reading, the AMD research is compelling because it is just a bifurcated training of two networks, one for outside, one for inside/near, and lots of reductions made for the sake of adequate performance.  My thinking is lets increase the network a bit, and see how well it can generalize.</p>



<a name="451070363"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070363" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070363">(Jul 12 2024 at 20:39)</a>:</h4>
<p>On a related note, here's a nice site that summarizes a lot of the neural field papers -- definitely are concepts that are relevant in some of them:  <a href="https://radiancefields.com/siggraph-2024-program-announced">https://radiancefields.com/siggraph-2024-program-announced</a></p>



<a name="451070607"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070607" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070607">(Jul 12 2024 at 20:40)</a>:</h4>
<p>I have already made just a little bit more complex the NN of AMD research and it generalizes very well.</p>



<a name="451070693"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070693" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070693">(Jul 12 2024 at 20:40)</a>:</h4>
<p>This means that for each angle of the object, the NN is able to understand the shape.</p>



<a name="451070780"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070780" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070780">(Jul 12 2024 at 20:41)</a>:</h4>
<p>But the problem is that on the boundaries of the objects, there are still some artifacts (for example the shape is smooth even though it should be sharp from the ground truth). It is not very precise there.</p>



<a name="451070930"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451070930" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451070930">(Jul 12 2024 at 20:42)</a>:</h4>
<p>My idea was to substitute the grid encoding approach they used.</p>



<a name="451071002"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451071002" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451071002">(Jul 12 2024 at 20:42)</a>:</h4>
<p>Because for me, the grid encoding was working only because they trained the NN with fixed directions of the rays. But in our case, the rays can have infinite directions from the same origin.</p>



<a name="451071510"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451071510" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451071510">(Jul 12 2024 at 20:45)</a>:</h4>
<p>If you think about the grid encoding, every ray that hit a specific cell have a very similar origin since the direction is fixed.</p>



<a name="451071594"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451071594" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451071594">(Jul 12 2024 at 20:45)</a>:</h4>
<p>But in our case this is not true.</p>



<a name="451072518"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451072518" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451072518">(Jul 12 2024 at 20:49)</a>:</h4>
<p>I know that encoding volumetric informations are not the final goal, but I believe that the NN is not able to capture very well this details due to the lack of volumetric informations of the model itself. We could use for example an encoding like "voxels" because they are invariant to directions. This is just an idea for the moment, I don't know if it can work.</p>



<a name="451073664"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451073664" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451073664">(Jul 12 2024 at 20:54)</a>:</h4>
<p>I will read some papers in these days about this.</p>



<a name="451121429"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451121429" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451121429">(Jul 13 2024 at 03:57)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span>  That is sort of incorporating some of the concepts of a radiance field (what you're calling a grid encoding), also known as a volumetric encoding.  Your intuition about the direction vectors being fixed does certainly sound plausible.  While the image space was fixed, the rays themselves were scattering in nearly all directions due to the physically based lighting model they were using (lots of reflection rays, refraction rays, light sampling rays, diffuse surface rays, and more).  Still, that is certainly a vast subset for the net to train on, and like I said, you have a reasoned impetus for trying to encode it volumetrically.</p>



<a name="451121613"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451121613" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451121613">(Jul 13 2024 at 03:58)</a>:</h4>
<p>You'd definitely need something more descriptive than voxels unless we go pixar route to sub-pixel resolution, which is not practical (for lots of reasons).</p>



<a name="451121738"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451121738" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451121738">(Jul 13 2024 at 04:00)</a>:</h4>
<p>You'd probably need something more like a vdb signed distance field (sdf) where you have voxel occupancy as well as surface direction vectors.</p>



<a name="451321049"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451321049" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451321049">(Jul 14 2024 at 05:39)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> AMD research doesn't use rays with fixed directions. They encoded both diection and position, then concatenated  them to a vector:<br>
<a href="/user_uploads/1549/WCjqqOJr3v2hz1Y9QF_NlFfM/AMD.png">AMD.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/WCjqqOJr3v2hz1Y9QF_NlFfM/AMD.png" title="AMD.png"><img src="/user_uploads/1549/WCjqqOJr3v2hz1Y9QF_NlFfM/AMD.png"></a></div>



<a name="451321515"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451321515" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451321515">(Jul 14 2024 at 05:48)</a>:</h4>
<p>I think a different strategy could be used for grid coding. Replacing a 2-dimensional network with a 4-dimensional network, this grid coding encodes both positional and directional information in a single vector</p>



<a name="451328162"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328162" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328162">(Jul 14 2024 at 07:02)</a>:</h4>
<p>Maybe I was not so clear. Yes, they encoded both direction and position BUT they trained with a fixed viewpoint:<br>
<a href="/user_uploads/1549/bLA96oXiOSQtHnGE1XcpOlqy/Screenshot-2024-07-14-alle-09.00.20.png">Screenshot-2024-07-14-alle-09.00.20.png</a><br>
This means that all the rays have more or less the same directions each training.<br>
<a href="/user_uploads/1549/-ze6tTd7GIv9w8LNXKteSUXt/Screenshot-2024-07-14-alle-09.01.26.png">Screenshot-2024-07-14-alle-09.01.26.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/bLA96oXiOSQtHnGE1XcpOlqy/Screenshot-2024-07-14-alle-09.00.20.png" title="Screenshot-2024-07-14-alle-09.00.20.png"><img src="/user_uploads/1549/bLA96oXiOSQtHnGE1XcpOlqy/Screenshot-2024-07-14-alle-09.00.20.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/-ze6tTd7GIv9w8LNXKteSUXt/Screenshot-2024-07-14-alle-09.01.26.png" title="Screenshot-2024-07-14-alle-09.01.26.png"><img src="/user_uploads/1549/-ze6tTd7GIv9w8LNXKteSUXt/Screenshot-2024-07-14-alle-09.01.26.png"></a></div><p>This is very different from our goal and I explained why it can not work in our case (from my hypothesis).</p>



<a name="451328614"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328614" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328614">(Jul 14 2024 at 07:06)</a>:</h4>
<p>I got it. Thanks</p>



<a name="451328625"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328625" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328625">(Jul 14 2024 at 07:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451321515">ha scritto</a>:</p>
<blockquote>
<p>I think a different strategy could be used for grid coding. Replacing a 2-dimensional network with a 4-dimensional network, this grid coding encodes both positional and directional information in a single vector</p>
</blockquote>
<p>Can you elaborate more about this?</p>



<a name="451328750"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451328750" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451328750">(Jul 14 2024 at 07:09)</a>:</h4>
<p>I put my codes here:<a href="https://github.com/Rainy-fall-end/Rendernn/blob/main/trainDir.py">trainDir</a>. I use a 128×128×64×64 net to encodes both dir and pos.</p>



<a name="451329160"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329160" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329160">(Jul 14 2024 at 07:15)</a>:</h4>
<p>Mh I cannot quite understand this. Are you using a total of 128x128x64x64=67billions cells?</p>



<a name="451329221"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329221" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329221">(Jul 14 2024 at 07:16)</a>:</h4>
<p>This is quite overfitting because you will get train error 0 since you have less rays than cells.</p>



<a name="451329248"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329248" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329248">(Jul 14 2024 at 07:17)</a>:</h4>
<p>Or am I wrong?</p>



<a name="451329254"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329254" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329254">(Jul 14 2024 at 07:17)</a>:</h4>
<p>Yes... I am trying to improve it.</p>



<a name="451329264"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329264" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329264">(Jul 14 2024 at 07:17)</a>:</h4>
<p>Maybe it can work only if the viewpoint is fixed.</p>



<a name="451329267"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451329267" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451329267">(Jul 14 2024 at 07:17)</a>:</h4>
<p>There are too many parameters</p>



<a name="451365877"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451365877" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451365877">(Jul 14 2024 at 16:17)</a>:</h4>
<p>I've been doing a lot of experimenting with grid net lately, and it's hard for him to predict rays in all directions, which may require a lot of parameters. One of the big problems is that the objective function is non-differentiable</p>



<a name="451366101"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451366101" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451366101">(Jul 14 2024 at 16:20)</a>:</h4>
<p>Instead of using nif directly for rendering, AMD just uses NIF to intersect to speed up the rendering process. The focus is really on intersection, which is effective for rendering complex geometry.</p>



<a name="451366395"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451366395" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451366395">(Jul 14 2024 at 16:25)</a>:</h4>
<p>Nerf is actually rendered differently than we are, they are using volume rendering while we are doing ray tracing.</p>



<a name="451366539"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451366539" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451366539">(Jul 14 2024 at 16:27)</a>:</h4>
<p>I'd like to try to modify the objective function later in order to make ray-tracing a differentiable process, and if all the data for the model is known, can I then return exactly which point was hit, and the distance between the hit point and the origin?</p>



<a name="451370675"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451370675" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451370675">(Jul 14 2024 at 17:45)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> I confirm that on my Mac m1 it works well now.</p>



<a name="451371911"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451371911" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451371911">(Jul 14 2024 at 18:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451328162">said</a>:</p>
<blockquote>
<p>Maybe I was not so clear. Yes, they encoded both direction and position BUT they trained with a fixed viewpoint:</p>
</blockquote>
<p>I certainly got what you meant, and there's certainly truth in both statements.  The fact that the training is happening across two networks and with rays very much scattered in all directions does to me indicate that it likely can generalize (with more parameters).  They did not pick a simple scene to say the least, and their sampling was not at a low resolution.  The fixed viewpoint is what let them achieve their target performance, but I don't think that their approach was really indicative of an overtrained solution.  On the contrary, they showed how well it performed on other viewpoints in their talk (they just don't go into that detail on their paper -- that's another paper).</p>



<a name="451373109"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451373109" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451373109">(Jul 14 2024 at 18:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451371911">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451328162">said</a>:</p>
<blockquote>
<p>Maybe I was not so clear. Yes, they encoded both direction and position BUT they trained with a fixed viewpoint:</p>
</blockquote>
<p>I certainly got what you meant, and there's certainly truth in both statements.  The fact that the training is happening across two networks and with rays very much scattered in all directions does to me indicate that it likely can generalize (with more parameters).  They did not pick a simple scene to say the least, and their sampling was not at a low resolution.  The fixed viewpoint is what let them achieve their target performance, but I don't think that their approach was really indicative of an overtrained solution.  On the contrary, they showed how well it performed on other viewpoints in their talk (they just don't go into that detail on their paper -- that's another paper).</p>
</blockquote>
<p>Yes I agree with you, their approach is certainly able to generalize and I have proved it but we need to add a more complex encoding like we were saying yesterday to reach the maximum accuracy. I will study more about the papers you gave us and expecially with sdf.</p>



<a name="451535418"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451535418" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451535418">(Jul 15 2024 at 16:06)</a>:</h4>
<p>Before implementing a more complex encoding (like sdf), today I tried first with positional encoding of Nerf's work. The idea is that MPL neural networks perform poorly at representing high-frequency variation in geometry. Mapping the inputs to a higher dimensional space using high frequency functions before passing them to the network enables better fitting of data that contains high frequency variation.</p>
<p>I got an improvement of 0.02% of accuracy, from 99.1% to 99.3%. These are two renders of the same objects but with different angles (and of course it's the same model without retraining):</p>
<p><a href="/user_uploads/1549/n4oPMMw47I5E7k1mIpFE2-jC/output0_ground.png">output0_ground.png</a><br>
<a href="/user_uploads/1549/gf3Nw7Z7hRyMrQx8ggDI00ij/output0_pred.png">output0_pred.png</a><br>
<a href="/user_uploads/1549/S4qjgfMFSgiAlG5g2-hbHaPd/output1_ground.png">output1_ground.png</a><br>
<a href="/user_uploads/1549/Y7UzmOCsDRd57to14CjsC1Lv/output1_pred.png">output1_pred.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/n4oPMMw47I5E7k1mIpFE2-jC/output0_ground.png" title="output0_ground.png"><img src="/user_uploads/1549/n4oPMMw47I5E7k1mIpFE2-jC/output0_ground.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/gf3Nw7Z7hRyMrQx8ggDI00ij/output0_pred.png" title="output0_pred.png"><img src="/user_uploads/1549/gf3Nw7Z7hRyMrQx8ggDI00ij/output0_pred.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/S4qjgfMFSgiAlG5g2-hbHaPd/output1_ground.png" title="output1_ground.png"><img src="/user_uploads/1549/S4qjgfMFSgiAlG5g2-hbHaPd/output1_ground.png"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/Y7UzmOCsDRd57to14CjsC1Lv/output1_pred.png" title="output1_pred.png"><img src="/user_uploads/1549/Y7UzmOCsDRd57to14CjsC1Lv/output1_pred.png"></a></div>



<a name="451537139"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451537139" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451537139">(Jul 15 2024 at 16:15)</a>:</h4>
<p>Left is ground truth, right is prediction.</p>



<a name="451537557"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451537557" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451537557">(Jul 15 2024 at 16:17)</a>:</h4>
<p>Major issues concern the boundaries, which are not as sharp as they should be but rather tend to be smooth.</p>



<a name="451538558"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451538558" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451538558">(Jul 15 2024 at 16:22)</a>:</h4>
<p>I believe both of these issues can be resolved by using a different and more complex encoding approach, as we discussed. <span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="700180">@fall Rainy</span></p>



<a name="451638003"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451638003" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451638003">(Jul 15 2024 at 21:59)</a>:</h4>
<p>Another idea I was thinking to help the NN is to modify a bit the sampling method. Now I use a totally randomic sampling around the bounding sphere but we can use a smarter approach using an importance sampling to sample more the regions where we are more uncertain.<br>
There are 4 steps: <br>
-first we sample randomly using the same approach as now.<br>
-Second, we can divide in N cells (like a grid) the rays basing on their origin and directions so that very similar rays will be found in the same cell.<br>
-Third, we calculate for each cell the uncertainty (very easy to calculate).<br>
-Lastly, We resemple but this time using the uncertainty in order to gather more samples in regions where we are more uncertain.</p>
<p>Do you think it could work?</p>



<a name="451642643"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451642643" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451642643">(Jul 15 2024 at 22:36)</a>:</h4>
<p>Think those percentages might be a little misleading?   Is it taking all the black background into account also?  If we count up expected hits vs predicted hits, that output0 in particular looks considerably more than 1% deviated.</p>



<a name="451643256"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451643256" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451643256">(Jul 15 2024 at 22:41)</a>:</h4>
<p>Importance sampling would be good, but that's typically done as an optimization -- Would need to see a graph over epochs to see if this actually could converge onto the solution (even if over-trained).  Can you make a graph?</p>
<p>That said, I think it might help with some of the perimeter and higher frequency detail, but it's really easy to get the sampling ever so subtle wrong and introduce bias or error.  Kind of what to see proven that we can get a robust fit, that a given network topology is capable of precise match before going down that route.</p>



<a name="451670446"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451670446" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451670446">(Jul 16 2024 at 02:57)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Can we treat the image as a whole, rather than a single pixel, so that we can use the filtering algorithm to do some post-processing?</p>



<a name="451690863"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451690863" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451690863">(Jul 16 2024 at 06:45)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451642643">ha scritto</a>:</p>
<blockquote>
<p>Think those percentages might be a little misleading?   Is it taking all the black background into account also?  If we count up expected hits vs predicted hits, that output0 in particular looks considerably more than 1% deviated.</p>
</blockquote>
<p>Yes you are right. The dataset is unbalanced (more black than white) and this is the reason why accuracy is not the best in this case (I print also precision recall and better F1). But I remember that previous students used accuracy as the main metric and I wouldn’t change it. If you are interested in F1, it is 0.988 (a bit lower)</p>



<a name="451690999"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451690999" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451690999">(Jul 16 2024 at 06:45)</a>:</h4>
<p>Sure, I can plot a graph over epochs.</p>



<a name="451736447"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451736447" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451736447">(Jul 16 2024 at 11:14)</a>:</h4>
<p>I want to discuss just a moment about metrics. Do you think precision, recall or F1 is the most important one in our case?</p>
<p>Just to remember (I know you are familiar with all of these):</p>
<ul>
<li>precision is the percentage of true and predicted hitted rays among those predicted and hitted.</li>
<li>recall is the pecentage of true predicted hitted rays among all true hitted rays.</li>
<li>F1 is an armonic mean between precision and recall.</li>
</ul>
<p>I think both precision and recall are important in our case, so I believe that F1 is the most significant one.</p>



<a name="451736529"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451736529" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451736529">(Jul 16 2024 at 11:15)</a>:</h4>
<p>Or maybe do you think some others metrics I have not mentioned are more relevant in our case?</p>



<a name="451739810"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451739810" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451739810">(Jul 16 2024 at 11:38)</a>:</h4>
<p>This is the plot of the model of yesterday (so without importance sampling):<br>
<a href="/user_uploads/1549/nheHYp8UKzkQYAfXESxespLx/download.png">download.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/nheHYp8UKzkQYAfXESxespLx/download.png" title="download.png"><img src="/user_uploads/1549/nheHYp8UKzkQYAfXESxespLx/download.png"></a></div><p>As we can notice, as we increase the number of epochs we get an average F1 between 0.98 and 0.99, so we can say that our model has an average error of 1.5%.</p>



<a name="451739890"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451739890" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451739890">(Jul 16 2024 at 11:39)</a>:</h4>
<p>Today I will implement importance sampling to see if we get improvements.</p>



<a name="451802049"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451802049" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451802049">(Jul 16 2024 at 16:22)</a>:</h4>
<p>And this is the behaviour with importance sampling (a moderate importance sampling):<br>
<a href="/user_uploads/1549/ze_CILI4SHrGNIUCnCEs8NZy/download.png">download.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/ze_CILI4SHrGNIUCnCEs8NZy/download.png" title="download.png"><img src="/user_uploads/1549/ze_CILI4SHrGNIUCnCEs8NZy/download.png"></a></div>



<a name="451802730"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451802730" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451802730">(Jul 16 2024 at 16:24)</a>:</h4>
<p>I tried also with a more aggressive importance sampling and I got an improvement of F1: 0.991, accuracy: 0.994. So overall:<br>
importance sampling helps the model to understand better the regions more uncertain but it is not sufficient alone to achieve best results.</p>



<a name="451803116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/451803116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#451803116">(Jul 16 2024 at 16:25)</a>:</h4>
<p>So it means that we need a more complex encoding or a more complex NN. For the moment I will focus on exploring encoding based on sdf.</p>



<a name="452234079"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452234079" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452234079">(Jul 18 2024 at 03:00)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/451670446">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> Can we treat the image as a whole, rather than a single pixel, so that we can use the filtering algorithm to do some post-processing?</p>
</blockquote>
<p>To what end, what exactly do you mean?  If the end result is pixel approximation, then it will be potentially useful for visualization purposes (only).  That has use, but it's definitely a different target.  The distinguishing feature that makes this challenge is replacing rt_shootray() with a neural net or the slightly higher level do_pixel().  Going full image robustly might allow for a (real-time) preview.</p>



<a name="452239169"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452239169" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452239169">(Jul 18 2024 at 03:52)</a>:</h4>
<p>The image rendered with neural network will have noise, if I can use the denoising algorithm after generating the image, the effect will be good, the left side of the image rendered by neural network, the right side is the image <br>
<a href="/user_uploads/1549/_v4_a7u2gkk4EpDk5B3Se1GG/denose.png">denose.png</a><br>
after denoising</p>
<div class="message_inline_image"><a href="/user_uploads/1549/_v4_a7u2gkk4EpDk5B3Se1GG/denose.png" title="denose.png"><img src="/user_uploads/1549/_v4_a7u2gkk4EpDk5B3Se1GG/denose.png"></a></div>



<a name="452335910"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452335910" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452335910">(Jul 18 2024 at 12:50)</a>:</h4>
<p>Ok after studying some papers about sdf/nerf/gaussian splatting I have understood that one key information I do not actually use in the NN is the direction itself of the ray. Currently as input of the NN I use the spherical coordinates of the first and second intersection but not the direction vector.<br>
Before introducing any further and more complex encoding I need to add this new information as input of the NN because all these methods rely on the direction.<br>
I was thinking that we can use a smart idea to help the NN: we are not interested in the orientation of the vector direction but only on its direction. <br>
<a href="/user_uploads/1549/6TleqJhFROZ4p1NxNmqNi1yE/Direction-bounding-sphere.jpeg.png">Direction-bounding-sphere.jpeg.png</a><br>
Imagine a vector in 2D, the maximum range we can have is from 0 to 180 (red region) since we are interested only on its direction. So, if the vector is in the green area, all we need to do is reflecting its angle to the positive half space. <br>
The same idea can be applied to 3D vectors in spherical coordinates (with a fixed radius).<br>
I think that using these new input features will be beneficial for two reasons:<br>
1) we could use some more complex encoding based on sdf/gaussian that they all rely on the concept of direction.<br>
2) using these input features, we will have as the new input of our NN the first intersection on the bounding sphere and this new vector direction. The advantage is that the range of theta and phi (of the new vector direction) is smaller than the previous input features that used the full ranges in spherical coordinates of the second intersection on the bounding sphere. This should help the NN because it will have less input space to analyse but without loss of informations.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/6TleqJhFROZ4p1NxNmqNi1yE/Direction-bounding-sphere.jpeg.png" title="Direction-bounding-sphere.jpeg.png"><img src="/user_uploads/1549/6TleqJhFROZ4p1NxNmqNi1yE/Direction-bounding-sphere.jpeg.png"></a></div><p>PS: we could even try grid encoding associated to direction and see how it works.</p>



<a name="452380256"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452380256" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452380256">(Jul 18 2024 at 15:54)</a>:</h4>
<p>Is there any way to know exactly which object the light hit?</p>



<a name="452584525"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452584525" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452584525">(Jul 19 2024 at 14:32)</a>:</h4>
<p>Ok I have added also the direction of the ray in the input features. As I was expecting, the NN does not improve adding the direction itself because we are not adding more informations but we are only using different features (I have also tried grid encoding).<br>
But the advantage is that now we can implement a more complex encoding that rely on the concept of direction.</p>



<a name="452590469"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/452590469" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#452590469">(Jul 19 2024 at 14:58)</a>:</h4>
<p>I have 2 ideas about encodings to try:</p>
<ul>
<li>
<p>first idea (and the best one in my opinion) is similar to the work of <a href="https://arxiv.org/abs/2011.13495">DeepSDF</a>. The idea is to train latent vectors to predict the sdf for each ray.  Then this latent vectors will be the input of our NIF architecture. The problem is that we need to compute the sdf for each ray in the sampling approach. I don't know if there is a fast way to do it. <span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="103542">@Erik</span> <br>
Note that the sdf will be used only to train the latent vectors, so the NIF architecture won't use the sdf but only the latent vectors.</p>
</li>
<li>
<p>second one (more difficult than the first) is a similar work of  <a href="https://arxiv.org/abs/2011.13495">Neural pull</a>. In this case we do not have ground truth sdf, so the idea is to train latent vectors to "pull" rays towards the nearest surface by using the predicted signed distance values and their gradients, which the network computes. The movement of each rays is determined by the predicted distance and can be either towards or away from the surface, depending on the sign of the distance. </p>
</li>
</ul>
<p>In both the cases,  we need to choose an arbitrary number of latent vectors that will be associated to each direction (and this is the reason why I have added the direction to the input features).</p>
<p>I believe that if we can calculate the sdf for each ray the first encoding will be more efficient. I wait for your opinion. <span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="103542">@Erik</span></p>



<a name="453079929"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453079929" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453079929">(Jul 22 2024 at 04:46)</a>:</h4>
<p>I have read a lot of papers, nerf, nerf++,etc...and I decided to use the methodology in this paper:<a href="https://arxiv.org/abs/2308.04079">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a></p>



<a name="453089382"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453089382" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453089382">(Jul 22 2024 at 06:01)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/452590469">said</a>:</p>
<blockquote>
<p>I have 2 ideas about encodings to try:</p>
<ul>
<li>
<p>first idea (and the best one in my opinion) is similar to the work of <a href="https://arxiv.org/abs/2011.13495">DeepSDF</a>. The idea is to train latent vectors to predict the sdf for each ray.  Then this latent vectors will be the input of our NIF architecture. The problem is that we need to compute the sdf for each ray in the sampling approach. I don't know if there is a fast way to do it. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span> <br>
Note that the sdf will be used only to train the latent vectors, so the NIF architecture won't use the sdf but only the latent vectors.</p>
</li>
<li>
<p>second one (more difficult than the first) is a similar work of  <a href="https://arxiv.org/abs/2011.13495">Neural pull</a>. In this case we do not have ground truth sdf, so the idea is to train latent vectors to "pull" rays towards the nearest surface by using the predicted signed distance values and their gradients, which the network computes. The movement of each rays is determined by the predicted distance and can be either towards or away from the surface, depending on the sign of the distance. </p>
</li>
</ul>
<p>In both the cases,  we need to choose an arbitrary number of latent vectors that will be associated to each direction (and this is the reason why I have added the direction to the input features).</p>
<p>I believe that if we can calculate the sdf for each ray the first encoding will be more efficient. I wait for your opinion. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span></p>
</blockquote>
<p>I'm reading some papers on sdf and have some questions, sdf is used to represent geometric objects, how to represent ray with sdf?</p>



<a name="453093169"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453093169" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453093169">(Jul 22 2024 at 06:29)</a>:</h4>
<p>I have currently implemented 3d Gaussian ahah</p>



<a name="453093531"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453093531" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453093531">(Jul 22 2024 at 06:32)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453089382">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/452590469">said</a>:</p>
<blockquote>
<p>I have 2 ideas about encodings to try:</p>
<ul>
<li>
<p>first idea (and the best one in my opinion) is similar to the work of <a href="https://arxiv.org/abs/2011.13495">DeepSDF</a>. The idea is to train latent vectors to predict the sdf for each ray.  Then this latent vectors will be the input of our NIF architecture. The problem is that we need to compute the sdf for each ray in the sampling approach. I don't know if there is a fast way to do it. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span> <br>
Note that the sdf will be used only to train the latent vectors, so the NIF architecture won't use the sdf but only the latent vectors.</p>
</li>
<li>
<p>second one (more difficult than the first) is a similar work of  <a href="https://arxiv.org/abs/2011.13495">Neural pull</a>. In this case we do not have ground truth sdf, so the idea is to train latent vectors to "pull" rays towards the nearest surface by using the predicted signed distance values and their gradients, which the network computes. The movement of each rays is determined by the predicted distance and can be either towards or away from the surface, depending on the sign of the distance. </p>
</li>
</ul>
<p>In both the cases,  we need to choose an arbitrary number of latent vectors that will be associated to each direction (and this is the reason why I have added the direction to the input features).</p>
<p>I believe that if we can calculate the sdf for each ray the first encoding will be more efficient. I wait for your opinion. <span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span></p>
</blockquote>
<p>I'm reading some papers on sdf and have some questions, sdf is used to represent geometric objects, how to represent ray with sdf?</p>
</blockquote>
<p>The idea is to find the point on the ray such that it has the minimum distance to the surface. See the ray marching algorithm or sphere tracing.</p>



<a name="453171884"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453171884" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453171884">(Jul 22 2024 at 13:05)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453093169">ha scritto</a>:</p>
<blockquote>
<p>I have currently implemented 3d Gaussian ahah</p>
</blockquote>
<p>I am trying with a probabilistic approach because I wasn't sure how to correctly extract the sdf for rays.<br>
My idea is to use an autoencoder (giving as input only the direction) so as to encode in an embedding a number n of gaussians that represent the shape of the object for that direction.</p>



<a name="453172190"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453172190" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453172190">(Jul 22 2024 at 13:07)</a>:</h4>
<p>In principle we do not need to encode all the "pixels" for a given direction in an embedding, but we need only to encode those areas which are the most uncertain.</p>



<a name="453172272"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453172272" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453172272">(Jul 22 2024 at 13:07)</a>:</h4>
<p>So I think I will merge this idea with my previous network which was good apart from the boundaries of the object.</p>



<a name="453173077"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453173077" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453173077">(Jul 22 2024 at 13:12)</a>:</h4>
<p>I made few tries in python so as to take confidence with gaussian splatting (for example I tried approximating an image using n gaussians) and I was really impressed how good is this technique.</p>



<a name="453185710"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453185710" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453185710">(Jul 22 2024 at 14:15)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453172272">said</a>:</p>
<blockquote>
<p>So I think I will merge this idea with my previous network which was good apart from the boundaries of the object.</p>
</blockquote>
<p>I agree with you. The problem is finding the boundaries.</p>



<a name="453186252"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453186252" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453186252">(Jul 22 2024 at 14:17)</a>:</h4>
<p>I have an idea about this. Since I use a sigmoid activation function as last layer to predict hit/miss it is somehow an information of the uncertainty of the prediction.</p>



<a name="453186436"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453186436" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453186436">(Jul 22 2024 at 14:18)</a>:</h4>
<p>So if it gives me a number around 0.5 it means that it is uncertain, so the gaussian should have more weight on that area.</p>



<a name="453187833"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453187833" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453187833">(Jul 22 2024 at 14:22)</a>:</h4>
<p>I think consider using Bayesian optimization</p>



<a name="453188010"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188010" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188010">(Jul 22 2024 at 14:23)</a>:</h4>
<p>About this, I would also calculate what is the mean probability that the NN gives me to each missclassified ray to check whether it can work.</p>



<a name="453188107"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188107" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188107">(Jul 22 2024 at 14:23)</a>:</h4>
<p>Bayesian networks can output both mean and variance simultaneously</p>



<a name="453188196"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188196" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188196">(Jul 22 2024 at 14:23)</a>:</h4>
<p>what is your idea</p>



<a name="453188334"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188334" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188334">(Jul 22 2024 at 14:24)</a>:</h4>
<p>I'm going a little slow, and I'm still considering how to integrate 3dgs</p>



<a name="453188635"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188635" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188635">(Jul 22 2024 at 14:25)</a>:</h4>
<p>I've completely given up on grid net.</p>



<a name="453188738"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188738" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188738">(Jul 22 2024 at 14:25)</a>:</h4>
<p>If you want to know how I want to implemented it, i use an embedding of N gaussians for each direction</p>



<a name="453188958"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453188958" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453188958">(Jul 22 2024 at 14:26)</a>:</h4>
<p>each gaussian can have a number of parameter that you want</p>



<a name="453189056"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189056" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189056">(Jul 22 2024 at 14:26)</a>:</h4>
<p>Can I refer to your code?</p>



<a name="453189071"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189071" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189071">(Jul 22 2024 at 14:26)</a>:</h4>
<p>but for simplicity I use only mean, variance and I think I should add also a weight</p>



<a name="453189193"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189193" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189193">(Jul 22 2024 at 14:26)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453189056">ha scritto</a>:</p>
<blockquote>
<p>Can I refer to your code?</p>
</blockquote>
<p>Ok later I will upload to github</p>



<a name="453189310"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189310" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189310">(Jul 22 2024 at 14:27)</a>:</h4>
<p>Ok, thx</p>



<a name="453189595"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189595" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189595">(Jul 22 2024 at 14:27)</a>:</h4>
<p>I tried with a small number of rays (10000) and a small number of gaussians for each direction and the NN is perfectly able to discretize all the rays</p>



<a name="453189953"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453189953" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453189953">(Jul 22 2024 at 14:28)</a>:</h4>
<p>The good thing is that I do not need to add any grid encoding to separate each direction, because the autoencoder is able to output the embedding in a continuos way since the input I give to it (only direction) is continuos</p>



<a name="453190136"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453190136" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453190136">(Jul 22 2024 at 14:29)</a>:</h4>
<p>That sounds great. I'd like to replace the whole rendering process with a 3dgs approach, which might turn into a rasterized rendering</p>



<a name="453265286"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453265286" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453265286">(Jul 22 2024 at 19:54)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453189056">ha scritto</a>:</p>
<blockquote>
<p>Can I refer to your code?</p>
</blockquote>
<p>i have uploaded the code for gaussian splatting. <br>
<a href="https://github.com/bralani/rt_volume/blob/neural_rendering2/src/rt/gaussian_splatting.py">https://github.com/bralani/rt_volume/blob/neural_rendering2/src/rt/gaussian_splatting.py</a></p>



<a name="453535448"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453535448" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453535448">(Jul 23 2024 at 21:48)</a>:</h4>
<p>Today I made another improvement with gaussian splatting. I decided to associate a single gaussian to each positive hit of ray in the training set with a large variance.  Each gaussian has a mean (origin_theta, origin_phi, dir_phi, dir_theta) and a variance (variance_theta, variance_phi, dir_phi, dir_theta). Dir_phi and dir_theta are set to a fixed number of 0.05 because in my opinion we can save some memory in this way and the training process will be faster. The only thing the neural network is supposed to do is to find the maximum variance of each gaussian so that also the negative hits are correctly classified. <br>
The reason why we want to find the largest variance of gaussians is because of overfitting issues.</p>



<a name="453535937"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453535937" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453535937">(Jul 23 2024 at 21:50)</a>:</h4>
<p>This works pretty good with 10000 rays but the problem is that if we increase just a bit the number of examples in the training set, the NN will become very complex in the number of parameters</p>



<a name="453536404"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453536404" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453536404">(Jul 23 2024 at 21:52)</a>:</h4>
<p>I believe that this approach has a lot of potential</p>



<a name="453536818"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453536818" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453536818">(Jul 23 2024 at 21:54)</a>:</h4>
<p>Tomorrow I will focus on reducing the number of gaussians without losing accuracy</p>



<a name="453754141"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754141" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754141">(Jul 24 2024 at 17:16)</a>:</h4>
<p>There is a bottleneck of the current NN because as I increase the number of examples in the training set, it goes out of memory</p>



<a name="453754152"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754152" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754152">(Jul 24 2024 at 17:16)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> Can you recap the structure of the computations and memory involved with the gaussian approach?  How is that related to the Encoder/Decoder networks you have/had in your gaussian_splatting.py</p>



<a name="453754204"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754204" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754204">(Jul 24 2024 at 17:17)</a>:</h4>
<p>Ok</p>



<a name="453754347"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754347" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754347">(Jul 24 2024 at 17:18)</a>:</h4>
<p>I should update that file, anyway</p>



<a name="453754522"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754522" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754522">(Jul 24 2024 at 17:18)</a>:</h4>
<p>The network is very simple: there is an encoder (which has the task to produce the embedding) and a decoder which has the task to produce the output (a probability between 0 and 1)</p>



<a name="453754642"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754642" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754642">(Jul 24 2024 at 17:19)</a>:</h4>
<p>I'm seeing a 6-layer fully connected network there, where the layers are pretty hefty number of weights in total, which would explain the memory explosion</p>



<a name="453754979"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453754979" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453754979">(Jul 24 2024 at 17:20)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/453754642">ha scritto</a>:</p>
<blockquote>
<p>I'm seeing a 6-layer fully connected network there, where the layers are pretty hefty number of weights in total, which would explain the memory explosion</p>
</blockquote>
<p>It is the old version, I don't use any layer anymore.</p>



<a name="453755135"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755135" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755135">(Jul 24 2024 at 17:21)</a>:</h4>
<p>I have uploaded the new version now</p>



<a name="453755335"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755335" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755335">(Jul 24 2024 at 17:22)</a>:</h4>
<p>Okay.  In the old, looks like approximately 4MB of memory for that latent_dim=100 construction on just the encoder side.</p>



<a name="453755472"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755472" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755472">(Jul 24 2024 at 17:23)</a>:</h4>
<p>Sorry, way off... that's better.</p>



<a name="453755698"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755698" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755698">(Jul 24 2024 at 17:24)</a>:</h4>
<p>Ok, in this new version I associate to each gaussian 4 numbers for the mean and 4 for the variance.</p>



<a name="453755812"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453755812" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453755812">(Jul 24 2024 at 17:24)</a>:</h4>
<p>And the number of gaussians are proportional to the number of positive hit in the training set.</p>



<a name="453756111"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453756111" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453756111">(Jul 24 2024 at 17:25)</a>:</h4>
<p>When I use 10k samples it works fine, with 100k is very slow and with 1 million it goes out of memory</p>



<a name="453756882"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453756882" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453756882">(Jul 24 2024 at 17:29)</a>:</h4>
<p>Maybe I should not associate a single gaussian to each positive hit in the training set but I should randomly take a subset of positive hits...</p>



<a name="453757917"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453757917" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453757917">(Jul 24 2024 at 17:33)</a>:</h4>
<p>So you're using 10k ray samples currently right?  Is that your number of embeddings?</p>



<a name="453758073"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758073" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758073">(Jul 24 2024 at 17:34)</a>:</h4>
<p>With 10k rays, half are positive hits so about 5k are the embeddings</p>



<a name="453758140"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758140" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758140">(Jul 24 2024 at 17:34)</a>:</h4>
<p>Okay, but worst case it's 10k?</p>



<a name="453758170"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758170" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758170">(Jul 24 2024 at 17:35)</a>:</h4>
<p>yes</p>



<a name="453758192"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758192" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758192">(Jul 24 2024 at 17:35)</a>:</h4>
<p>or is there more on disk?  You have it actually using whatever is in the data folder</p>



<a name="453758293"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758293" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758293">(Jul 24 2024 at 17:36)</a>:</h4>
<p>(just need to make sure you don't have a json with 100M lines or something)</p>



<a name="453758373"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758373" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758373">(Jul 24 2024 at 17:36)</a>:</h4>
<p>my json has 1 million data</p>



<a name="453758426"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758426" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758426">(Jul 24 2024 at 17:36)</a>:</h4>
<p>but I take randomly only 10k samples</p>



<a name="453758530"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758530" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758530">(Jul 24 2024 at 17:37)</a>:</h4>
<p>Heh, okay .. but you're still creating an Encoder based on embeddings, which is based on how much is in your json, not how many samples, unless I'm reading this differently</p>



<a name="453758712"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758712" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758712">(Jul 24 2024 at 17:38)</a>:</h4>
<p>if you print(embeddings.shape[0]) in get_embeddings, what's that report?</p>



<a name="453758832"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758832" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758832">(Jul 24 2024 at 17:39)</a>:</h4>
<p>4683</p>



<a name="453758866"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758866" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758866">(Jul 24 2024 at 17:39)</a>:</h4>
<p>Line 47 i cut the json, so I take only 10k examples</p>



<a name="453758894"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758894" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758894">(Jul 24 2024 at 17:39)</a>:</h4>
<p>Okay, so it is hitting the else case in the constructor</p>



<a name="453758913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453758913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453758913">(Jul 24 2024 at 17:39)</a>:</h4>
<p>yes</p>



<a name="453760043"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760043" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760043">(Jul 24 2024 at 17:43)</a>:</h4>
<p>So in my back-of-napkin calculations, you're really not using much memory at all, nothing that explains running out.</p>



<a name="453760148"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760148" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760148">(Jul 24 2024 at 17:44)</a>:</h4>
<p>With 10k or with 1M?</p>



<a name="453760150"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760150" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760150">(Jul 24 2024 at 17:44)</a>:</h4>
<p>The autoencoder network is trivial as you noted, about 0.25MB total (which is dubious for any real model)</p>



<a name="453760343"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760343" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760343">(Jul 24 2024 at 17:45)</a>:</h4>
<p>I don't (yet) see where you're actually accruing memory in the test iterations.</p>



<a name="453760384"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760384" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760384">(Jul 24 2024 at 17:45)</a>:</h4>
<p>Unless pytorch is doing something under the hood that isn't being used but is growing</p>



<a name="453760515"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760515" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760515">(Jul 24 2024 at 17:46)</a>:</h4>
<p>It does not even start training with 1M</p>



<a name="453760828"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760828" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760828">(Jul 24 2024 at 17:48)</a>:</h4>
<p>You mean all you change is num_epochs = 1000000 and it dies?</p>



<a name="453760873"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760873" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760873">(Jul 24 2024 at 17:49)</a>:</h4>
<p>That doesn't add up</p>



<a name="453760886"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760886" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760886">(Jul 24 2024 at 17:49)</a>:</h4>
<p>not epochs</p>



<a name="453760948"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453760948" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453760948">(Jul 24 2024 at 17:49)</a>:</h4>
<p>I comment the line 47, so I load all the json</p>



<a name="453761014"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761014" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761014">(Jul 24 2024 at 17:49)</a>:</h4>
<p>Oooh oh, gotcha -- so you're chaning the [:10000] to other values, how much data, how many embeddings</p>



<a name="453761063"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761063" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761063">(Jul 24 2024 at 17:50)</a>:</h4>
<p>yes</p>



<a name="453761291"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761291" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761291">(Jul 24 2024 at 17:51)</a>:</h4>
<p>In the real paper of gaussian splatting they associate a single embedding to each example but I don't understand how they don't run out of memory</p>



<a name="453761854"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761854" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761854">(Jul 24 2024 at 17:55)</a>:</h4>
<p>I don't see how you're running out of memory.</p>



<a name="453761926"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761926" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761926">(Jul 24 2024 at 17:55)</a>:</h4>
<p>there must be some bug or cleanup issue that is ballooning.  Even with 1M samples, that's only about 38MB of data</p>



<a name="453761948"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453761948" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453761948">(Jul 24 2024 at 17:55)</a>:</h4>
<p>you surely have more than that available :)</p>



<a name="453762030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762030">(Jul 24 2024 at 17:56)</a>:</h4>
<p>how do you calculate it?</p>



<a name="453762189"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762189" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762189">(Jul 24 2024 at 17:57)</a>:</h4>
<p>with double precision, your 5 origin+dir+label tensors consume just 40 bytes</p>



<a name="453762388"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762388" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762388">(Jul 24 2024 at 17:58)</a>:</h4>
<p>mmmm, maybe the issue is with the gradient of pytorch</p>



<a name="453762473"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762473" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762473">(Jul 24 2024 at 17:59)</a>:</h4>
<p>I remember I had this problem a long time ago</p>



<a name="453762523"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762523" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762523">(Jul 24 2024 at 17:59)</a>:</h4>
<p>I must do some checks, thanks</p>



<a name="453762527"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762527" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762527">(Jul 24 2024 at 17:59)</a>:</h4>
<p>at 5000 embeddings, that's not even 1MB for the autoencoding (embeddings + embedding params + proxy vars)</p>



<a name="453762640"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762640" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762640">(Jul 24 2024 at 18:00)</a>:</h4>
<p>got it</p>



<a name="453762802"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453762802" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453762802">(Jul 24 2024 at 18:00)</a>:</h4>
<p>even if it scaled linearly, to 500000 embeddings, that'd be 100MB max</p>



<a name="453763010"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763010" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763010">(Jul 24 2024 at 18:01)</a>:</h4>
<p>The json file is 100MB, so you are right</p>



<a name="453763183"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763183" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763183">(Jul 24 2024 at 18:02)</a>:</h4>
<p>Well that's text, but even as 8-byte double precision floats there's just not enough data</p>



<a name="453763319"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763319" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763319">(Jul 24 2024 at 18:02)</a>:</h4>
<p>I'd suggest adding some print or pause statements and watch the process memory usage, see if some particular operation is increasing usage substantially</p>



<a name="453763399"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763399" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763399">(Jul 24 2024 at 18:03)</a>:</h4>
<p>Ok thanks 👍🏻</p>



<a name="453763490"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763490" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763490">(Jul 24 2024 at 18:03)</a>:</h4>
<p>got to be something relatively simple.  If you were getting to iterations, I would suggest adding a gc.collect() or something to ensure python has opportunity to purge, but clearly something is going on before that even if it doesn't get to iterations.</p>



<a name="453763619"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763619" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763619">(Jul 24 2024 at 18:04)</a>:</h4>
<p>I don't see it yet, but something is consuming gobs of memory</p>



<a name="453763674"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763674" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763674">(Jul 24 2024 at 18:04)</a>:</h4>
<p>Yes it is really strange</p>



<a name="453763913"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453763913" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453763913">(Jul 24 2024 at 18:05)</a>:</h4>
<p>Thanks</p>



<a name="453764292"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453764292" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453764292">(Jul 24 2024 at 18:07)</a>:</h4>
<p>Like I could totally see if it your constructor data hash was making 1M copies of all those string hash keys... but those are reset on each iteration of self.datas.</p>



<a name="453764657"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453764657" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453764657">(Jul 24 2024 at 18:08)</a>:</h4>
<p>maybe some linear overhead of torch.Tensor, but that doesn't make sense to me</p>



<a name="453764725"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453764725" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453764725">(Jul 24 2024 at 18:09)</a>:</h4>
<p>any change if you replace them with:</p>
<p>origin = torch.tensor(data["point1_sph"], dtype=torch.float64) <br>
dir = torch.tensor(data["dir_sph"], dtype=torch.float64) <br>
label = torch.tensor([data["label"]], dtype=torch.float64)</p>
<p>?</p>



<a name="453765068"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765068" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765068">(Jul 24 2024 at 18:10)</a>:</h4>
<p>I have not anymore the pc with me</p>



<a name="453765089"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765089" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765089">(Jul 24 2024 at 18:10)</a>:</h4>
<p>I will try later</p>



<a name="453765589"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765589" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765589">(Jul 24 2024 at 18:12)</a>:</h4>
<p>Okay.  I'd try that but then also exit before the training use and see if you can get a pause before exiting to see how much memory the app is actually using before RayDataset, after RayDataset construction, and after Autoencoder construction, see where it balloons out.</p>



<a name="453765750"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453765750" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453765750">(Jul 24 2024 at 18:13)</a>:</h4>
<p>Yep it is what I am going to try 👍🏻</p>



<a name="453767361"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453767361" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453767361">(Jul 24 2024 at 18:20)</a>:</h4>
<p>Came across this interesting high-level article posted today, nice generic tutorial... <a href="https://gpuopen.com/learn/deep_learning_crash_course/">https://gpuopen.com/learn/deep_learning_crash_course/</a></p>



<a name="453804846"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453804846" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453804846">(Jul 24 2024 at 22:02)</a>:</h4>
<p><a href="/user_uploads/1549/8gAx74Q6K7ERNGbn0gbqLPi0/Screenshot-2024-07-24-alle-23.59.31.png">Screenshot-2024-07-24-alle-23.59.31.png</a><br>
Ok I got it. <span class="user-mention" data-user-id="102902">@Sean</span> You were right on all the estimations of the memory. The problem is in the decoder which you hadn't seen, when I calculate the probability of the examples that belongs to each gaussian.<br>
I had implemented broadcasting (to speed up calculations) so I clone the embeddings (gaussian) n times where n is the batch size (number of examples).<br>
In this image the batch size was of 256 examples.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/8gAx74Q6K7ERNGbn0gbqLPi0/Screenshot-2024-07-24-alle-23.59.31.png" title="Screenshot-2024-07-24-alle-23.59.31.png"><img src="/user_uploads/thumbnail/1549/8gAx74Q6K7ERNGbn0gbqLPi0/Screenshot-2024-07-24-alle-23.59.31.png/840x560.webp"></a></div>



<a name="453805101"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453805101" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453805101">(Jul 24 2024 at 22:04)</a>:</h4>
<p>Broadcasting in this case isn't probably a smart way to speed up calculations since a lot of gaussians are totally useless for the calculations of the probability for the current examples, but only the closest one to the current example are relevant.</p>



<a name="453948030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/453948030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#453948030">(Jul 25 2024 at 13:23)</a>:</h4>
<p>I have solved the broadcasting issue that run out memory and I have first results. For the moment I am trying with only 10k rays because the calculation of probability is pretty slow.</p>
<p>Here the best epoch of the previous NIF network with only 10k rays:</p>
<p>F1: 0.880218316493941 <br>
Accuracy: 0.9283117186132877 <br>
Precision: 0.9087676930301201 <br>
Recall: 0.8534080886985007</p>
<p>Here, instead the best epoch with this new gaussian splatting network with 10K rays and only 1k gaussians embeddings (I decided to lower the number of gaussians to better explain the power of this model):</p>
<p>F1 Score: 0.9155<br>
Accuracy: 0.9261<br>
Precision: 0.9316<br>
Recall: 0.9000</p>
<p>As you can notice, the gaussian splatting architecture has more power than the NIF architecture BUT it is way slower. <br>
The interesting part is that I achieved this result in only 11 epochs, so the training is not slow but the inference is slow (the action from the start of the neural network to giving back the prediction).</p>
<p>For this reason, I will now focus on speeding up the gaussian splatting architecture. I believe I should read some papers about real-time renderings with gaussian splatting so as to achieve this speed up.</p>
<p>One idea I have is cutting some gaussians basing on the input I want to predict. (ie the furthest ones from the ray I want to predict).</p>
<p>P.S: the results I have showed here are not close to the ones of the previous week (accuracy: 0.994 and F1: 0.991) just because they were achieved with 1 Million examples. Here I use only 10k rays just to compare NIF architecture with Gaussian Splatting.</p>



<a name="454353169"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454353169" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454353169">(Jul 26 2024 at 18:38)</a>:</h4>
<p>Today I had implemented parallelization of inference process and the training process is much faster. <br>
However, I had another problem with the covariance matrix. To calculate the pdf of a gaussian we need to invert the covariance matrix but when it is close to singularity, it is not possible to invert it. The problem is that the covariance matrix for all the gaussians has small values due to the nature of the problem (if you imagine each gaussian as an ellipsoid in 3D, it will have very small magnitude). <br>
To mitigate this problem I decided to use double precision (float64) and for the moment it seems to perform better.</p>



<a name="454353587"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454353587" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454353587">(Jul 26 2024 at 18:42)</a>:</h4>
<p>Do you know any other method to solve this issue of matrix ill-conditioning?</p>



<a name="454354000"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454354000" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454354000">(Jul 26 2024 at 18:46)</a>:</h4>
<p>Apart from this, tomorrow I will train with more examples to see the true results of this model.</p>



<a name="454539480"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454539480" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454539480">(Jul 27 2024 at 23:13)</a>:</h4>
<p>Today I had further speed up the inference process by taking only the closest gaussians to the example to predict. I had also tried with more examples (100k) and the metric F1 improves even to 94-95%. However, it seems more difficult to improve this result with the current architecture. My opinion is due to the number of gaussians that now are fixed for all the training. The original paper (3DGS) uses instead a variable number of gaussians that can be lowered during the training process (if some gaussians have a very small variance) or it can be increased if the accuracy is low.</p>



<a name="454544610"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454544610" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454544610">(Jul 28 2024 at 00:10)</a>:</h4>
<p>That's sounding a lot better.  I think it'll still need to get into the 99% realm, but that's a distinct improvement.  What's that 94%-95% look like?</p>



<a name="454544714"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454544714" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454544714">(Jul 28 2024 at 00:11)</a>:</h4>
<p>By the way, had a lovely discussion with one of the authors of AMD's Neural Intersection Function paper today.  He said they've made some headway on generalizing themselves, but that's obviously a hard problem.  He's probably going to publish on it next year.</p>



<a name="454544906"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454544906" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454544906">(Jul 28 2024 at 00:15)</a>:</h4>
<p>One thought I had, and it's obviously in a different direction but maybe applicable is what if we try integrating over multiple networks.  That is, use the simple network they demonstrated works well for a single view, but then lets create one for 32 (or 32768) views, get estimated in-hit points from all of them, and integrate spatially.</p>



<a name="454545008"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454545008" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454545008">(Jul 28 2024 at 00:16)</a>:</h4>
<p>That's actually not terribly dissimilar from the NeRF approach, but the goal would not be a radiance field.  It would be like a surface occupancy field, or a point cloud with weights.</p>



<a name="454604656"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454604656" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454604656">(Jul 28 2024 at 11:42)</a>:</h4>
<p>This is really possible. I recently saw some algorithms for interpolation between multiple pictures. Maybe we can predict in key directions and then make differences in other directions.</p>



<a name="454612969"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454612969" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454612969">(Jul 28 2024 at 13:27)</a>:</h4>
<p>If the direction is contant, network is learning a func like:<br>
<a href="/user_uploads/1549/FirF5i_t38_4wtaOioudCpRS/屏幕截图-2024-07-28-212551.png">2024-07-28-212551.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/FirF5i_t38_4wtaOioudCpRS/屏幕截图-2024-07-28-212551.png" title="2024-07-28-212551.png"><img data-original-dimensions="1281x705" src="/user_uploads/thumbnail/1549/FirF5i_t38_4wtaOioudCpRS/屏幕截图-2024-07-28-212551.png/840x560.webp"></a></div>



<a name="454613104"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454613104" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454613104">(Jul 28 2024 at 13:29)</a>:</h4>
<p>Interpolated fits between different perspectives have been done before:<br>
<a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png">2024-07-28-212847.png</a><br>
from <a href="https://arxiv.org/pdf/2211.00722">VIINTER: View Interpolation with Implicit Neural Representations of Images</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png" title="2024-07-28-212847.png"><img data-original-dimensions="1696x558" src="/user_uploads/thumbnail/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png/840x560.webp"></a></div>



<a name="454617963"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454617963" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454617963">(Jul 28 2024 at 14:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454544610">ha scritto</a>:</p>
<blockquote>
<p>That's sounding a lot better.  I think it'll still need to get into the 99% realm, but that's a distinct improvement.  What's that 94%-95% look like?</p>
</blockquote>
<p>I have not rendered any frame for gaussian splatting network yet because if the percentage are under 0.97 - 0.98, the predicted image is very far from the true one. I prefer first to achieve better results and then plotting it.</p>



<a name="454618704"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454618704" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454618704">(Jul 28 2024 at 14:35)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454544906">ha scritto</a>:</p>
<blockquote>
<p>One thought I had, and it's obviously in a different direction but maybe applicable is what if we try integrating over multiple networks.  That is, use the simple network they demonstrated works well for a single view, but then lets create one for 32 (or 32768) views, get estimated in-hit points from all of them, and integrate spatially.</p>
</blockquote>
<p>This idea is not far from the idea of grid encoding of direction which I have already tried without any improvement. In that case I used embeddings for each direction, you suggest using a network for each direction. I can try it. <span aria-label="thumbs up" class="emoji emoji-1f44d" role="img" title="thumbs up">:thumbs_up:</span></p>



<a name="454620623"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454620623" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454620623">(Jul 28 2024 at 14:54)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454613104">ha scritto</a>:</p>
<blockquote>
<p>Interpolated fits between different perspectives have been done before:<br>
<a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png">2024-07-28-212847.png</a><br>
from <a href="https://arxiv.org/pdf/2211.00722">VIINTER: View Interpolation with Implicit Neural Representations of Images</a></p>
</blockquote>
<p>This could work but it means that  we have to change the sampling to fixed view sampling. I have some doubts about the number of views we should sample because:<br>
If we choose for example 1 million rays in the training set and we choose  a reasonable number of 1000 rays for each view this means that we have a total of 1000 views.<br>
If we distribute uniformly these views around the bounding sphere it means that, remember that theta goes from 0 to pi and phi goes from 0 to 2pi:<br>
In my case I can use half of phi because in my case the problem is simpler and the direction is invariant to orientation (so I have theta that goes from 0 to pi and phi that goes from 0 to pi):<br>
Theta x phi = 3,14 x 3,14 = 9,8596 -&gt; total space<br>
Uniform distribution of views:<br>
9,8596/1000 views = 0,009859 rad = 0,56° between two views. <br>
I think it is a reasonable error and it can be easily interpolated.<br>
In your case, however, you can't reduce the range of phi (because rgb is not invariant to orientations), so you will have:<br>
Theta x phi = 3,14 x 6,28 = 19,719 -&gt; total space<br>
19,719/1000 views = 0,0197 rad = 1,128° between two views. <br>
An error of 1° is reasonable also in your case and if my calculations are exact, it could work even in your case but the error is the double of mine.</p>



<a name="454620794"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454620794" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454620794">(Jul 28 2024 at 14:57)</a>:</h4>
<p>I believe we should try this approach using NIF architecture and then interpolating them.</p>



<a name="454622260"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454622260" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454622260">(Jul 28 2024 at 15:10)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span>  I have a doubt about rays and pixels: if we want to render a frame of 100x100 it means that the algorithm sample for each pixel a ray (for a total of 10k rays) or is it different?</p>



<a name="454677762"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454677762" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454677762">(Jul 28 2024 at 23:13)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454617963">said</a>:</p>
<blockquote>
<p>I have not rendered any frame for gaussian splatting network yet because if the percentage are under 0.97 - 0.98, the predicted image is very far from the true one. I prefer first to achieve better results and then plotting it.</p>
</blockquote>
<p>That is absolutely not best practice and not recommended to ignore the predicted images solely based on having low percentages.  Not looking gives you no information.  Looking may give no information, or may provide helpful clues as to what isn't encoding well.  </p>
<p>It can be high frequency detail, it can be a straight up bug where values are simply shifted, it can be low frequency undulations, and more.  It's not in your interest to ignore them even if 19 times out of 20 it's just a "drunk wet mess".</p>



<a name="454678116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454678116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454678116">(Jul 28 2024 at 23:18)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454620794">said</a>:</p>
<blockquote>
<p>I believe we should try this approach using NIF architecture and then interpolating them.</p>
</blockquote>
<p>I will just reiterate what we'd discussed earlier, that there should be two different approaches being taken (in general), or even better two different goals (e.g., 3d shape vs 2d image).  There is value in exploring the same method with different implementation detail (on the off chance there is some detail that matters more than anticipated).</p>



<a name="454678542"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454678542" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454678542">(Jul 28 2024 at 23:22)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454618704">said</a>:</p>
<blockquote>
<p>This idea is not far from the idea of grid encoding of direction which I have already tried without any improvement. In that case I used embeddings for each direction, you suggest using a network for each direction. I can try it. <span aria-label="thumbs up" class="emoji emoji-1f44d" role="img" title="thumbs up">:thumbs_up:</span></p>
</blockquote>
<p>It's not far off, but the separate networks is the key.  AMD really proved that surface illumination can be almost perfectly encoded for a given view.  Maybe if we were to first reproduce their research, that would give more confidence, but lacking that it's not terribly unexpected.</p>
<p>Now that said, I don't think there's a whole lot of difference with random rays in random dirs -- naively I think that can work with the right network and right amount of training.  Remains to be proven though.  The idea with the 32+ grid views, however, is a compromise, banking on the notion that a single view should converge that view.  In other analysis work we're involved with, there's mathematical proofs that lend evidence towards 32 views being a sweet spot approximation for complete random, converging much faster than pure random.</p>



<a name="454678740"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454678740" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454678740">(Jul 28 2024 at 23:25)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454620623">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454613104">ha scritto</a>:</p>
<blockquote>
<p>Interpolated fits between different perspectives have been done before:<br>
<a href="/user_uploads/1549/5tRH7xU1qKEypSPE64ZNJSR5/2024-07-28-212847.png">2024-07-28-212847.png</a><br>
from <a href="https://arxiv.org/pdf/2211.00722">VIINTER: View Interpolation with Implicit Neural Representations of Images</a></p>
</blockquote>
<p>This could work but it means that  we have to change the sampling to fixed view sampling. I have some doubts about the number of views we should sample because:<br>
If we choose for example 1 million rays in the training set and we choose  a reasonable number of 1000 rays for each view this means that we have a total of 1000 views.<br>
If we distribute uniformly these views around the bounding sphere it means that, remember that theta goes from 0 to pi and phi goes from 0 to 2pi:<br>
In my case I can use half of phi because in my case the problem is simpler and the direction is invariant to orientation (so I have theta that goes from 0 to pi and phi that goes from 0 to pi):<br>
Theta x phi = 3,14 x 3,14 = 9,8596 -&gt; total space<br>
Uniform distribution of views:<br>
9,8596/1000 views = 0,009859 rad = 0,56° between two views. <br>
I think it is a reasonable error and it can be easily interpolated.<br>
In your case, however, you can't reduce the range of phi (because rgb is not invariant to orientations), so you will have:<br>
Theta x phi = 3,14 x 6,28 = 19,719 -&gt; total space<br>
19,719/1000 views = 0,0197 rad = 1,128° between two views. <br>
An error of 1° is reasonable also in your case and if my calculations are exact, it could work even in your case but the error is the double of mine.</p>
</blockquote>
<p>Again, I would just caution whether we're following research that is attempting to capture shape in the embedding or whether the goal is capturing the shape just barely enough that color, i.e., a visual image can be constructed that "looks good enough".  On quick read, that VINTER paper appears to be the latter, but I'd have to read it in more detail.</p>



<a name="454679031"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454679031" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454679031">(Jul 28 2024 at 23:28)</a>:</h4>
<p>As for total number of views, I think you could try as coarse as 45-degree increments.  Resolution will need to be as fine as the smallest detail, which depends on the model size and detail complexity.  I'd personally start at 1024x1024, about 1M per view.</p>



<a name="454679122"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454679122" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454679122">(Jul 28 2024 at 23:29)</a>:</h4>
<p>That 1024^2 resolution at 45-degree probably means something like 256 or 512 resolution alignment, whatever that cell size resolves to.</p>



<a name="454764857"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454764857" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454764857">(Jul 29 2024 at 08:52)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454677762">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454617963">said</a>:</p>
<blockquote>
<p>I have not rendered any frame for gaussian splatting network yet because if the percentage are under 0.97 - 0.98, the predicted image is very far from the true one. I prefer first to achieve better results and then plotting it.</p>
</blockquote>
<p>That is absolutely not best practice and not recommended to ignore the predicted images solely based on having low percentages.  Not looking gives you no information.  Looking may give no information, or may provide helpful clues as to what isn't encoding well.  </p>
<p>It can be high frequency detail, it can be a straight up bug where values are simply shifted, it can be low frequency undulations, and more.  It's not in your interest to ignore them even if 19 times out of 20 it's just a "drunk wet mess".</p>
</blockquote>
<p>Yes, you are totally right. I did not considered to render it because I got that result with only 100K rays and I wanted first to train the NN with at least 1 million rays. Thanks for the advise.</p>



<a name="454766161"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454766161" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454766161">(Jul 29 2024 at 08:57)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454678542">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/454618704">said</a>:</p>
<blockquote>
<p>This idea is not far from the idea of grid encoding of direction which I have already tried without any improvement. In that case I used embeddings for each direction, you suggest using a network for each direction. I can try it. <span aria-label="thumbs up" class="emoji emoji-1f44d" role="img" title="thumbs up">:thumbs_up:</span></p>
</blockquote>
<p>It's not far off, but the separate networks is the key.  AMD really proved that surface illumination can be almost perfectly encoded for a given view.  Maybe if we were to first reproduce their research, that would give more confidence, but lacking that it's not terribly unexpected.</p>
<p>Now that said, I don't think there's a whole lot of difference with random rays in random dirs -- naively I think that can work with the right network and right amount of training.  Remains to be proven though.  The idea with the 32+ grid views, however, is a compromise, banking on the notion that a single view should converge that view.  In other analysis work we're involved with, there's mathematical proofs that lend evidence towards 32 views being a sweet spot approximation for complete random, converging much faster than pure random.</p>
</blockquote>
<p>I was wondering... Isn't the limit of the previous NN (NIF network which I got 0.994 for accuracy) was simply that the number of examples in the training set was too low? Maybe we should try with even more samples (more than 1 million) to see how it works.</p>



<a name="454956525"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/454956525" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#454956525">(Jul 29 2024 at 21:45)</a>:</h4>
<p>Today I had implemented the adaptive learning for Gaussian splatting architecture. I want first to finish and evaluate this architecture before trying with multiple NIFs.</p>



<a name="455319987"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455319987" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455319987">(Jul 31 2024 at 08:38)</a>:</h4>
<p>After many optimizations, I got a pretty good result(grid net, fix direction)<br>
<a href="/user_uploads/1549/RTCyYXBw1e7ZcOaqRuzzZ8dQ/屏幕截图-2024-07-31-163626.png">2024-07-31-163626.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/RTCyYXBw1e7ZcOaqRuzzZ8dQ/屏幕截图-2024-07-31-163626.png" title="2024-07-31-163626.png"><img data-original-dimensions="757x796" src="/user_uploads/thumbnail/1549/RTCyYXBw1e7ZcOaqRuzzZ8dQ/屏幕截图-2024-07-31-163626.png/840x560.webp"></a></div>



<a name="455421932"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455421932" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455421932">(Jul 31 2024 at 16:20)</a>:</h4>
<p><span class="user-mention" data-user-id="700180">@fall Rainy</span> please elaborate, (and point to latest code!) what's the resolution of the grid net, what are the layers, how many epochs, how long did training take, how long does lookup take, etc...</p>



<a name="455494134"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455494134" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455494134">(Jul 31 2024 at 22:09)</a>:</h4>
<p>Really cool paper implementation on how to encode BREP in a NNet... <a href="https://github.com/samxuxiang/BrepGen">https://github.com/samxuxiang/BrepGen</a></p>



<a name="455494519"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455494519" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455494519">(Jul 31 2024 at 22:12)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455494134">said</a>:</p>
<blockquote>
<p>Really cool paper implementation on how to encode BREP in a NNet... <a href="https://github.com/samxuxiang/BrepGen">https://github.com/samxuxiang/BrepGen</a></p>
</blockquote>
<p>I have some experience with diffusion models for 3D. I did a diffusion network for automatic retopology (for my university).</p>



<a name="455494661"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455494661" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455494661">(Jul 31 2024 at 22:13)</a>:</h4>
<p>Regarding Gaussian splatting, I am not so convinced about metrics, tomorrow I will render some frames to see graphical results…</p>



<a name="455558171"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455558171" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455558171">(Aug 01 2024 at 06:02)</a>:</h4>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>



<a name="455619388"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455619388" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455619388">(Aug 01 2024 at 11:07)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">ha scritto</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>This is fantastic, I just tried the software of <a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a> (which is the base code they use) and the training time is of the order of seconds even with my poor GTX 1060!!</p>



<a name="455626048"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455626048" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> starseeker <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455626048">(Aug 01 2024 at 11:48)</a>:</h4>
<p>Nuts.  instant-ngp code license is non-commercial only</p>



<a name="455627431"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455627431" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455627431">(Aug 01 2024 at 11:57)</a>:</h4>
<p><span class="user-mention silent" data-user-id="112516">starseeker</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455626048">said</a>:</p>
<blockquote>
<p>Nuts.  instant-ngp code license is non-commercial only</p>
</blockquote>
<p>It’s not so bad, all we need to do is understand their paper and the one that Sean sent. The coding part shouldn’t be difficult even if we have to code from 0.</p>



<a name="455657387"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455657387" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455657387">(Aug 01 2024 at 14:00)</a>:</h4>
<p>Yeah, the implementation seems pretty straightforward.  The main limitation is they didn't get a performance gain.  They train for a few minutes, then ray query performance is on par with the ray tracing time.  The one big gain they saw was getting that on-par ray tracing time with an order of magnitude less memory use.  So exceptional compression in the latent space.</p>



<a name="455659182"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659182" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659182">(Aug 01 2024 at 14:08)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455421932">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> please elaborate, (and point to latest code!) what's the resolution of the grid net, what are the layers, how many epochs, how long did training take, how long does lookup take, etc...</p>
</blockquote>
<p>There are three resolutions: <br>
first,I give up bilinear interpolation and try to learn a matrix to express the relationship between neighboring vectors<br>
second, I consider neighboring vectors in the range 7&times;7 instead of 2&times;2<br>
third, I use a threshold to reduce noise.<br>
here is my codes: <a href="https://github.com/Rainy-fall-end/Rendernn/blob/main/networks/gridnet3.py">https://github.com/Rainy-fall-end/Rendernn/blob/main/networks/gridnet3.py</a><br>
100,000 points need to be sampled, but the model actually converges when <strong>20,000</strong> points are used，The training will take 2 minutes total.(4060)<br>
The yellow curve is the improved gridnet, the purple one is the original gridnet. <br>
<a href="/user_uploads/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png">2024-08-01-220614.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png" title="2024-08-01-220614.png"><img data-original-dimensions="1623x703" src="/user_uploads/thumbnail/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png/840x560.webp"></a></div>



<a name="455659364"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659364" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659364">(Aug 01 2024 at 14:09)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">said</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>But this one looks so much better than mine....</p>



<a name="455659469"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659469" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659469">(Aug 01 2024 at 14:09)</a>:</h4>
<p>Cool, thanks!  I'll take a look in more detail.  Looks like it converges pretty quickly?  How long did it take to get to step 200?</p>



<a name="455659590"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659590" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659590">(Aug 01 2024 at 14:10)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455659364">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">said</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>But this one looks so much better than mine....</p>
</blockquote>
<p>Don't worry about that -- this is very ripe area of research.</p>



<a name="455659621"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659621" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659621">(Aug 01 2024 at 14:10)</a>:</h4>
<p>About 30 seconds.</p>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455659469">said</a>:</p>
<blockquote>
<p>Cool, thanks!  I'll take a look in more detail.  Looks like it converges pretty quickly?  How long did it take to get to step 200?</p>
</blockquote>



<a name="455659622"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455659622" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455659622">(Aug 01 2024 at 14:10)</a>:</h4>
<p>It also means it's worth exploring all avenues as the details matter.</p>



<a name="455660576"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455660576" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455660576">(Aug 01 2024 at 14:15)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455619388">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">ha scritto</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>This is fantastic, I just tried the software of <a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a> (which is the base code they use) and the training time is of the order of seconds even with my poor GTX 1060!!</p>
</blockquote>
<p>This looks like it's implemented in C++, are you going to reproduce it in pytorch?</p>



<a name="455660836"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455660836" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455660836">(Aug 01 2024 at 14:16)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455660576">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455619388">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455558171">ha scritto</a>:</p>
<blockquote>
<p>Shame I didn't notice/read this paper sooner, but looks like this siggraph paper is right on track with what we're trying to achieve with impressive multiviewer results:  <a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>
</blockquote>
<p>This is fantastic, I just tried the software of <a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a> (which is the base code they use) and the training time is of the order of seconds even with my poor GTX 1060!!</p>
</blockquote>
<p>This looks like it's implemented in C++, are you going to reproduce it in pytorch?</p>
</blockquote>
<p>I am still understanding all the ideas of those two papers, but yes probably I will reproduce in pytorch.</p>



<a name="455686227"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455686227" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455686227">(Aug 01 2024 at 15:53)</a>:</h4>
<p>The N-BVH paper was an outstanding talk -- will see if I can get a copy, but it's a direct response to AMD's NIF paper.   They key insight was to not use the ray+dir but to instead use 3 sample points along the ray on the interior of the bounding volume along with a BVH.<br>
<a href="https://weiphil.github.io/portfolio/neural_bvh">https://weiphil.github.io/portfolio/neural_bvh</a></p>



<a name="455686661"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455686661" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455686661">(Aug 01 2024 at 15:55)</a>:</h4>
<p>The key insight of using interior points was demonstrated with just 3-10 sample points which of course made training slower as points are added, but achieved essentially perfect occupancy recall even with high frequency detail.  Adding in a BVH was a training optimization so they could reduce it back down to just 3 points per BVH node.</p>



<a name="455763730"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455763730" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455763730">(Aug 01 2024 at 21:59)</a>:</h4>
<p>I was studying that paper and had a few questions:</p>
<ul>
<li>They mention using a batch size of 2^18 rays, which is 262,144.</li>
<li>They use a total of 100 batches.</li>
</ul>
<p>This means their training set consists of 2^18×100, equating to approximately 26 million rays. Moreover, they state that the training time is at most 2-3 minutes.</p>
<p>I just discovered that it is indeed possible to use such a large batch size (I had been training NIF with a batch size of just 512 rays until now...). However, theory suggests that using a large batch size can increase variance error. Likely, with such a large training set, they do not encounter this issue.</p>
<p>What puzzles me most is how they can achieve convergence in just about 2-3 minutes.</p>
<p>To investigate, I increased the batch size for the NIF model (with which I previously achieved an accuracy of 0.994). As expected, the model trains faster (20 minutes for 1 million rays), and the performance metrics remained roughly the same (just a little worse).</p>



<a name="455764243"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455764243" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455764243">(Aug 01 2024 at 22:02)</a>:</h4>
<p>However, convergence for NIF is much slower than their approach, meaning that training a simple NIF requires more time and results in lower accuracy. Likely, the bounding volume hierarchies approach they use significantly helps the neural network.</p>



<a name="455811517"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455811517" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455811517">(Aug 02 2024 at 03:17)</a>:</h4>
<p>That 262144 is almost certainly a 512x512 grid, 100 different views</p>



<a name="455811606"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455811606" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455811606">(Aug 02 2024 at 03:17)</a>:</h4>
<p>Now have to take performance with a grain of salt.  I didn't see the hardware, but it they're on a high-end GPU, that might be an hour of training on a CPU..</p>



<a name="455812755"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455812755" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455812755">(Aug 02 2024 at 03:24)</a>:</h4>
<p>In their talk the BVH optimization using 3 samples vs 10 samples cut the training time roughly in half (1min)</p>



<a name="455868509"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455868509" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455868509">(Aug 02 2024 at 08:17)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455811606">ha scritto</a>:</p>
<blockquote>
<p>Now have to take performance with a grain of salt.  I didn't see the hardware, but it they're on a high-end GPU, that might be an hour of training on a CPU..</p>
</blockquote>
<p>They used an RTX 3090</p>



<a name="455868781"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455868781" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455868781">(Aug 02 2024 at 08:18)</a>:</h4>
<p>How do you estimate that it would be an hour on a CPU?</p>



<a name="455917973"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455917973" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455917973">(Aug 02 2024 at 12:05)</a>:</h4>
<p>I decided to implement first the multi-resolution hash grid and validate it, then on top of this I will add the BVH approach so as to integrate rays in the 3D grid.</p>



<a name="455987086"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/455987086" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#455987086">(Aug 02 2024 at 17:09)</a>:</h4>
<p>I found this wonderful repository <a href="https://github.com/ashawkey/torch-ngp">https://github.com/ashawkey/torch-ngp</a> and I am using this as a base code for the multi-resolution hash grid.</p>



<a name="456042543"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456042543" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456042543">(Aug 02 2024 at 21:11)</a>:</h4>
<p>I implemented the multi-resolution hash grid and I tested it on top of my previous NIF network. It's incredible how it converges in just few seconds even on my poor gpu.<br>
It achieves only 96% of F1 but it was expected since this encoding is not appropriated for rays+dir input (as we have in NIF) but they are appropriated for 3D points (like in NVBH).<br>
Tomorrow I will focus on this part <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>



<a name="456199833"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456199833" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456199833">(Aug 03 2024 at 18:06)</a>:</h4>
<p><a href="/user_uploads/1549/-Weq4In9RbiGIix2jJyXzhBH/Figure_1.png">Figure_1.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/-Weq4In9RbiGIix2jJyXzhBH/Figure_1.png" title="Figure_1.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/-Weq4In9RbiGIix2jJyXzhBH/Figure_1.png/840x560.webp"></a></div><p><a href="/user_uploads/1549/AQ1sAr9p6ma0ECmaNWiwrNzi/Figure_2.png">Figure_2.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/AQ1sAr9p6ma0ECmaNWiwrNzi/Figure_2.png" title="Figure_2.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/AQ1sAr9p6ma0ECmaNWiwrNzi/Figure_2.png/840x560.webp"></a></div><p>Today I tried the multi-resolution hash grid sampling N points along the the ray. In this picture I sampled 70 points along each ray. I want to mention that this is without the BVH approach but only the multi-grid resolution. The metric F1 is about 0.985 and it converges in few seconds. The training set was about 3 million rays and the picture is 512x512. I noticed that increasing the number of the sampling points, the metrics are better (and without the BVH approach I have to use a lot of sampling points).</p>



<a name="456200003"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456200003" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456200003">(Aug 03 2024 at 18:07)</a>:</h4>
<p>Before implementing the BVH approach I want to try with more samples (like the paper -&gt; 26 millions).</p>



<a name="456289693"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456289693" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456289693">(Aug 04 2024 at 08:55)</a>:</h4>
<p><a href="/user_uploads/1549/wiHYF52ccfUPY3660FQRIV-Z/Figure_1.png">Figure_1.png</a><br>
Here there is the prediction of that image training with only this fixed direction just to prove that this model is perfectly able to discretize IF the number of training samples are sufficient.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/wiHYF52ccfUPY3660FQRIV-Z/Figure_1.png" title="Figure_1.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/wiHYF52ccfUPY3660FQRIV-Z/Figure_1.png/840x560.webp"></a></div>



<a name="456289748"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456289748" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456289748">(Aug 04 2024 at 08:55)</a>:</h4>
<p>Now I will train with 26 million samples.</p>



<a name="456336846"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456336846" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456336846">(Aug 04 2024 at 15:14)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="103542">@Erik</span> Generating 26 million samples takes me several hours. Are there any ways to optimize the ray tracing algorithm in BRL-CAD to speed up the process?</p>



<a name="456383316"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456383316" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456383316">(Aug 04 2024 at 19:46)</a>:</h4>
<p><a href="/user_uploads/1549/l3mtpZ21jSV-7qZn6YobRWJ9/Figure_1.png">Figure_1.png</a><br>
This is with 6 millions rays.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/l3mtpZ21jSV-7qZn6YobRWJ9/Figure_1.png" title="Figure_1.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/l3mtpZ21jSV-7qZn6YobRWJ9/Figure_1.png/840x560.webp"></a></div>



<a name="456674229"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456674229" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456674229">(Aug 05 2024 at 18:34)</a>:</h4>
<p><a href="/user_uploads/1549/HEKDCZBT8G0lFt_qNtprXj8v/Figure_1.png">Figure_1.png</a><br>
This is with 6 million rays BUT generated from 22 different and fixed views (512x512x22) instead of using random sampling. Metrics are  higher with this sampling: I got 0.997 in both accuracy and F1.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/HEKDCZBT8G0lFt_qNtprXj8v/Figure_1.png" title="Figure_1.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/HEKDCZBT8G0lFt_qNtprXj8v/Figure_1.png/840x560.webp"></a></div>



<a name="456710880"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456710880" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456710880">(Aug 05 2024 at 21:28)</a>:</h4>
<p>Curious, <span class="user-mention" data-user-id="702819">@Matteo Balice</span> why 22?  That’s what, 16degrees or so in one axis of rotation?</p>



<a name="456712345"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456712345" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456712345">(Aug 05 2024 at 21:38)</a>:</h4>
<p>Well that is not exactly 22 views. I finally successfully sampled 100 views (thanks to my Mac M1) each with 512x512 rays for a total of 26 millions. However when I load all these rays on PyTorch I go out of memory… so I decided to cut only 6 millions rays.</p>



<a name="456712466"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456712466" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456712466">(Aug 05 2024 at 21:39)</a>:</h4>
<p>But before cutting I randomly shuffle the 26 millions rays, so it is not right to say that they are 22 views.</p>



<a name="456712648"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456712648" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456712648">(Aug 05 2024 at 21:40)</a>:</h4>
<p>Now I am trying a way to load more samples</p>



<a name="456713103"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456713103" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456713103">(Aug 05 2024 at 21:43)</a>:</h4>
<p>So it’s better to say that we have 60k rays for each view (100 views)</p>



<a name="456720557"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456720557" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456720557">(Aug 05 2024 at 22:35)</a>:</h4>
<p><a href="/user_uploads/1549/cW3YboKe-687unME3psHXxvu/Figure_1.png">Figure_1.png</a><br>
10 millions. Getting better <span aria-label="mechanical arm" class="emoji emoji-1f9be" role="img" title="mechanical arm">:mechanical_arm:</span></p>
<div class="message_inline_image"><a href="/user_uploads/1549/cW3YboKe-687unME3psHXxvu/Figure_1.png" title="Figure_1.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/cW3YboKe-687unME3psHXxvu/Figure_1.png/840x560.webp"></a></div>



<a name="456720796"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456720796" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456720796">(Aug 05 2024 at 22:37)</a>:</h4>
<p>Even though there is no much difference with 6 millions... But I noticed that with 10 millions I did not converge in 10 epochs like in 6 millions case... Probably I need to train more.</p>



<a name="456722296"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456722296" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456722296">(Aug 05 2024 at 22:49)</a>:</h4>
<p>(just to be clear: I always print this view because I noticed it’s one of the most difficult to render, but the model is able to render also all the others views)</p>



<a name="456754441"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456754441" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456754441">(Aug 06 2024 at 03:15)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/456336846">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <span class="user-mention silent" data-user-id="103542">Erik</span> Generating 26 million samples takes me several hours. Are there any ways to optimize the ray tracing algorithm in BRL-CAD to speed up the process?</p>
</blockquote>
<p>You can consider using multithreading</p>



<a name="456754872"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456754872" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456754872">(Aug 06 2024 at 03:18)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455494134">said</a>:</p>
<blockquote>
<p>Really cool paper implementation on how to encode BREP in a NNet... <a href="https://github.com/samxuxiang/BrepGen">https://github.com/samxuxiang/BrepGen</a></p>
</blockquote>
<p>But I remember brl-cad doesn't seem to be based on b-rep modeling?</p>



<a name="456865886"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456865886" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456865886">(Aug 06 2024 at 14:09)</a>:</h4>
<p>A great imple implementation of the hash encoding:<a href="https://github.com/yashbhalgat/HashNeRF-pytorch">HashNeRF</a>. It is sad to find that many of my ideas have already been realized, but I'll finish my other ideas on that basis</p>



<a name="456945655"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456945655" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456945655">(Aug 06 2024 at 20:09)</a>:</h4>
<p><a href="/user_uploads/1549/fOru6sTCYngrm3EryRk07X5E/Figure_4.png">Figure_4.png</a><br>
This is with 26 million samples. I had to increase the resolution of hash grid but a lot of white dots appears. It seems that we need to add also the BVH approach so as to delete all these noisy dots.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/fOru6sTCYngrm3EryRk07X5E/Figure_4.png" title="Figure_4.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/fOru6sTCYngrm3EryRk07X5E/Figure_4.png/840x560.webp"></a></div>



<a name="456945699"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456945699" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456945699">(Aug 06 2024 at 20:09)</a>:</h4>
<p>The F1 metric is improved to 0.998</p>



<a name="456969299"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456969299" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456969299">(Aug 06 2024 at 22:26)</a>:</h4>
<p>Don't quite understand how you'd run out of memory.. Is that with replicated view information or with offsets?</p>



<a name="456969830"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456969830" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456969830">(Aug 06 2024 at 22:30)</a>:</h4>
<p>Even with independent 6 doubles (xyz+dir), that should be about 1.1GB, and depending on how that's encoded, that could be reduced to just 4 floats (azel on bounding sphere + azel direction) which is about 400MB for 100x512x512 views.</p>



<a name="456970399"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456970399" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456970399">(Aug 06 2024 at 22:36)</a>:</h4>
<p>Because when I loaded the dataset, I computed 70 points xyz along each rays. So I had in memory 70 points xyz for 26 millions rays</p>



<a name="456970442"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456970442" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456970442">(Aug 06 2024 at 22:36)</a>:</h4>
<p>Now I compute these 70 points only in the forward method of the neural network (so only for the batch).</p>



<a name="456970465"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456970465" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456970465">(Aug 06 2024 at 22:36)</a>:</h4>
<p>For the current batch</p>



<a name="456970542"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456970542" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456970542">(Aug 06 2024 at 22:37)</a>:</h4>
<p>Tomorrow I will upload the code on GitHub</p>



<a name="456971066"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456971066" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456971066">(Aug 06 2024 at 22:42)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/456754872">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455494134">said</a>:</p>
<blockquote>
<p>Really cool paper implementation on how to encode BREP in a NNet... <a href="https://github.com/samxuxiang/BrepGen">https://github.com/samxuxiang/BrepGen</a></p>
</blockquote>
<p>But I remember brl-cad doesn't seem to be based on b-rep modeling?</p>
</blockquote>
<p>Yes and no, <span class="user-mention" data-user-id="700180">@fall Rainy</span> ...  BRL-CAD does have support for BREP models.  They import, display, and raytrace.  There's even some basic tessellation (conversion) and preliminary export support.  There's just not much support yet for editing and we want ray tracing performance to be better before we push it harder. </p>
<p>It's fundamentally no different than all the other primitives, can be used in boolean expressions (which raytrace just fine), can be volumetric/solid or plate-mode like meshes.  There's also some direct Boolean evaluation support which is converting BREP used in CSG expressions to BREP without CSG, but that work is incomplete. </p>
<p>What's really cool about that paper is the figured out how to encode solid geometry (in BREP form) into a NNet.  Not only is that a general concept that extends to other geometry forms, it's a way to actually encode <em>CAD</em> in the latent space, not just SDFs or volume grids or radiance fields.</p>



<a name="456971232"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456971232" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456971232">(Aug 06 2024 at 22:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/456970442">said</a>:</p>
<blockquote>
<p>Now I compute these 70 points only in the forward method of the neural network (so only for the batch).</p>
</blockquote>
<p>Why 70 points??  The paper demonstrated complete convergence with less than 10...</p>



<a name="456971326"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456971326" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456971326">(Aug 06 2024 at 22:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/456971232">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/456970442">said</a>:</p>
<blockquote>
<p>Now I compute these 70 points only in the forward method of the neural network (so only for the batch).</p>
</blockquote>
<p>Why 70 points??  The paper demonstrated complete convergence with less than 10...</p>
</blockquote>
<p>Yes but because they use the BVH</p>



<a name="456971346"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456971346" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456971346">(Aug 06 2024 at 22:44)</a>:</h4>
<p>I don’t have implemented it yet</p>



<a name="456971408"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456971408" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456971408">(Aug 06 2024 at 22:45)</a>:</h4>
<p>This will be the next step</p>



<a name="456974126"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456974126" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456974126">(Aug 06 2024 at 23:13)</a>:</h4>
<p>If I recall correctly, they did not use BVH in their first iterations -- they went from 3 points to 10 points to get convergence.</p>



<a name="456974137"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456974137" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456974137">(Aug 06 2024 at 23:13)</a>:</h4>
<p>They introduced a BVH to make the performance of 10 points take less time than the original 3 points.</p>



<a name="456974213"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/456974213" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#456974213">(Aug 06 2024 at 23:14)</a>:</h4>
<p>So in theory, it should converge just fine with 10 points, just not quickly.  Also means 70 should converge, but in 7x time or more.</p>



<a name="457049083"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457049083" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457049083">(Aug 07 2024 at 08:36)</a>:</h4>
<p><a href="/user_uploads/1549/Oz6oU-8uxT1MBN3eH92Libw7/Figure_6.png">Figure_6.png</a><br>
Here there is the figure with only 10 points... As you can see it's pretty weird and the F1 metric is only about 0.97... Instead, with 70 points I got 0.998 of F1</p>
<div class="message_inline_image"><a href="/user_uploads/1549/Oz6oU-8uxT1MBN3eH92Libw7/Figure_6.png" title="Figure_6.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/Oz6oU-8uxT1MBN3eH92Libw7/Figure_6.png/840x560.webp"></a></div>



<a name="457049562"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457049562" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457049562">(Aug 07 2024 at 08:38)</a>:</h4>
<p>The accuracy should be higher (according to the paper) IF the points are sampled near the surface. So even with 10 points it should be ok IF they are sampled near the surface. But how can we guarantee that they are sampled there if we do not know the intersection of the ray with the surface?</p>



<a name="457049858"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457049858" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457049858">(Aug 07 2024 at 08:40)</a>:</h4>
<p>This is the reason why I uniformly sample along the ray (all the points have the same distance along the ray)... And this is the reason why increasing the number of points it converges with higher accuracy.</p>



<a name="457050306"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457050306" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457050306">(Aug 07 2024 at 08:42)</a>:</h4>
<p>If there is some ideas about smarter sampling along the ray it should improve a lot the model...</p>



<a name="457054489"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457054489" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457054489">(Aug 07 2024 at 08:58)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/457049083">ha scritto</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/Oz6oU-8uxT1MBN3eH92Libw7/Figure_6.png">Figure_6.png</a><br>
Here there is the figure with only 10 points... As you can see it's pretty weird and the F1 metric is only about 0.97... Instead, with 70 points I got 0.998 of F1</p>
</blockquote>
<p>Let's think for instance at the torus in the figure. Why is it so ugly? In my opinion, since we have rays that start and end in a bounding sphere, if we sample along these rays there is a medium/high probability that all the points sampled aren't close to the torus since this one is very thin. And this is the reason why the cube and the sphere are better represented (because their volume is larger and so it is easier that the points are closer to the cube/sphere).</p>



<a name="457055582"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457055582" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457055582">(Aug 07 2024 at 09:01)</a>:</h4>
<p>In my opinion if we use BVHs that wrap the surface, not only we can use less sampling points but I think that also the accuracy must increase.</p>



<a name="457133692"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457133692" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457133692">(Aug 07 2024 at 15:14)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Is the BVH algorithm already implemented in brl-cad?</p>



<a name="457232821"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457232821" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457232821">(Aug 08 2024 at 00:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/456945655">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/fOru6sTCYngrm3EryRk07X5E/Figure_4.png">Figure_4.png</a><br>
This is with 26 million samples. I had to increase the resolution of hash grid but a lot of white dots appears. It seems that we need to add also the BVH approach so as to delete all these noisy dots.</p>
</blockquote>
<p>Add a threshold layer before output may solve this question.</p>



<a name="457293495"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457293495" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457293495">(Aug 08 2024 at 07:54)</a>:</h4>
<p>I'd like to combine these tricks with the hashencoder to see how much improvement can be gained</p>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455659182">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/455421932">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> please elaborate, (and point to latest code!) what's the resolution of the grid net, what are the layers, how many epochs, how long did training take, how long does lookup take, etc...</p>
</blockquote>
<p>There are three resolutions: <br>
first,I give up bilinear interpolation and try to learn a matrix to express the relationship between neighboring vectors<br>
second, I consider neighboring vectors in the range 7×7 instead of 2×2<br>
third, I use a threshold to reduce noise.<br>
here is my codes: <a href="https://github.com/Rainy-fall-end/Rendernn/blob/main/networks/gridnet3.py">https://github.com/Rainy-fall-end/Rendernn/blob/main/networks/gridnet3.py</a><br>
100,000 points need to be sampled, but the model actually converges when <strong>20,000</strong> points are used，The training will take 2 minutes total.(4060)<br>
The yellow curve is the improved gridnet, the purple one is the original gridnet. <br>
<a href="/user_uploads/1549/Gzl76_z3fF_bVI5hztuH4h9T/2024-08-01-220614.png">2024-08-01-220614.png</a></p>
</blockquote>



<a name="457295474"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/457295474" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#457295474">(Aug 08 2024 at 08:02)</a>:</h4>
<p>Of course, there are some other things that need to be improved</p>
<ol>
<li>most of the current hashencoder are for Cartesian coordinates, and I'd like to implement it with spherical coordinates(two version, both dir and pos imported as inputs, only pos imported as inputs)</li>
<li>Modification of the Neighborhood Algorithm. The range of spherical coordinate is [0,pi] and [0,2pi]. 0 and pi actually represent the same point</li>
<li>Improved initialization strategy. During my training, I found that I could initialize the output of the model to 0, 0, 0 instead of [127.5,127.5,127.5] and it would be beneficial for the model to converge</li>
</ol>



<a name="459666499"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459666499" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459666499">(Aug 10 2024 at 09:50)</a>:</h4>
<p><a href="/user_uploads/1549/a2vxhbcEws9G8fld72oTmFka/Figure_13.png">Figure_13.png</a><br>
I finally achieved the 0.9991 of F1 overtraining with 200 points for each ray and 26 millions total rays. I modified  the prediction so that for each ray, I take only the maximum of those 200 points and if it is greater than 0.5 it is a hit, otherwise it's a miss. It's like we have a voxel grid, in which for each voxel we have a probability of a hit/miss.</p>
<div class="message_inline_image"><a href="/user_uploads/1549/a2vxhbcEws9G8fld72oTmFka/Figure_13.png" title="Figure_13.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/a2vxhbcEws9G8fld72oTmFka/Figure_13.png/840x560.webp"></a></div>



<a name="459666736"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459666736" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459666736">(Aug 10 2024 at 09:52)</a>:</h4>
<p>Of course it's much slower BUT I have an idea. We can train the multi-resolution grid in this way (using a lot of points for each ray) but after the training we can take the grid already trained and build another model on top of this (without editing the grid) trying to predict the right "voxel" for each ray. We can leverage the fact that closest rays have closest "voxels" hit.</p>



<a name="459666991"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459666991" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459666991">(Aug 10 2024 at 09:54)</a>:</h4>
<p>And trying to build an hashmap (similar as the grid encoding) so that for each input ray we have an O(1) complexity to retrieve the right voxel and then the inference process would be very fast!</p>



<a name="459667012"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459667012" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459667012">(Aug 10 2024 at 09:54)</a>:</h4>
<p>If this works, it could be even faster than the paper of nvbh!</p>



<a name="459715335"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459715335" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459715335">(Aug 10 2024 at 15:43)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/457133692">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> Is the BVH algorithm already implemented in brl-cad?</p>
</blockquote>
<p>Yes there is, see src/librt/cut_hlbvh.*</p>



<a name="459715561"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459715561" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459715561">(Aug 10 2024 at 15:45)</a>:</h4>
<p>See it in use in clt_prep() in src/librt/prep.cpp</p>



<a name="459715953"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459715953" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459715953">(Aug 10 2024 at 15:48)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/457295474">said</a>:</p>
<blockquote>
<ol start="3">
<li>Improved initialization strategy. During my training, I found that I could initialize the output of the model to 0, 0, 0 instead of [127.5,127.5,127.5] and it would be beneficial for the model to converge</li>
</ol>
</blockquote>
<p>That's one of the optimizations mentioned in the paper -- the model is not only normalized in position, but also scaled/centered/normalized in size also.  So values are all 0 to 1 or -1 to 1 for XYZ.  That was pretty essential in limiting the training space.</p>



<a name="459717554"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459717554" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459717554">(Aug 10 2024 at 15:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/459666499">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/a2vxhbcEws9G8fld72oTmFka/Figure_13.png">Figure_13.png</a><br>
I finally achieved the 0.9991 of F1 overtraining with 200 points for each ray and 26 millions total rays. I modified  the prediction so that for each ray, I take only the maximum of those 200 points and if it is greater than 0.5 it is a hit, otherwise it's a miss. It's like we have a voxel grid, in which for each voxel we have a probability of a hit/miss.</p>
</blockquote>
<p>Please show the code for what you're doing here?  That's definitely interesting results, but I'm still not understanding why you need 70 or 200 sample points.  I get that it's sampling like a voxel grid, but that shouldn't be necessary (and degenerates to a simple grid query).  Implies some fundamental difference in setup or evaluation.  What's the network you're using at this point?</p>



<a name="459717703"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459717703" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459717703">(Aug 10 2024 at 15:57)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/459717554">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/459666499">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/a2vxhbcEws9G8fld72oTmFka/Figure_13.png">Figure_13.png</a><br>
I finally achieved the 0.9991 of F1 overtraining with 200 points for each ray and 26 millions total rays. I modified  the prediction so that for each ray, I take only the maximum of those 200 points and if it is greater than 0.5 it is a hit, otherwise it's a miss. It's like we have a voxel grid, in which for each voxel we have a probability of a hit/miss.</p>
</blockquote>
<p>Please show the code for what you're doing here?  That's definitely interesting results, but I'm still not understanding why you need 70 or 200 sample points.  I get that it's sampling like a voxel grid, but that shouldn't be necessary (and degenerates to a simple grid query).  Implies some fundamental difference in setup or evaluation.  What's the network you're using at this point?</p>
</blockquote>
<p>I'm going to upload the code in half an hour more or less.</p>



<a name="459719976"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459719976" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459719976">(Aug 10 2024 at 16:08)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="700180">@fall Rainy</span>  <a href="https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh">https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh</a></p>



<a name="459720238"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459720238" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459720238">(Aug 10 2024 at 16:09)</a>:</h4>
<p>We can summarize the neural network in this picture:</p>
<p><a href="/user_uploads/1549/UJc1UPO9wgIZQ3IAaCtdbkvA/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/UJc1UPO9wgIZQ3IAaCtdbkvA/image.png" title="image.png"><img data-original-dimensions="1101x733" src="/user_uploads/thumbnail/1549/UJc1UPO9wgIZQ3IAaCtdbkvA/image.png/840x560.webp"></a></div>



<a name="459720533"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459720533" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459720533">(Aug 10 2024 at 16:10)</a>:</h4>
<p>In the prediction (forward method),  I take the ray, sample n points along the ray, then I pass this to the encoder and finally the embedding are scaled to a probability [0;1]</p>



<a name="459720958"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459720958" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459720958">(Aug 10 2024 at 16:12)</a>:</h4>
<p>In the end, for each ray I take the maximum for all the points sampled and this works well because:</p>
<ul>
<li>if the ray is a miss, all the points must have a probability less than 0.5 so taking the maximum it's ok.</li>
<li>if the ray is a hit, there should be at least one voxel in the ray that has a probability greater than 0.5 and using the maximum it's ok.</li>
</ul>



<a name="459721196"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459721196" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459721196">(Aug 10 2024 at 16:15)</a>:</h4>
<p>This neural network works well in the training of the multi-resolution hash grid. My idea is to use the trained grid of this network as a base for another network much simpler and that uses less points. Do you have some ideas how to achieve this result (I proposed the idea of the hashmap; the paper used the BVH approach for instance)?</p>



<a name="459723073"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459723073" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459723073">(Aug 10 2024 at 16:31)</a>:</h4>
<p>I would also remark some differences about the nvbh paper:<br>
<a href="/user_uploads/1549/GlDBhRy6KFBm6KZZfNjWNuqh/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/GlDBhRy6KFBm6KZZfNjWNuqh/image.png" title="image.png"><img data-original-dimensions="513x175" src="/user_uploads/thumbnail/1549/GlDBhRy6KFBm6KZZfNjWNuqh/image.png/840x560.webp"></a></div><ul>
<li>They used an MLP network with 4 hidden layers (each with relu) and a sigmoid as output but I simply use one single sigmoid layer as output without any hidden layer. (better in my network)</li>
<li>They used 8 levels for the grid, I use 4 levels. (better in my network)</li>
<li>They used a very high base resolution (8^3=512), I simply use 32 or 16 as a base resolution. (better in my network)</li>
<li>They used 4 features per level, I use 8 features. I have to try with 4 features. (better in their network)</li>
</ul>



<a name="459723540"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459723540" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459723540">(Aug 10 2024 at 16:35)</a>:</h4>
<p>Overall my network is much faster than theirs (if we do not take into consideration the sampling points part).</p>



<a name="459933078"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459933078" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459933078">(Aug 11 2024 at 19:29)</a>:</h4>
<p><a href="/user_uploads/1549/yw-Rbx5MnwH0UDPIpNO6yOz-/Screenshot-2024-08-11-alle-21.27.55.png">Screenshot-2024-08-11-alle-21.27.55.png</a><br>
<a href="/user_uploads/1549/wltuTHGZA2WdV7lxsLrq8ch3/Screenshot-2024-08-11-alle-21.28.26.png">Screenshot-2024-08-11-alle-21.28.26.png</a><br>
<a href="/user_uploads/1549/aAzMEEYL8G1HwPkQjBOYAaAY/Screenshot-2024-08-11-alle-21.28.51.png">Screenshot-2024-08-11-alle-21.28.51.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/yw-Rbx5MnwH0UDPIpNO6yOz-/Screenshot-2024-08-11-alle-21.27.55.png" title="Screenshot-2024-08-11-alle-21.27.55.png"><img data-original-dimensions="1244x908" src="/user_uploads/thumbnail/1549/yw-Rbx5MnwH0UDPIpNO6yOz-/Screenshot-2024-08-11-alle-21.27.55.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/wltuTHGZA2WdV7lxsLrq8ch3/Screenshot-2024-08-11-alle-21.28.26.png" title="Screenshot-2024-08-11-alle-21.28.26.png"><img data-original-dimensions="1376x946" src="/user_uploads/thumbnail/1549/wltuTHGZA2WdV7lxsLrq8ch3/Screenshot-2024-08-11-alle-21.28.26.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/aAzMEEYL8G1HwPkQjBOYAaAY/Screenshot-2024-08-11-alle-21.28.51.png" title="Screenshot-2024-08-11-alle-21.28.51.png"><img data-original-dimensions="1462x872" src="/user_uploads/thumbnail/1549/aAzMEEYL8G1HwPkQjBOYAaAY/Screenshot-2024-08-11-alle-21.28.51.png/840x560.webp"></a></div><p>I have implemented an hierarchy of bbox like in a tree.</p>



<a name="459933361"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459933361" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459933361">(Aug 11 2024 at 19:30)</a>:</h4>
<p>My idea is to leverage this architecture so as to retrieve all the leaf nodes of a given ray.</p>
<p><a href="/user_uploads/1549/UL0nE-uamiygpROdSf0zd-5_/Screenshot-2024-08-11-alle-21.30.39.png">Screenshot-2024-08-11-alle-21.30.39.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/UL0nE-uamiygpROdSf0zd-5_/Screenshot-2024-08-11-alle-21.30.39.png" title="Screenshot-2024-08-11-alle-21.30.39.png"><img data-original-dimensions="1038x806" src="/user_uploads/thumbnail/1549/UL0nE-uamiygpROdSf0zd-5_/Screenshot-2024-08-11-alle-21.30.39.png/840x560.webp"></a></div>



<a name="459933449"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459933449" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459933449">(Aug 11 2024 at 19:31)</a>:</h4>
<p>And moreover, we can precompute all the leaf nodes for all the rays with a given tolerance.</p>



<a name="459933567"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/459933567" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#459933567">(Aug 11 2024 at 19:32)</a>:</h4>
<p>In this way the sampling parts of the NN should be way faster (less points to sample)</p>



<a name="460108757"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/460108757" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#460108757">(Aug 12 2024 at 15:49)</a>:</h4>
<p>with hashnet: 1 million data, 1 minute to train(4060) <br>
<a href="/user_uploads/1549/js-AL4Qkg5yp_ebMue0BpNg5/hashnet.png">hashnet.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/js-AL4Qkg5yp_ebMue0BpNg5/hashnet.png" title="hashnet.png"><img data-original-dimensions="754x802" src="/user_uploads/thumbnail/1549/js-AL4Qkg5yp_ebMue0BpNg5/hashnet.png/840x560.webp"></a></div>



<a name="460109337"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/460109337" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#460109337">(Aug 12 2024 at 15:53)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/460108757">ha scritto</a>:</p>
<blockquote>
<p>with hashnet: 1 million data, 1 minute to train(4060) <br>
<a href="/user_uploads/1549/js-AL4Qkg5yp_ebMue0BpNg5/hashnet.png">hashnet.png</a></p>
</blockquote>
<p>Does this work with arbitary rays or only with fixed directions?</p>



<a name="460109431"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/460109431" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#460109431">(Aug 12 2024 at 15:53)</a>:</h4>
<p>In a small range</p>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/460109337">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/460108757">ha scritto</a>:</p>
<blockquote>
<p>with hashnet: 1 million data, 1 minute to train(4060) <br>
<a href="/user_uploads/1549/js-AL4Qkg5yp_ebMue0BpNg5/hashnet.png">hashnet.png</a></p>
</blockquote>
<p>Does this work with arbitary rays or only with fixed directions?</p>
</blockquote>



<a name="461940975"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/461940975" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#461940975">(Aug 12 2024 at 19:37)</a>:</h4>
<p>I am currently recording predicting times of my network and I got these results (for 1024x1024) with batch size of 8k:</p>
<ul>
<li>if I sample 200 points I have 0.1004147 s = 100ms</li>
<li>if I sample 3 points (like in the paper) I have 0.123648 s = 124 ms<br>
So it seems that the rendering times are independent from the number of points sampled (and I cannot understand why). It seems pretty strange.</li>
</ul>



<a name="461941013"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/461941013" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#461941013">(Aug 12 2024 at 19:37)</a>:</h4>
<p>Here in the picture there are the times of the paper:</p>
<p><a href="/user_uploads/1549/RJ8jojM6KUGpxh-OCgtYxwhC/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/RJ8jojM6KUGpxh-OCgtYxwhC/image.png" title="image.png"><img data-original-dimensions="279x292" src="/user_uploads/thumbnail/1549/RJ8jojM6KUGpxh-OCgtYxwhC/image.png/840x560.webp"></a></div>



<a name="461941374"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/461941374" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#461941374">(Aug 12 2024 at 19:39)</a>:</h4>
<p>In my opinion my network is better in rendering times because I use batch sizes of only 8k. They instead used 260k as batch size.</p>



<a name="461941501"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/461941501" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#461941501">(Aug 12 2024 at 19:40)</a>:</h4>
<p>I have bought an RTX 4070 and in these days I will set up it on my PC</p>



<a name="461941601"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/461941601" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#461941601">(Aug 12 2024 at 19:40)</a>:</h4>
<p>I will re-record times on my new rtx using their same batch size.</p>



<a name="462077254"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462077254" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462077254">(Aug 13 2024 at 10:39)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/461940975">said</a>:</p>
<blockquote>
<p>I am currently recording predicting times of my network and I got these results (for 1024x1024) with batch size of 8k:</p>
<ul>
<li>if I sample 200 points I have 0.1004147 s = 100ms</li>
<li>if I sample 3 points (like in the paper) I have 0.123648 s = 124 ms<br>
So it seems that the rendering times are independent from the number of points sampled (and I cannot understand why). It seems pretty strange.</li>
</ul>
</blockquote>
<p>This may be due to the GPU's acceleration in matrix computation</p>



<a name="462106561"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462106561" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462106561">(Aug 13 2024 at 12:52)</a>:</h4>
<p>I think I need to compare the same object as in the paper.</p>



<a name="462106605"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462106605" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462106605">(Aug 13 2024 at 12:52)</a>:</h4>
<p>And using the same batch size as theirs</p>



<a name="462106670"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462106670" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462106670">(Aug 13 2024 at 12:53)</a>:</h4>
<p>Because otherwise results are not comparable</p>



<a name="462146237"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462146237" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462146237">(Aug 13 2024 at 15:29)</a>:</h4>
<p>I installed the new RTX 4070, but I discovered today that the power supply is no longer sufficient. I’ve ordered a new power supply, but it hasn’t arrived yet (hopefully it’ll be here by tomorrow), so I’ll be without a PC for a couple of days.</p>



<a name="462264743"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462264743" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462264743">(Aug 14 2024 at 05:12)</a>:</h4>
<p>It would be very good if you're going to follow their approach <span class="user-mention" data-user-id="702819">@Matteo Balice</span> to see if you can indeed match their results.  If you can, then everything you're learning and asserting  with different geometry is new insight.  If you can't, then that may lead to discovering where there are differences/bugs/issues/assumptions that need to be considered.</p>



<a name="462405916"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462405916" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462405916">(Aug 14 2024 at 19:30)</a>:</h4>
<p><a href="/user_uploads/1549/HLYo5wThAzE2atyvTQ5Cv45n/img-2025_Ym53QguN.mp4">img-2025_Ym53QguN.mp4</a><br>
Today I had implemented a 3D visualizer directly in python.</p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/HLYo5wThAzE2atyvTQ5Cv45n/img-2025_Ym53QguN.mp4" title="img-2025_Ym53QguN.mp4"><video preload="metadata" src="/user_uploads/1549/HLYo5wThAzE2atyvTQ5Cv45n/img-2025_Ym53QguN.mp4"></video></a></div>



<a name="462405975"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462405975" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462405975">(Aug 14 2024 at 19:31)</a>:</h4>
<p>In this way it's easier to see how much the model is predicting well.</p>



<a name="462406887"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/462406887" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#462406887">(Aug 14 2024 at 19:39)</a>:</h4>
<p>All the frames are rendered with the neural network.</p>



<a name="463153096"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463153096" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463153096">(Aug 18 2024 at 11:39)</a>:</h4>
<p><a href="/user_uploads/1549/bypXCbYNWa3dvKcjR_29uzF0/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/bypXCbYNWa3dvKcjR_29uzF0/image.png" title="image.png"><img data-original-dimensions="351x202" src="/user_uploads/thumbnail/1549/bypXCbYNWa3dvKcjR_29uzF0/image.png/840x560.webp"></a></div><p>This is the "statuette" model by the nbvh paper with the memory and render times.<br>
<a href="/user_uploads/1549/jvF1kD4fHaloSGkIiiN_pdWP/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/jvF1kD4fHaloSGkIiiN_pdWP/image.png" title="image.png"><img data-original-dimensions="677x117" src="/user_uploads/thumbnail/1549/jvF1kD4fHaloSGkIiiN_pdWP/image.png/840x560.webp"></a></div><p>These are the memory and render times of my network in pytorch:<br>
Memory: 27mb<br>
Render time: 20,68 ms</p>
<p>Regarding the memory, I believe that the grid network I use as base model does not compress a lot the grid itself.<br>
About rendering times, I think they are good because of course python is much slower than C++ (their code is in C++).<br>
Moreover, you have to take into consideration also a small overhead in my rendering time due to the conversion to spherical to cartesian coordinates (because my training set is in spherical coordinates as previous methods), but this can be easily avoided.</p>



<a name="463153393"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463153393" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463153393">(Aug 18 2024 at 11:41)</a>:</h4>
<p>About the error, I got the same as the last model (F1 of about 0.9991)</p>



<a name="463380787"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463380787" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463380787">(Aug 19 2024 at 11:46)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="700180">@fall Rainy</span> I have figured out why in my network using N = 200 has the same speed as N = 3. The difference with the NBVH network is that they encode N = 3 points and then they concatenate all of these 3 points in order so as to include also the direction of the vector. But the main difference is that the input of their network has 3 * number of features for each point.<br>
In my case it is different because I get 200 points BUT I compute in parallel all of these 200 points, so the input of my network is only 1 * number of features for each point because I do not need the direction of the ray (I just have to predict whether the voxel is hit/miss).</p>
<p><a href="/user_uploads/1549/tspuu5sV8wmSKMepEDucXTd1/photo_2024-08-19_13-41-50.jpg">photo_2024-08-19_13-41-50.jpg</a><br>
(sorry for my bad handwriting).</p>
<div class="message_inline_image"><a href="/user_uploads/1549/tspuu5sV8wmSKMepEDucXTd1/photo_2024-08-19_13-41-50.jpg" title="photo_2024-08-19_13-41-50.jpg"><img data-original-dimensions="844x722" src="/user_uploads/thumbnail/1549/tspuu5sV8wmSKMepEDucXTd1/photo_2024-08-19_13-41-50.jpg/840x560.webp"></a></div>



<a name="463392331"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463392331" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463392331">(Aug 19 2024 at 12:42)</a>:</h4>
<p>I had a talk on LinkedIn with Philippe Weier, the author of the nbvh paper and he said to me that the inference time of one ray depends on the time of computing the intersection of the ray with the first node + the time of getting the three points + the time of prediction. Then, if it is a miss, you should add the time of computing the intersection of the second node + etc...</p>
<p>I believe that their network can be improved using this approach:<br>
instead of using the bvh, we can simply get N = 201 points and merging them in order in triples of three points (67 triples). In this way we can parallelize all these computations in GPU and take only the informations on the first hit. I think it should be faster than the bvh approach.</p>



<a name="463393344"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463393344" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463393344">(Aug 19 2024 at 12:45)</a>:</h4>
<p>It sounds a little like volume rendering</p>



<a name="463393727"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463393727" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463393727">(Aug 19 2024 at 12:46)</a>:</h4>
<p>Yes, it's like it</p>



<a name="463394278"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463394278" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463394278">(Aug 19 2024 at 12:47)</a>:</h4>
<p>Today I was thinking that the multi resolution hash encoding isn't very far from nif network</p>



<a name="463394430"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463394430" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463394430">(Aug 19 2024 at 12:47)</a>:</h4>
<p>For example the grid encode they use has the bilinear interpolation</p>



<a name="463394535"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463394535" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463394535">(Aug 19 2024 at 12:48)</a>:</h4>
<p>But it is more like voxels</p>



<a name="463394659"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463394659" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463394659">(Aug 19 2024 at 12:48)</a>:</h4>
<p>Maybe attach more information, like whether the point is visible or not, and then do an integration at the end</p>



<a name="463394902"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463394902" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463394902">(Aug 19 2024 at 12:49)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/463394278">said</a>:</p>
<blockquote>
<p>Today I was thinking that the multi resolution hash encoding isn't very far from nif network</p>
</blockquote>
<p>Yes, it has the advantage of being more efficient in the use of voxels</p>



<a name="463395163"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463395163" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463395163">(Aug 19 2024 at 12:50)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/463394659">ha scritto</a>:</p>
<blockquote>
<p>Maybe attach more information, like whether the point is visible or not, and then do an integration at the end</p>
</blockquote>
<p>Yes</p>



<a name="463395404"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463395404" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463395404">(Aug 19 2024 at 12:50)</a>:</h4>
<p>I'd like to make some attempts as well, do you currently have the code for that?</p>



<a name="463396279"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463396279" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463396279">(Aug 19 2024 at 12:53)</a>:</h4>
<p>No, I have only my network to predict hit/miss here but you can easily adapt for your task <a href="https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh">https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh</a></p>



<a name="463396681"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463396681" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463396681">(Aug 19 2024 at 12:54)</a>:</h4>
<p>Actually, I think it's kind of like a combination of nbvh and nerf.</p>



<a name="463397357"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/463397357" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#463397357">(Aug 19 2024 at 12:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/463396279">said</a>:</p>
<blockquote>
<p>No, I have only my network to predict hit/miss here but you can easily adapt for your task <a href="https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh">https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh</a></p>
</blockquote>
<p>Thx</p>



<a name="464010858"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464010858" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464010858">(Aug 21 2024 at 10:38)</a>:</h4>
<p>I got another improvement in both rendering time and memory. Talking with the author of nbvh he suggested me to use only 1 number as the dimension of each level (and he was right because I only need to predict visibility ie the shape of the object).<br>
Here it is the grid:<br>
<a href="/user_uploads/1549/wcgJrdT6FqnT1BYbTLnbJjlv/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/wcgJrdT6FqnT1BYbTLnbJjlv/image.png" title="image.png"><img data-original-dimensions="1116x141" src="/user_uploads/thumbnail/1549/wcgJrdT6FqnT1BYbTLnbJjlv/image.png/840x560.webp"></a></div><p>Moreover, now the statistics are:</p>
<p>memory usage: 4,3mb<br>
max inference time: 5,2 ms in 1920x1080 (assuming all rays hit the bounding sphere, otherwise the time is lower)</p>
<p>These statistics are indipendent from the object encoded. I have tried with moss.g and statuette (one of their object) and the reason is very simple: I do not use any bvh, so every ray will have the same inference time IF the grid is the same between object. The only thing that can change between objects is the metric F1, because some objects can have small details that are more complex to encode but using this grid is ok both for moss.g and statuette.</p>



<a name="464011085"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464011085" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464011085">(Aug 21 2024 at 10:40)</a>:</h4>
<p>I have written some metrics here if you are interested:</p>
<p>NBVH<br>
hardware: RTX 4070 12GB<br>
batch size: 2^14 (16'384 rays)</p>
<p>Both models achieve 0.9991 F1 with 26 millions rays in about 10 minutes<br>
memory usage: 4,3mb<br>
max inference time: 5,2 ms in 1920x1080 (assuming all rays hit the bounding sphere)</p>
<p>MOSS MODEL<br>
training set: 1 million rays<br>
training time: 47 seconds<br>
F1: 0.9958</p>
<p>training set: 5 million rays<br>
training time: 4 min 10 sec<br>
F1: 0.9974</p>
<p>STATUETTE MODEL<br>
training set: 1 million rays<br>
training time: 40 seconds<br>
F1: 0.9942</p>
<p>training set: 5 million rays<br>
training time: 4 min<br>
F1: 0.9972</p>



<a name="464083920"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464083920" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464083920">(Aug 21 2024 at 15:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/463396279">said</a>:</p>
<blockquote>
<p>No, I have only my network to predict hit/miss here but you can easily adapt for your task <a href="https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh">https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh</a></p>
</blockquote>
<p>I read these codes. It still looks like gridnet&amp;hashnet? not nbvh</p>



<a name="464084356"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464084356" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464084356">(Aug 21 2024 at 15:07)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464083920">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/463396279">said</a>:</p>
<blockquote>
<p>No, I have only my network to predict hit/miss here but you can easily adapt for your task <a href="https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh">https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh</a></p>
</blockquote>
<p>I read these codes. It still looks like gridnet&amp;hashnet? not nbvh</p>
</blockquote>
<p>Yes I call it nbvh but it is only hashnet and gridnet</p>



<a name="464084608"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464084608" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464084608">(Aug 21 2024 at 15:08)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464010858">said</a>:</p>
<blockquote>
<p>I got another improvement in both rendering time and memory. Talking with the author of nbvh he suggested me to use only 1 number as the dimension of each level (and he was right because I only need to predict visibility ie the shape of the object).<br>
Here it is the grid:<br>
<a href="/user_uploads/1549/wcgJrdT6FqnT1BYbTLnbJjlv/image.png">image.png</a></p>
<p>Moreover, now the statistics are:</p>
<p>memory usage: 4,3mb<br>
max inference time: 5,2 ms in 1920x1080 (assuming all rays hit the bounding sphere, otherwise the time is lower)</p>
<p>These statistics are indipendent from the object encoded. I have tried with moss.g and statuette (one of their object) and the reason is very simple: I do not use any bvh, so every ray will have the same inference time IF the grid is the same between object. The only thing that can change between objects is the metric F1, because some objects can have small details that are more complex to encode but using this grid is ok both for moss.g and statuette.</p>
</blockquote>
<p>what do you mean about 1920×1080?</p>



<a name="464084672"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464084672" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464084672">(Aug 21 2024 at 15:09)</a>:</h4>
<p>The resolution of the rendering</p>



<a name="464085266"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464085266" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464085266">(Aug 21 2024 at 15:11)</a>:</h4>
<p>I am using your rgb training set now and I have one picture to show you</p>



<a name="464085519"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464085519" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464085519">(Aug 21 2024 at 15:12)</a>:</h4>
<p>I've actually found out before. And for rgb prediction, dimension=3 is better</p>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464010858">said</a>:</p>
<blockquote>
<p>I got another improvement in both rendering time and memory. Talking with the author of nbvh he suggested me to use only 1 number as the dimension of each level (and he was right because I only need to predict visibility ie the shape of the object).<br>
Here it is the grid:<br>
<a href="/user_uploads/1549/wcgJrdT6FqnT1BYbTLnbJjlv/image.png">image.png</a></p>
<p>Moreover, now the statistics are:</p>
<p>memory usage: 4,3mb<br>
max inference time: 5,2 ms in 1920x1080 (assuming all rays hit the bounding sphere, otherwise the time is lower)</p>
<p>These statistics are indipendent from the object encoded. I have tried with moss.g and statuette (one of their object) and the reason is very simple: I do not use any bvh, so every ray will have the same inference time IF the grid is the same between object. The only thing that can change between objects is the metric F1, because some objects can have small details that are more complex to encode but using this grid is ok both for moss.g and statuette.</p>
</blockquote>



<a name="464085960"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464085960" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464085960">(Aug 21 2024 at 15:14)</a>:</h4>
<p><a href="/user_uploads/1549/Yzw3H71LfxFycYoA1gQXnAz9/image.png">image.png</a><br>
The torch.max is not suitable for rgb prediction</p>
<div class="message_inline_image"><a href="/user_uploads/1549/Yzw3H71LfxFycYoA1gQXnAz9/image.png" title="image.png"><img data-original-dimensions="492x370" src="/user_uploads/thumbnail/1549/Yzw3H71LfxFycYoA1gQXnAz9/image.png/840x560.webp"></a></div>



<a name="464086346"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464086346" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464086346">(Aug 21 2024 at 15:15)</a>:</h4>
<p>You can do it with this:</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># map output to 0,1</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span> <span class="c1">#Reducing noise</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">255</span> <span class="c1">#map output to 0,255</span>
</code></pre></div>



<a name="464086480"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464086480" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464086480">(Aug 21 2024 at 15:16)</a>:</h4>
<p>Is this differentiable?</p>



<a name="464086533"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464086533" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464086533">(Aug 21 2024 at 15:16)</a>:</h4>
<p>Yes(I think so</p>



<a name="464086559"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464086559" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464086559">(Aug 21 2024 at 15:16)</a>:</h4>
<p>Because I tried something similar but it wasnt differentiable</p>



<a name="464086766"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464086766" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464086766">(Aug 21 2024 at 15:17)</a>:</h4>
<p>Have you tried rgb with hashnet&amp;gridnet?</p>



<a name="464086972"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464086972" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464086972">(Aug 21 2024 at 15:17)</a>:</h4>
<p>This is my res:<br>
<a href="/user_uploads/1549/lK5GZq7FbUR887ubpqW9lG_O/91aa8fe67e981e4ed47dc11c6bda546.png">91aa8fe67e981e4ed47dc11c6bda546.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/lK5GZq7FbUR887ubpqW9lG_O/91aa8fe67e981e4ed47dc11c6bda546.png" title="91aa8fe67e981e4ed47dc11c6bda546.png"><img data-original-dimensions="766x816" src="/user_uploads/thumbnail/1549/lK5GZq7FbUR887ubpqW9lG_O/91aa8fe67e981e4ed47dc11c6bda546.png/840x560.webp"></a></div>



<a name="464087161"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087161" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087161">(Aug 21 2024 at 15:18)</a>:</h4>
<p>Does it work with all directions?</p>



<a name="464087179"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087179" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087179">(Aug 21 2024 at 15:18)</a>:</h4>
<p>with 1million rays to train</p>



<a name="464087219"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087219" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087219">(Aug 21 2024 at 15:18)</a>:</h4>
<p>Just for fixed direction</p>



<a name="464087351"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087351" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087351">(Aug 21 2024 at 15:19)</a>:</h4>
<p>Ah ok</p>



<a name="464087396"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087396" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087396">(Aug 21 2024 at 15:19)</a>:</h4>
<p>For all directions, I'm getting similar results to you.</p>



<a name="464087573"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087573" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087573">(Aug 21 2024 at 15:20)</a>:</h4>
<p>For all directions, my predictions for binary classification actually turned out pretty well</p>



<a name="464087673"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087673" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087673">(Aug 21 2024 at 15:20)</a>:</h4>
<p>I'll organize the results tomorrow.</p>



<a name="464087716"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087716" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087716">(Aug 21 2024 at 15:20)</a>:</h4>
<p>ok good</p>



<a name="464087935"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464087935" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464087935">(Aug 21 2024 at 15:21)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464085960">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/Yzw3H71LfxFycYoA1gQXnAz9/image.png">image.png</a><br>
The torch.max is not suitable for rgb prediction</p>
</blockquote>
<p>This image doesn't look like it's been rendered by brl-cad</p>



<a name="464088044"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088044" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088044">(Aug 21 2024 at 15:21)</a>:</h4>
<p>it's in python</p>



<a name="464088116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088116">(Aug 21 2024 at 15:21)</a>:</h4>
<p>OK, got it</p>



<a name="464088283"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088283" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088283">(Aug 21 2024 at 15:21)</a>:</h4>
<p>they are rgb colors of the pygame renderer</p>



<a name="464088370"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088370" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088370">(Aug 21 2024 at 15:22)</a>:</h4>
<p>it's a python library</p>



<a name="464088484"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088484" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088484">(Aug 21 2024 at 15:22)</a>:</h4>
<p>I will show all of my results here: <a href="https://docs.google.com/document/d/1-mp9u9IhesOGkq6bs2UvucQAj-iNafe-nx8Xr3rK3a0/edit#heading=h.wqr1x1wu0z7r">neural rendering</a></p>



<a name="464088583"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088583" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088583">(Aug 21 2024 at 15:23)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464088283">said</a>:</p>
<blockquote>
<p>they are rgb colors of the pygame renderer</p>
</blockquote>
<p>The resulting graph is very nice.</p>



<a name="464088650"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088650" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088650">(Aug 21 2024 at 15:23)</a>:</h4>
<p>which graph</p>



<a name="464088738"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088738" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088738">(Aug 21 2024 at 15:23)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464085960">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/Yzw3H71LfxFycYoA1gQXnAz9/image.png">image.png</a><br>
The torch.max is not suitable for rgb prediction</p>
</blockquote>
<p>this one</p>



<a name="464088876"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464088876" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464088876">(Aug 21 2024 at 15:24)</a>:</h4>
<p>Looks more like a point cloud map.</p>



<a name="464089105"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464089105" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464089105">(Aug 21 2024 at 15:25)</a>:</h4>
<p>well, this is because at the moment if the ray intersects 2 or more surfaces, my network does not know which color to show</p>



<a name="464089134"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464089134" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464089134">(Aug 21 2024 at 15:25)</a>:</h4>
<p>so it seems weird</p>



<a name="464089310"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464089310" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464089310">(Aug 21 2024 at 15:26)</a>:</h4>
<p>OK, got it</p>



<a name="464138747"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464138747" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464138747">(Aug 21 2024 at 18:50)</a>:</h4>
<p><a href="/user_uploads/1549/fjMPcdjNRBA6kJb_qx49N5Ad/img-2044_owThMErC.mp4">img-2044_owThMErC.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/fjMPcdjNRBA6kJb_qx49N5Ad/img-2044_owThMErC.mp4" title="img-2044_owThMErC.mp4"><video preload="metadata" src="/user_uploads/1549/fjMPcdjNRBA6kJb_qx49N5Ad/img-2044_owThMErC.mp4"></video></a></div>



<a name="464138911"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464138911" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464138911">(Aug 21 2024 at 18:51)</a>:</h4>
<p><span class="user-mention" data-user-id="700180">@fall Rainy</span> I believe it's just a matter of choosing the right loss function and the right hyperparameters.</p>



<a name="464139218"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464139218" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464139218">(Aug 21 2024 at 18:53)</a>:</h4>
<p>If we add also the position of where the ray intersects the surface, I believe we will achieve a great accuracy.</p>



<a name="464145477"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464145477" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464145477">(Aug 21 2024 at 19:17)</a>:</h4>
<p>(The training set is 1 million)</p>



<a name="464297075"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297075" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297075">(Aug 22 2024 at 08:17)</a>:</h4>
<p>for all direction?</p>



<a name="464297092"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297092" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297092">(Aug 22 2024 at 08:17)</a>:</h4>
<p>yes</p>



<a name="464297140"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297140" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297140">(Aug 22 2024 at 08:18)</a>:</h4>
<p>That's amazing</p>



<a name="464297227"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297227" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297227">(Aug 22 2024 at 08:18)</a>:</h4>
<p>just hashnet/gridnet?</p>



<a name="464297253"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297253" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297253">(Aug 22 2024 at 08:18)</a>:</h4>
<p>yes</p>



<a name="464297347"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297347" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297347">(Aug 22 2024 at 08:19)</a>:</h4>
<p>Wow</p>



<a name="464297432"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297432" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297432">(Aug 22 2024 at 08:19)</a>:</h4>
<p>well it is not a surprise</p>



<a name="464297503"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297503" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297503">(Aug 22 2024 at 08:19)</a>:</h4>
<p>it was already done in the nbvh paper</p>



<a name="464297616"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297616" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297616">(Aug 22 2024 at 08:20)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464139218">said</a>:</p>
<blockquote>
<p>If we add also the position of where the ray intersects the surface, I believe we will achieve a great accuracy.</p>
</blockquote>
<p>I've created such a dataset before, but it didn't work well and I gave up on it</p>



<a name="464297767"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297767" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297767">(Aug 22 2024 at 08:20)</a>:</h4>
<p>on which network?</p>



<a name="464297838"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297838" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297838">(Aug 22 2024 at 08:20)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464297503">said</a>:</p>
<blockquote>
<p>it was already done in the nbvh paper</p>
</blockquote>
<p>But I don't think you're using the bvh?</p>



<a name="464297865"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297865" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297865">(Aug 22 2024 at 08:21)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464297767">said</a>:</p>
<blockquote>
<p>on which network?</p>
</blockquote>
<p>gridnet</p>



<a name="464297946"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464297946" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464297946">(Aug 22 2024 at 08:21)</a>:</h4>
<p>the bvh is useful only to decrease the number of points but the network is exactly hashnet + gridnet</p>



<a name="464298256"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298256" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298256">(Aug 22 2024 at 08:22)</a>:</h4>
<p>As I said, I use a different approach as a sampling approach (I parallelize the points)</p>



<a name="464298276"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298276" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298276">(Aug 22 2024 at 08:23)</a>:</h4>
<p>OK, got it. What did you do?</p>



<a name="464298358"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298358" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298358">(Aug 22 2024 at 08:23)</a>:</h4>
<p>I just extendend my previous network with rgb</p>



<a name="464298389"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298389" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298389">(Aug 22 2024 at 08:23)</a>:</h4>
<p>I take the first hit along the 200 points</p>



<a name="464298458"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298458" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298458">(Aug 22 2024 at 08:23)</a>:</h4>
<p>And I take the embedding of that voxel to show the rgb color</p>



<a name="464298538"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298538" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298538">(Aug 22 2024 at 08:24)</a>:</h4>
<p>wait a minute. you just pridict hit points?</p>



<a name="464298806"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464298806" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464298806">(Aug 22 2024 at 08:25)</a>:</h4>
<p>Well something similar, the network is able to predict itself the voxels hitted or not</p>



<a name="464299020"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464299020" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464299020">(Aug 22 2024 at 08:25)</a>:</h4>
<p>Because all the rays that miss the object will put 0 on all the voxels along their path</p>



<a name="464299461"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464299461" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464299461">(Aug 22 2024 at 08:27)</a>:</h4>
<p>Instead, if we are talking about a ray that is a hit, there must be at least one voxel along the path that it is a hit.</p>



<a name="464299517"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464299517" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464299517">(Aug 22 2024 at 08:27)</a>:</h4>
<p>How many parameters did you enter? Spherical or Cartesian coordinates?</p>



<a name="464299658"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464299658" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464299658">(Aug 22 2024 at 08:27)</a>:</h4>
<p>All the points along the path are in cartesian coordinates</p>



<a name="464299843"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464299843" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464299843">(Aug 22 2024 at 08:28)</a>:</h4>
<p>But they are scaled like they are in a sphere of radius 1.</p>



<a name="464299968"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464299968" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464299968">(Aug 22 2024 at 08:28)</a>:</h4>
<p>I need this to make hashnet work between range -1,1</p>



<a name="464300094"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464300094" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464300094">(Aug 22 2024 at 08:28)</a>:</h4>
<p>Do you want to see the code?</p>



<a name="464300122"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464300122" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464300122">(Aug 22 2024 at 08:28)</a>:</h4>
<p>yes</p>



<a name="464300193"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464300193" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464300193">(Aug 22 2024 at 08:29)</a>:</h4>
<p>Ok some minutes, I am going to upload it.</p>



<a name="464300222"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464300222" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464300222">(Aug 22 2024 at 08:29)</a>:</h4>
<p>I'm a little confused.</p>



<a name="464303211"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464303211" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464303211">(Aug 22 2024 at 08:40)</a>:</h4>
<p><a href="https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh">https://github.com/bralani/rt_volume/tree/neural_rendering/src/rt/nvbh</a><br>
The file nvbh_rgb.py</p>



<a name="464303813"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464303813" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464303813">(Aug 22 2024 at 08:42)</a>:</h4>
<p>OK, thx.</p>



<a name="464304259"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464304259" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464304259">(Aug 22 2024 at 08:44)</a>:</h4>
<p>I'll try it after I submit my final evaluation.</p>



<a name="464305283"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464305283" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464305283">(Aug 22 2024 at 08:48)</a>:</h4>
<p>As you can see, it understands the volume by itself</p>
<p>epoch 1<br>
<a href="/user_uploads/1549/lUfFum9c4Kc8e6EPDpE6q2AW/image.png">image.png</a><br>
<a href="/user_uploads/1549/sIdgV7CMCFYgXavsY1w0XRkR/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/lUfFum9c4Kc8e6EPDpE6q2AW/image.png" title="image.png"><img data-original-dimensions="478x359" src="/user_uploads/thumbnail/1549/lUfFum9c4Kc8e6EPDpE6q2AW/image.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/sIdgV7CMCFYgXavsY1w0XRkR/image.png" title="image.png"><img data-original-dimensions="462x281" src="/user_uploads/thumbnail/1549/sIdgV7CMCFYgXavsY1w0XRkR/image.png/840x560.webp"></a></div><p>epoch 5<br>
<a href="/user_uploads/1549/vdJWzlRdcttmOPzuwvU0h2bk/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/vdJWzlRdcttmOPzuwvU0h2bk/image.png" title="image.png"><img data-original-dimensions="484x364" src="/user_uploads/thumbnail/1549/vdJWzlRdcttmOPzuwvU0h2bk/image.png/840x560.webp"></a></div>



<a name="464306431"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464306431" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464306431">(Aug 22 2024 at 08:53)</a>:</h4>
<p>There are still a lot of improvements to do, first I do not encode the direction of the ray</p>



<a name="464306878"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464306878" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464306878">(Aug 22 2024 at 08:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464306431">said</a>:</p>
<blockquote>
<p>There are still a lot of improvements to do, first I do not encode the direction of the ray</p>
</blockquote>
<p>I'm getting more and more confused, wait until I read your code</p>



<a name="464307047"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464307047" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464307047">(Aug 22 2024 at 08:56)</a>:</h4>
<p>haha ok</p>



<a name="464307624"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464307624" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464307624">(Aug 22 2024 at 08:57)</a>:</h4>
<p>If you want to get more message, like distance, you can find it here:</p>
<div class="codehilite" data-code-language="C++"><pre><span></span><code><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">rt_shootray</span><span class="p">(</span><span class="o">&amp;</span><span class="n">a</span><span class="p">);</span>
<span class="o">*</span><span class="n">dist</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">a_dist</span><span class="p">;</span>
<span class="o">*</span><span class="n">hit_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">a_user</span><span class="p">;</span>
</code></pre></div>



<a name="464639760"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464639760" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464639760">(Aug 23 2024 at 12:31)</a>:</h4>
<p><a href="/user_uploads/1549/ywnqkJGnrJ6INaXjK6ECOY5N/IMG_2047.mp4">IMG_2047.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/ywnqkJGnrJ6INaXjK6ECOY5N/IMG_2047.mp4" title="IMG_2047.mp4"><video preload="metadata" src="/user_uploads/1549/ywnqkJGnrJ6INaXjK6ECOY5N/IMG_2047.mp4"></video></a></div>



<a name="464640064"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464640064" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464640064">(Aug 23 2024 at 12:33)</a>:</h4>
<p><span class="user-mention" data-user-id="700180">@fall Rainy</span> it’s better with the intersection point</p>



<a name="464640239"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464640239" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464640239">(Aug 23 2024 at 12:34)</a>:</h4>
<p>This is trained with 10 millions rays but only in 5 epochs</p>



<a name="464640328"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464640328" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464640328">(Aug 23 2024 at 12:34)</a>:</h4>
<p>It can be even better</p>



<a name="464640766"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464640766" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464640766">(Aug 23 2024 at 12:36)</a>:</h4>
<p>I train in parallel the shape of the object and also the rgb. Probably it is better to separate the two networks because the second one (rgb) depends on the first (shape-&gt; hit/miss)</p>



<a name="464641030"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464641030" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464641030">(Aug 23 2024 at 12:37)</a>:</h4>
<p>(Don’t see the fact that the object stretches when I rotate, it’s a bug of the camera…)</p>



<a name="464641265"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464641265" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464641265">(Aug 23 2024 at 12:39)</a>:</h4>
<p>If you see below the cube there is an error of the color, probably there aren’t any rays in the training set that go below the cube <span aria-label="joy" class="emoji emoji-1f602" role="img" title="joy">:joy:</span></p>



<a name="464754747"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464754747" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464754747">(Aug 23 2024 at 22:19)</a>:</h4>
<p><a href="/user_uploads/1549/w21TCzW-NH2XrEQLh5FK1UYr/img-2048_FQBUrdcC-2.mp4">img-2048_FQBUrdcC 2.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/w21TCzW-NH2XrEQLh5FK1UYr/img-2048_FQBUrdcC-2.mp4" title="img-2048_FQBUrdcC 2.mp4"><video preload="metadata" src="/user_uploads/1549/w21TCzW-NH2XrEQLh5FK1UYr/img-2048_FQBUrdcC-2.mp4"></video></a></div>



<a name="464754891"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464754891" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464754891">(Aug 23 2024 at 22:20)</a>:</h4>
<p>I have added also the direction of the ray and as you can see it is essential in the prediction of the color because the same intersection point can have a different color if the direction is different (see how the light on the surface change).</p>



<a name="464754941"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464754941" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464754941">(Aug 23 2024 at 22:21)</a>:</h4>
<p>Again, don’t see the fact that the shape stretches.</p>



<a name="464960871"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464960871" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464960871">(Aug 25 2024 at 08:06)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> I just read your code. Any example for your dataset?</p>



<a name="464960933"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464960933" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464960933">(Aug 25 2024 at 08:06)</a>:</h4>
<p>Wait a moment</p>



<a name="464961256"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464961256" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464961256">(Aug 25 2024 at 08:08)</a>:</h4>
<p>(deleted)</p>



<a name="464961357"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464961357" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464961357">(Aug 25 2024 at 08:08)</a>:</h4>
<p><a href="https://drive.google.com/file/d/1G-HR5PSxtaXoZCaQYEKGXHrx1sTcfSwh/view?usp=drive_link">https://drive.google.com/file/d/1G-HR5PSxtaXoZCaQYEKGXHrx1sTcfSwh/view?usp=drive_link</a></p>



<a name="464961405"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464961405" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464961405">(Aug 25 2024 at 08:08)</a>:</h4>
<p>I don't have access to this link.</p>



<a name="464961502"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464961502" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464961502">(Aug 25 2024 at 08:09)</a>:</h4>
<p>Just sent an access request</p>



<a name="464961525"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464961525" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464961525">(Aug 25 2024 at 08:09)</a>:</h4>
<p>I have accepted</p>



<a name="464961807"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464961807" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464961807">(Aug 25 2024 at 08:10)</a>:</h4>
<p>OK thx</p>



<a name="464962131"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464962131" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464962131">(Aug 25 2024 at 08:11)</a>:</h4>
<p>The code you read is not updated. In that code I did not managed with the intersection point.</p>



<a name="464962323"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464962323" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464962323">(Aug 25 2024 at 08:14)</a>:</h4>
<p>Can you update it now?</p>



<a name="464962396"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464962396" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464962396">(Aug 25 2024 at 08:14)</a>:</h4>
<p>But in the dataset there are (for each example i.e each row):</p>
<ul>
<li>2 values for intersection 1 (spherical coord)</li>
<li>2 values for intersection 2 (spherical coord)</li>
<li>1 value for label (hit/miss 1 or 0)</li>
<li>3 values for rgb</li>
<li>1 value for the intersection point: it is the distance from intersection1 to intersection2 (scaled to 0-1) -&gt; if it is 1 it means that the intersection is exactly on intersection2</li>
</ul>



<a name="464962408"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464962408" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464962408">(Aug 25 2024 at 08:14)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/464962323">ha scritto</a>:</p>
<blockquote>
<p>Can you update it now?</p>
</blockquote>
<p>Yes just some minutes</p>



<a name="464963734"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464963734" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464963734">(Aug 25 2024 at 08:22)</a>:</h4>
<p>Done</p>



<a name="464964071"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464964071" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464964071">(Aug 25 2024 at 08:24)</a>:</h4>
<p>Got it, Thx</p>



<a name="464975699"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464975699" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464975699">(Aug 25 2024 at 09:58)</a>:</h4>
<p>What do these two spherical coordinates represent?</p>



<a name="464975720"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464975720" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464975720">(Aug 25 2024 at 09:58)</a>:</h4>
<p>the first and second intersection on the bounding sphere</p>



<a name="464977644"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464977644" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464977644">(Aug 25 2024 at 10:05)</a>:</h4>
<p>It looks like you've trained two networks, one for determining if it's a hit or not, and the other for predicting rgb values</p>



<a name="464977756"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464977756" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464977756">(Aug 25 2024 at 10:05)</a>:</h4>
<p>yes</p>



<a name="464981896"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464981896" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464981896">(Aug 25 2024 at 10:15)</a>:</h4>
<p>I see how you're controlling the direction, the two intersections actually determine the direction of light</p>



<a name="464985473"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464985473" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464985473">(Aug 25 2024 at 10:24)</a>:</h4>
<p>yes but it is controlled also by the order of the points sampled close to the hit surface</p>



<a name="464985645"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464985645" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464985645">(Aug 25 2024 at 10:25)</a>:</h4>
<p>which they are sampled thanks to the two intersections as you said</p>



<a name="464991416"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464991416" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464991416">(Aug 25 2024 at 10:54)</a>:</h4>
<p>How do you get this loss function:</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">output_label</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">all_outputs</span><span class="p">):</span>

    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="c1"># Applichiamo la soglia morbida</span>
    <span class="n">indices_first</span> <span class="o">=</span> <span class="n">find_index_with_exponential_decay</span><span class="p">(</span><span class="n">all_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_points</span><span class="p">)))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_points</span><span class="p">))</span>

    <span class="c1"># L1 Loss tra gli indici soft e dist</span>
    <span class="n">loss1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()(</span><span class="n">indices_first</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">dist</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
    <span class="n">loss0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()(</span><span class="n">output_label</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss0</span> <span class="o">+</span> <span class="n">loss1</span>
</code></pre></div>



<a name="464991923"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464991923" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464991923">(Aug 25 2024 at 10:57)</a>:</h4>
<p>loss0 is simply the loss for hit/miss</p>



<a name="464992069"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464992069" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464992069">(Aug 25 2024 at 10:57)</a>:</h4>
<p>loss1 instead is the loss for the intersection point on the surface</p>



<a name="464992484"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464992484" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464992484">(Aug 25 2024 at 11:00)</a>:</h4>
<p>These are the steps:<br>
1) I sample n_points on the segment between intersection1 and intersection2<br>
2) I calculate the probability of hit for each point<br>
3) I need to get the first hit point on these n_points but I need to get it in a differentiable way to calculate the loss function, so the function find_index_with_exponential_decay cover this issue</p>



<a name="464992519"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/464992519" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#464992519">(Aug 25 2024 at 11:00)</a>:</h4>
<p>4) Thanks to the hit point prediction I can calculate the distance to the true hit point.</p>



<a name="465015470"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465015470" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465015470">(Aug 25 2024 at 13:57)</a>:</h4>
<p>I organized your code, after all, it's not good to put all the code in one file:<a href="https://github.com/Rainy-fall-end/neural_rendering">neural_rendering</a></p>



<a name="465019406"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465019406" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465019406">(Aug 25 2024 at 14:36)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465015470">ha scritto</a>:</p>
<blockquote>
<p>I organized your code, after all, it's not good to put all the code in one file:<a href="https://github.com/Rainy-fall-end/neural_rendering">neural_rendering</a></p>
</blockquote>
<p>This morning I did another improvement: I have merged the two networks into one (now it is faster to train) and I have added the true normalized direction as input of the MLP neural network: training with the full dataset there is an average error of 6 for each RGB channel.</p>



<a name="465019685"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465019685" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465019685">(Aug 25 2024 at 14:37)</a>:</h4>
<p>We are very close <span aria-label="mechanical arm" class="emoji emoji-1f9be" role="img" title="mechanical arm">:mechanical_arm:</span></p>



<a name="465021106"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465021106" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465021106">(Aug 25 2024 at 14:48)</a>:</h4>
<p><a href="/user_uploads/1549/blbX-dx0frLdZuwdQKXwAaoz/video-2024-08-25-16-46-36_R9pM18PD.mp4">video-2024-08-25-16-46-36_R9pM18PD.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/blbX-dx0frLdZuwdQKXwAaoz/video-2024-08-25-16-46-36_R9pM18PD.mp4" title="video-2024-08-25-16-46-36_R9pM18PD.mp4"><video preload="metadata" src="/user_uploads/1549/blbX-dx0frLdZuwdQKXwAaoz/video-2024-08-25-16-46-36_R9pM18PD.mp4"></video></a></div>



<a name="465101449"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465101449" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465101449">(Aug 26 2024 at 07:19)</a>:</h4>
<p><a href="/user_uploads/1549/4a4hD3-xavXUvjFmxLfGAP_y/true.png">true.png</a><br>
<a href="/user_uploads/1549/wMU3LRH-sO39Eodo02L2xYdC/pred.png">pred.png</a><br>
<span class="user-mention" data-user-id="700180">@fall Rainy</span> this is the current difference if you train the NN (the prediction is computed directly in python)</p>
<div class="message_inline_image"><a href="/user_uploads/1549/4a4hD3-xavXUvjFmxLfGAP_y/true.png" title="true.png"><img data-original-dimensions="256x256" src="/user_uploads/thumbnail/1549/4a4hD3-xavXUvjFmxLfGAP_y/true.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/wMU3LRH-sO39Eodo02L2xYdC/pred.png" title="pred.png"><img data-original-dimensions="256x256" src="/user_uploads/thumbnail/1549/wMU3LRH-sO39Eodo02L2xYdC/pred.png/840x560.webp"></a></div>



<a name="465102116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465102116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465102116">(Aug 26 2024 at 07:23)</a>:</h4>
<p>It seems the prediction is brighter for some reason</p>



<a name="465102297"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465102297" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465102297">(Aug 26 2024 at 07:24)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Are there any post production processes in brlcad before saving the render?</p>



<a name="465103052"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465103052" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465103052">(Aug 26 2024 at 07:27)</a>:</h4>
<p>Because I cannot explain why the light is brighter <span aria-label="distrust" class="emoji emoji-1f928" role="img" title="distrust">:distrust:</span></p>



<a name="465104572"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465104572" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465104572">(Aug 26 2024 at 07:33)</a>:</h4>
<p>(the prediction seems more realistic than the true one <span aria-label="joy" class="emoji emoji-1f602" role="img" title="joy">:joy:</span> )</p>



<a name="465105435"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465105435" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465105435">(Aug 26 2024 at 07:37)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465101449">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/4a4hD3-xavXUvjFmxLfGAP_y/true.png">true.png</a><br>
<a href="/user_uploads/1549/wMU3LRH-sO39Eodo02L2xYdC/pred.png">pred.png</a><br>
<span class="user-mention silent" data-user-id="700180">fall Rainy</span> this is the current difference if you train the NN (the prediction is computed directly in python)</p>
</blockquote>
<p>This is my results(rendered by brl-cad)<br>
<a href="/user_uploads/1549/RR8YBrGtSGQFIGV9QnHqfp-8/1fba315da2f2ce6c381664d32c767a8.png">1fba315da2f2ce6c381664d32c767a8.png</a><br>
I think it may be that the rendering parameters are different</p>
<div class="message_inline_image"><a href="/user_uploads/1549/RR8YBrGtSGQFIGV9QnHqfp-8/1fba315da2f2ce6c381664d32c767a8.png" title="1fba315da2f2ce6c381664d32c767a8.png"><img data-original-dimensions="753x768" src="/user_uploads/thumbnail/1549/RR8YBrGtSGQFIGV9QnHqfp-8/1fba315da2f2ce6c381664d32c767a8.png/840x560.webp"></a></div>



<a name="465106297"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465106297" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465106297">(Aug 26 2024 at 07:41)</a>:</h4>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465105435">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465101449">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/4a4hD3-xavXUvjFmxLfGAP_y/true.png">true.png</a><br>
<a href="/user_uploads/1549/wMU3LRH-sO39Eodo02L2xYdC/pred.png">pred.png</a><br>
<span class="user-mention silent" data-user-id="700180">fall Rainy</span> this is the current difference if you train the NN (the prediction is computed directly in python)</p>
</blockquote>
<p>This is my results(rendered by brl-cad)<br>
<a href="/user_uploads/1549/RR8YBrGtSGQFIGV9QnHqfp-8/1fba315da2f2ce6c381664d32c767a8.png">1fba315da2f2ce6c381664d32c767a8.png</a><br>
I think it may be that the rendering parameters are different</p>
</blockquote>
<p>Is this the prediction?</p>



<a name="465107221"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465107221" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465107221">(Aug 26 2024 at 07:45)</a>:</h4>
<p>No, the true result</p>



<a name="465107874"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465107874" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465107874">(Aug 26 2024 at 07:49)</a>:</h4>
<p>Have you tried training the NN?</p>



<a name="465108026"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465108026" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465108026">(Aug 26 2024 at 07:49)</a>:</h4>
<p>Yes, I got the same result with you</p>



<a name="465108281"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465108281" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465108281">(Aug 26 2024 at 07:50)</a>:</h4>
<p>I'm trying to add some of my previous improvements on hashencoder to your network.</p>



<a name="465108503"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465108503" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465108503">(Aug 26 2024 at 07:51)</a>:</h4>
<p>Ok you are more expert in rgb than me, I will wait for you</p>



<a name="465109265"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465109265" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465109265">(Aug 26 2024 at 07:54)</a>:</h4>
<p>The L1 Loss says that there is an average error of 6 along each RGB channel. But I think that this value is not uniform for each pixel, because if you see on the shadows it is nearly perfect. So I believe that this error is an average between the bright areas (more than 6) and shadows one (almost perfect).</p>



<a name="465109572"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465109572" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465109572">(Aug 26 2024 at 07:56)</a>:</h4>
<p>Yes, it is easier to train the shadow parts</p>



<a name="465109996"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465109996" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465109996">(Aug 26 2024 at 07:59)</a>:</h4>
<p>true</p>



<a name="465154678"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465154678" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465154678">(Aug 26 2024 at 11:33)</a>:</h4>
<p>I also merge the two networks into one:<a href="https://github.com/Rainy-fall-end/neural_rendering/tree/merge_network">https://github.com/Rainy-fall-end/neural_rendering/tree/merge_network</a></p>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465019406">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="700180">fall Rainy</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465015470">ha scritto</a>:</p>
<blockquote>
<p>I organized your code, after all, it's not good to put all the code in one file:<a href="https://github.com/Rainy-fall-end/neural_rendering">neural_rendering</a></p>
</blockquote>
<p>This morning I did another improvement: I have merged the two networks into one (now it is faster to train) and I have added the true normalized direction as input of the MLP neural network: training with the full dataset there is an average error of 6 for each RGB channel.</p>
</blockquote>



<a name="465154949"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465154949" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465154949">(Aug 26 2024 at 11:34)</a>:</h4>
<p>Good</p>



<a name="465155416"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465155416" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465155416">(Aug 26 2024 at 11:35)</a>:</h4>
<p>I have noticed also that the distance loss(loss1) is essential to predict the rgb color</p>



<a name="465155808"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465155808" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465155808">(Aug 26 2024 at 11:36)</a>:</h4>
<p>Maybe the error on the color is due to the small error on the loss1?</p>



<a name="465155874"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465155874" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465155874">(Aug 26 2024 at 11:36)</a>:</h4>
<p>I don’t think so</p>



<a name="465159805"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465159805" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465159805">(Aug 26 2024 at 11:51)</a>:</h4>
<p>I think some weight could be added in front of the loss?</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="k">def</span> <span class="nf">loss_fn3</span><span class="p">(</span><span class="n">output_label</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">output_dists</span><span class="p">,</span><span class="n">dists</span><span class="p">,</span><span class="n">output_rgb</span><span class="p">,</span><span class="n">rgb</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="c1"># Applichiamo la soglia morbida</span>
    <span class="n">indices_first</span> <span class="o">=</span> <span class="n">find_index_with_exponential_decay</span><span class="p">(</span><span class="n">output_dists</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_points</span><span class="p">)))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_points</span><span class="p">))</span>

    <span class="c1"># L1 Loss tra gli indici soft e dist</span>
    <span class="n">loss0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()(</span><span class="n">output_label</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()(</span><span class="n">indices_first</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">dists</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
    <span class="n">loss2</span> <span class="o">=</span> <span class="n">loss_fn2</span><span class="p">(</span><span class="n">output_rgb</span><span class="p">,</span><span class="n">rgb</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">loss0</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">loss1</span> <span class="o">+</span> <span class="mf">0.6</span><span class="o">*</span><span class="n">loss2</span>
</code></pre></div>



<a name="465159982"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465159982" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465159982">(Aug 26 2024 at 11:52)</a>:</h4>
<p>Well I don't think it will change the convergence because the encoders of loss2 and the others two losses are separate</p>



<a name="465160131"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465160131" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465160131">(Aug 26 2024 at 11:53)</a>:</h4>
<p>In other words, the gradients of rgb is separate from the the others two losses</p>



<a name="465160184"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465160184" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465160184">(Aug 26 2024 at 11:53)</a>:</h4>
<p>I believe there is still something missing</p>



<a name="465160383"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465160383" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465160383">(Aug 26 2024 at 11:54)</a>:</h4>
<p>Maybe we need to make more complex the encoder of rgb</p>



<a name="465162441"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465162441" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465162441">(Aug 26 2024 at 12:06)</a>:</h4>
<p><span class="user-mention" data-user-id="700180">@fall Rainy</span> If you see my last commit of yesterday I have changed the input of the rgb encoder. There is no need to give in input 5 points but 1 it's ok if we add directly the direction of the ray.</p>



<a name="465163027"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465163027" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465163027">(Aug 26 2024 at 12:09)</a>:</h4>
<p><a href="https://github.com/bralani/rt_volume/blob/neural_rendering/src/rt/nvbh/nvbh_rgb.py">https://github.com/bralani/rt_volume/blob/neural_rendering/src/rt/nvbh/nvbh_rgb.py</a></p>



<a name="465178824"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465178824" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465178824">(Aug 26 2024 at 12:57)</a>:</h4>
<p><a href="/user_uploads/1549/CrxNFV7UNasizzVVVjP7u2eL/pred2.png">pred2.png</a><br>
<span class="user-mention" data-user-id="700180">@fall Rainy</span> the problem was the training set</p>
<div class="message_inline_image"><a href="/user_uploads/1549/CrxNFV7UNasizzVVVjP7u2eL/pred2.png" title="pred2.png"><img data-original-dimensions="1920x969" src="/user_uploads/thumbnail/1549/CrxNFV7UNasizzVVVjP7u2eL/pred2.png/840x560.webp"></a></div>



<a name="465179022"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465179022" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465179022">(Aug 26 2024 at 12:57)</a>:</h4>
<p>The sampling was not uniform along each direction</p>



<a name="465179162"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465179162" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465179162">(Aug 26 2024 at 12:57)</a>:</h4>
<p><a href="https://drive.google.com/file/d/1yiyRmts0hboItRuw9VnC1OP1lriIxIOh/view?usp=drive_link">https://drive.google.com/file/d/1yiyRmts0hboItRuw9VnC1OP1lriIxIOh/view?usp=drive_link</a><br>
Try with this training set</p>



<a name="465181362"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465181362" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465181362">(Aug 26 2024 at 13:06)</a>:</h4>
<p><span aria-label="partying face" class="emoji emoji-1f973" role="img" title="partying face">:partying_face:</span></p>



<a name="465183669"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465183669" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465183669">(Aug 26 2024 at 13:16)</a>:</h4>
<p>Amazing, got it</p>



<a name="465186342"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465186342" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465186342">(Aug 26 2024 at 13:29)</a>:</h4>
<p>Now it's all about finding the right combination with quality and inference time/memory. I will focus on the first encoder</p>



<a name="465186411"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465186411" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465186411">(Aug 26 2024 at 13:29)</a>:</h4>
<p>So you can focus on the rgb encoder</p>



<a name="465209008"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465209008" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465209008">(Aug 26 2024 at 14:53)</a>:</h4>
<p>I think moss is a bit too simple to do training, may be we should test some of the more complex models</p>



<a name="465211168"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465211168" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465211168">(Aug 26 2024 at 15:00)</a>:</h4>
<p>Sure, this is the uniform sampling I did:</p>
<div class="codehilite" data-code-language="C++"><pre><span></span><code><span class="c1">// Funzione per calcolare i parametri azimuth ed elevation</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">uniform_sphere_sampling</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">angles</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">phi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mf">1.0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">5.0</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">2.0</span><span class="p">;</span><span class="w">  </span><span class="c1">// Costante aurea</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// Calcolo dell'angolo di elevazione (phi)</span>
<span class="w">        </span><span class="kt">double</span><span class="w"> </span><span class="n">elevation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">acos</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// Calcolo dell'angolo di azimut (theta)</span>
<span class="w">        </span><span class="kt">double</span><span class="w"> </span><span class="n">azimuth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">fmod</span><span class="p">(</span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">M_PI</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">phi</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">M_PI</span><span class="p">);</span>

<span class="w">                </span><span class="c1">// Convert the azimuth to degrees</span>
<span class="w">                </span><span class="n">azimuth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">azimuth</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">180</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">M_PI</span><span class="p">;</span>
<span class="w">                </span><span class="c1">// Convert the elevation to degrees</span>
<span class="w">                </span><span class="n">elevation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">elevation</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">180</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">M_PI</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// Aggiunge la coppia (azimuth, elevation) alla lista</span>
<span class="w">        </span><span class="n">angles</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="n">azimuth</span><span class="p">,</span><span class="w"> </span><span class="n">elevation</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">angles</span><span class="p">;</span>
<span class="p">}</span>


<span class="kt">void</span><span class="w"> </span><span class="n">generate_renders_test_set</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">num_renders</span><span class="p">)</span>
<span class="p">{</span>

<span class="w">    </span><span class="c1">// make a file to write the test set</span>
<span class="w">    </span><span class="kt">FILE</span><span class="o">*</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fopen</span><span class="p">(</span><span class="s">"./test_neural2.txt"</span><span class="p">,</span><span class="w"> </span><span class="s">"w"</span><span class="p">);</span>
<span class="w">    </span><span class="n">fclose</span><span class="p">(</span><span class="n">file</span><span class="p">);</span>


<span class="w">    </span><span class="c1">// test set</span>
<span class="w">    </span><span class="n">set_generate_test_set</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="n">set_type</span><span class="p">(</span><span class="n">render_type</span><span class="o">::</span><span class="n">neural</span><span class="p">);</span>

<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">para</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">uniform_sphere_sampling</span><span class="p">(</span><span class="n">num_renders</span><span class="p">);</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_renders</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">"Rendering %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">);</span>

<span class="w">        </span><span class="n">do_ae</span><span class="p">(</span><span class="n">para</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">first</span><span class="p">,</span><span class="w"> </span><span class="n">para</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">second</span><span class="p">);</span>

<span class="w">        </span><span class="c1">//outputfile = (char*)"./output.png";</span>
<span class="w">        </span><span class="n">rt_neu</span><span class="o">::</span><span class="n">render</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">set_generate_test_set</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>



<a name="465211331"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465211331" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465211331">(Aug 26 2024 at 15:00)</a>:</h4>
<p>If you want to generate the training set</p>



<a name="465227073"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227073" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227073">(Aug 26 2024 at 16:13)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465102297">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> Are there any post production processes in brlcad before saving the render?</p>
</blockquote>
<p>There are not any happening on an image / frame basis, no.  Your ambient level appears to approximately match.  What's not matching is the intensity from the sole light source itself, like it's being applied with a different scaling factor.</p>



<a name="465227255"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227255" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227255">(Aug 26 2024 at 16:14)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465227073">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465102297">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> Are there any post production processes in brlcad before saving the render?</p>
</blockquote>
<p>There are not any happening on an image / frame basis, no.  Your ambient level appears to approximately match.  What's not matching is the intensity from the sole light source itself, like it's being applied with a different scaling factor.</p>
</blockquote>
<p>Yep we have solved it. The error was on the training set due to the lack of samples for each direction :)</p>



<a name="465227332"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227332" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227332">(Aug 26 2024 at 16:14)</a>:</h4>
<p>I caught up and saw that :)</p>



<a name="465227387"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227387" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227387">(Aug 26 2024 at 16:15)</a>:</h4>
<p>Now it is almost perfect</p>



<a name="465227467"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227467" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227467">(Aug 26 2024 at 16:15)</a>:</h4>
<p>What happens with the 'havoc' object in 'havoc.g' sample?</p>



<a name="465227555"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227555" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227555">(Aug 26 2024 at 16:16)</a>:</h4>
<p>wildly different model</p>



<a name="465227564"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227564" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227564">(Aug 26 2024 at 16:16)</a>:</h4>
<p>Is this more complex?</p>



<a name="465227902"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465227902" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465227902">(Aug 26 2024 at 16:18)</a>:</h4>
<p>I will generate the training set later :)</p>



<a name="465229470"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465229470" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465229470">(Aug 26 2024 at 16:26)</a>:</h4>
<p>It's much more complex, by about 3 orders of magnitude compared with moss.</p>



<a name="465229544"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465229544" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465229544">(Aug 26 2024 at 16:27)</a>:</h4>
<p>Still considered a small model, but it has hard features that will be interesting to observe</p>



<a name="465242088"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465242088" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465242088">(Aug 26 2024 at 17:33)</a>:</h4>
<p><a href="/user_uploads/1549/y8AGB9yxvXaFhvCd7zhg8W-Y/pygame-window-2024-08-26-19-15-10.mp4">pygame-window-2024-08-26-19-15-10.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/y8AGB9yxvXaFhvCd7zhg8W-Y/pygame-window-2024-08-26-19-15-10.mp4" title="pygame-window-2024-08-26-19-15-10.mp4"><video preload="metadata" src="/user_uploads/1549/y8AGB9yxvXaFhvCd7zhg8W-Y/pygame-window-2024-08-26-19-15-10.mp4"></video></a></div>



<a name="465242285"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465242285" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465242285">(Aug 26 2024 at 17:34)</a>:</h4>
<p>It's strange why there are those noisy dots below the helicopter.</p>



<a name="465242629"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465242629" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465242629">(Aug 26 2024 at 17:36)</a>:</h4>
<p>Maybe the training set is small (it contains only 100 frames in 256x256 for a total of 5/6 millions)</p>



<a name="465421566"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465421566" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465421566">(Aug 27 2024 at 11:49)</a>:</h4>
<p>During the sampling part (renderings) I have these warnings (and others similar):</p>
<p>Root solver reported 3 intersections != {0, 2, 4} on s.nos5a.i<br>
        shooting point (units mm):  (16599.899526, 396.927869, 1211.109774)<br>
        shooting direction:         (-0.947094, -0.274243, -0.166745)<br>
        377.103 366.627 86.6928</p>
<p>OVERLAP1: /havoc_front/cannopy/cannopy_wipers/2_wiper/2_wipe1_rubber/2_r.wipe1<br>
OVERLAP2: /havoc_front/cannopy/cannopy_glass/r.glass1<br>
OVERLAPa: dist=(1.91371, 3.2123) isol=2_s.wipe2 osol=2_s.wipe2<br>
OVERLAPb: depth 1.29859mm at (15095.9, -244.662, 1677.06) x105 y148 lvl0</p>



<a name="465421636"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465421636" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465421636">(Aug 27 2024 at 11:50)</a>:</h4>
<p>Could it be for this reason that the model isn't able to predict well?</p>



<a name="465476518"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465476518" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465476518">(Aug 27 2024 at 14:57)</a>:</h4>
<p>Does a_dist contain always the first intersection even if there are more than 1 intersections of the ray on the surface?</p>
<div class="codehilite"><pre><span></span><code>VJOIN1(hit_point, ap-&gt;a_ray.r_pt, ap-&gt;a_dist, ap-&gt;a_ray.r_dir);
</code></pre></div>
<p><span class="user-mention" data-user-id="102902">@Sean</span></p>



<a name="465483576"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465483576" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465483576">(Aug 27 2024 at 15:27)</a>:</h4>
<p>This is the shape training only with the loss of hit/miss:<br>
<a href="/user_uploads/1549/wYUe8BNzgPkTE7VZyJu3x3VP/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/wYUe8BNzgPkTE7VZyJu3x3VP/image.png" title="image.png"><img data-original-dimensions="361x377" src="/user_uploads/thumbnail/1549/wYUe8BNzgPkTE7VZyJu3x3VP/image.png/840x560.webp"></a></div><p>And this is the shape training also with the loss of the distance:<br>
<a href="/user_uploads/1549/FxZLrxDcZwUIc0UVNWp8mnwr/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/FxZLrxDcZwUIc0UVNWp8mnwr/image.png" title="image.png"><img data-original-dimensions="400x389" src="/user_uploads/thumbnail/1549/FxZLrxDcZwUIc0UVNWp8mnwr/image.png/840x560.webp"></a></div><p>So the problem must be with the distance... I think that during the sampling part (in brl-cad), if there are more than 1 intersections, a_dist contains the wrong distance and I need only and always the first intersection. Could it be possible?</p>



<a name="465576331"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576331" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576331">(Aug 27 2024 at 21:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465476518">said</a>:</p>
<blockquote>
<p>Does a_dist contain always the first intersection even if there are more than 1 intersections of the ray on the surface?</p>
<div class="codehilite"><pre><span></span><code>VJOIN1(hit_point, ap-&gt;a_ray.r_pt, ap-&gt;a_dist, ap-&gt;a_ray.r_dir);
</code></pre></div>
<p><span class="user-mention silent" data-user-id="102902">Sean</span></p>
</blockquote>
<p>No, a_dist isn't even set by librt -- that's an application-specific field so apps (e.g., rt) get to use it however they want.  So code you're using/calling has set or used a_dist and that's what you'll have to refer to in order to determine what is there.</p>



<a name="465576493"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576493" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576493">(Aug 27 2024 at 21:57)</a>:</h4>
<p>That shape training doesn't look right -- that looks like just the nose geometry.  I mean it's great that it's recognizable, but missing a lot.  Did you use the 'havoc' object?</p>



<a name="465576610"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576610" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576610">(Aug 27 2024 at 21:58)</a>:</h4>
<p>Ah, and I see from your output reporting that you're using "havoc_front" .. you want "havoc" instead.</p>



<a name="465576617"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576617" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576617">(Aug 27 2024 at 21:58)</a>:</h4>
<p>No i</p>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465576493">said</a>:</p>
<blockquote>
<p>That shape training doesn't look right -- that looks like just the nose geometry.  I mean it's great that it's recognizable, but missing a lot.  Did you use the 'havoc' object?</p>
</blockquote>
<p>No I used only the havoc_front</p>



<a name="465576641"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576641" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576641">(Aug 27 2024 at 21:58)</a>:</h4>
<p>Ah ok I will train with havoc</p>



<a name="465576729"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576729" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576729">(Aug 27 2024 at 21:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465421636">said</a>:</p>
<blockquote>
<p>Could it be for this reason that the model isn't able to predict well?</p>
</blockquote>
<p>No, those warnings are innocuous.  They are known issues with the model that just affect a few pixels and do not affect the hit distance values or silhouetting at all.</p>



<a name="465576838"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576838" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576838">(Aug 27 2024 at 22:00)</a>:</h4>
<p>It’s strange</p>



<a name="465576927"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465576927" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465576927">(Aug 27 2024 at 22:00)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465576641">said</a>:</p>
<blockquote>
<p>Ah ok I will train with havoc</p>
</blockquote>
<p>Yeah, I think it'll be more interesting to use the whole vehicle, especially the long rotors and complexity in certain parts.</p>



<a name="465577233"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465577233" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465577233">(Aug 27 2024 at 22:03)</a>:</h4>
<p>Rotors are long and thin, which should approach a worst case for sampling.</p>



<a name="465577822"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465577822" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465577822">(Aug 27 2024 at 22:08)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465576838">said</a>:</p>
<blockquote>
<p>It’s strange</p>
</blockquote>
<p>One is the root solver saying it got 3 hits, which can happen on a couple primitives when rays just graze a surface.  We make it print to eventually see if we can special-case the condition but it doesn't affect ray tracing.</p>
<p>The other is a report of a geometry overlap which is a modeling error, which also doesn't affect the hit results you're using.</p>



<a name="465578112"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465578112" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465578112">(Aug 27 2024 at 22:11)</a>:</h4>
<p>I will see whether there are the same errors on the full havoc model</p>



<a name="465578191"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465578191" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465578191">(Aug 27 2024 at 22:11)</a>:</h4>
<p>We are certain that the hit informations are right due to the first image here</p>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/465483576">said</a>:</p>
<blockquote>
<p>This is the shape training only with the loss of hit/miss:<br>
<a href="/user_uploads/1549/wYUe8BNzgPkTE7VZyJu3x3VP/image.png">image.png</a></p>
<p>And this is the shape training also with the loss of the distance:<br>
<a href="/user_uploads/1549/FxZLrxDcZwUIc0UVNWp8mnwr/image.png">image.png</a></p>
<p>So the problem must be with the distance... I think that during the sampling part (in brl-cad), if there are more than 1 intersections, a_dist contains the wrong distance and I need only and always the first intersection. Could it be possible?</p>
</blockquote>



<a name="465578372"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465578372" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465578372">(Aug 27 2024 at 22:12)</a>:</h4>
<p>It shouldn’t be too difficult to understand the distance in those areas below the helicopter. I have seen the true model and it is pretty smooth</p>



<a name="465707402"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465707402" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465707402">(Aug 28 2024 at 09:32)</a>:</h4>
<p><a href="/user_uploads/1549/q-WQOLDpeKSudKpz42T3dyo3/pygame-window-2024-08-28-11-30-51.mp4">pygame-window-2024-08-28-11-30-51.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/q-WQOLDpeKSudKpz42T3dyo3/pygame-window-2024-08-28-11-30-51.mp4" title="pygame-window-2024-08-28-11-30-51.mp4"><video preload="metadata" src="/user_uploads/1549/q-WQOLDpeKSudKpz42T3dyo3/pygame-window-2024-08-28-11-30-51.mp4"></video></a></div>



<a name="465707697"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465707697" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465707697">(Aug 28 2024 at 09:33)</a>:</h4>
<p>This is trained with 100 frames 256x256</p>



<a name="465708100"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465708100" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465708100">(Aug 28 2024 at 09:34)</a>:</h4>
<p>We need more frames with even higher resolution...</p>



<a name="465981694"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465981694" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465981694">(Aug 29 2024 at 11:13)</a>:</h4>
<p><a href="/user_uploads/1549/jiFfB3UBz-pNSaSThS1x6Fke/pygame-window-2024-08-29-13-11-50.mp4">pygame-window-2024-08-29-13-11-50.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/jiFfB3UBz-pNSaSThS1x6Fke/pygame-window-2024-08-29-13-11-50.mp4" title="pygame-window-2024-08-29-13-11-50.mp4"><video preload="metadata" src="/user_uploads/1549/jiFfB3UBz-pNSaSThS1x6Fke/pygame-window-2024-08-29-13-11-50.mp4"></video></a></div>



<a name="465982116"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465982116" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465982116">(Aug 29 2024 at 11:15)</a>:</h4>
<p>I have trained without the loss function of the distance and it has understood by itself the true model. <span aria-label="joy" class="emoji emoji-1f602" role="img" title="joy">:joy:</span></p>



<a name="465982280"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465982280" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465982280">(Aug 29 2024 at 11:15)</a>:</h4>
<p>In this case it seems that the loss of the distance gets worse the model</p>



<a name="465982460"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465982460" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465982460">(Aug 29 2024 at 11:15)</a>:</h4>
<p>The resolution is always 256x256 but trained with 500 frames this time.</p>



<a name="465982688"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/465982688" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#465982688">(Aug 29 2024 at 11:16)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="700180">@fall Rainy</span></p>



<a name="466100345"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466100345" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466100345">(Aug 29 2024 at 19:47)</a>:</h4>
<p><a href="/user_uploads/1549/fiF5ItNwr6Jq0fh62mZJfkv5/pygame-window-2024-08-29-21-45-53.mp4">pygame-window-2024-08-29-21-45-53.mp4</a><br>
I changed the loss function and now it is very good :)</p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/fiF5ItNwr6Jq0fh62mZJfkv5/pygame-window-2024-08-29-21-45-53.mp4" title="pygame-window-2024-08-29-21-45-53.mp4"><video preload="metadata" src="/user_uploads/1549/fiF5ItNwr6Jq0fh62mZJfkv5/pygame-window-2024-08-29-21-45-53.mp4"></video></a></div>



<a name="466326561"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466326561" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466326561">(Aug 30 2024 at 18:56)</a>:</h4>
<p>Today I did a big improvement in the number of sample points. Depending on the model, you need a fixed tolerance between each sampling point to ensure good accuracy: for example in moss a good tolerance is 0.01 (remember that we should sample in range 0-1 where 0 means that we are sampling on the origin and 1 means we are sampling on the destination on the bounding sphere).<br>
The trivial solution is using the uniform sampling for each ray (it was the solution I used before today). With uniform sampling you need a number of points that is equal to range/tolerance. This is the reason why in moss I need 1/0.01 = 100 points.</p>



<a name="466326829"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466326829" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466326829">(Aug 30 2024 at 18:58)</a>:</h4>
<p>But we can do better than this because I tried to plot the distribution of all the rays and it is like this:<br>
<a href="/user_uploads/1549/AFeO0yJVwL3LxySJx3zWQWyE/distribution-rays-moss.png">distribution-rays-moss.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/AFeO0yJVwL3LxySJx3zWQWyE/distribution-rays-moss.png" title="distribution-rays-moss.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/AFeO0yJVwL3LxySJx3zWQWyE/distribution-rays-moss.png/840x560.webp"></a></div>



<a name="466326930"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466326930" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466326930">(Aug 30 2024 at 18:59)</a>:</h4>
<p>It means that in moss it follows more or less a gaussian distribution with a mean 0.7</p>



<a name="466327053"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466327053" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466327053">(Aug 30 2024 at 19:00)</a>:</h4>
<p>In the havoc model it is slightly different and it is a gaussian but with mean 0.5:<br>
<a href="/user_uploads/1549/mMIdaPCTnAeb5O6YtYRIy9iy/distribution-rays-helicopter.png">distribution-rays-helicopter.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/mMIdaPCTnAeb5O6YtYRIy9iy/distribution-rays-helicopter.png" title="distribution-rays-helicopter.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/mMIdaPCTnAeb5O6YtYRIy9iy/distribution-rays-helicopter.png/840x560.webp"></a></div>



<a name="466327316"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466327316" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466327316">(Aug 30 2024 at 19:02)</a>:</h4>
<p>So a first improvement would be to follow these distribution to sample more samples on the mean and less points far from the mean</p>



<a name="466330264"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466330264" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466330264">(Aug 30 2024 at 19:25)</a>:</h4>
<p>But we can do even better: we can divide our bounding sphere into cells (choosing an arbitrary resolution) and precompute the distribution for each pair of cell_origin and cell_destination. This way, the distribution no longer follows a Gaussian pattern but instead aligns with the local distribution in those areas. This represents a significant improvement because, not only do we capture the local distribution, but the range will also be reduced for almost all pairs. This is evident, as similar rays will have similar hit distances, as in this case:</p>
<p><a href="/user_uploads/1549/8W6OmznGYvjI-T-Fe6wESDGw/distribution-rays-helicopter-local.png">distribution-rays-helicopter-local.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/8W6OmznGYvjI-T-Fe6wESDGw/distribution-rays-helicopter-local.png" title="distribution-rays-helicopter-local.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/8W6OmznGYvjI-T-Fe6wESDGw/distribution-rays-helicopter-local.png/840x560.webp"></a></div>



<a name="466330398"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466330398" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466330398">(Aug 30 2024 at 19:26)</a>:</h4>
<p>Or like this<br>
<a href="/user_uploads/1549/2qEhYiX34x6JIuApFXeSOHPY/distribution-rays-helicopter-local-2.png">distribution-rays-helicopter-local-2.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/2qEhYiX34x6JIuApFXeSOHPY/distribution-rays-helicopter-local-2.png" title="distribution-rays-helicopter-local-2.png"><img data-original-dimensions="640x480" src="/user_uploads/thumbnail/1549/2qEhYiX34x6JIuApFXeSOHPY/distribution-rays-helicopter-local-2.png/840x560.webp"></a></div>



<a name="466331948"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466331948" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466331948">(Aug 30 2024 at 19:38)</a>:</h4>
<p>Moreover not all the rays have the same length because in a bounding sphere (of ray 1) we have the maximum length for the rays that have exactly length equal to 2 * radius but all the other rays will have a smaller length so we can even sample less points</p>



<a name="466332090"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466332090" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466332090">(Aug 30 2024 at 19:39)</a>:</h4>
<p>In these days I will try to merge all these ideas together and I will update you. If you have any other idea let me know :)</p>



<a name="466333904"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466333904" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466333904">(Aug 30 2024 at 19:51)</a>:</h4>
<p><a href="/user_uploads/1549/6r8lYoOo0pkv8w9duN79v2l-/intersection-prediction.pdf">intersection-prediction.pdf</a><br>
This paper for example use a similar approach to my idea but they use an hashmap based on quantization of input (rays origin + rays destination) instead of cells</p>



<a name="466444639"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466444639" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466444639">(Aug 31 2024 at 04:41)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/466100345">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/fiF5ItNwr6Jq0fh62mZJfkv5/pygame-window-2024-08-29-21-45-53.mp4">pygame-window-2024-08-29-21-45-53.mp4</a><br>
I changed the loss function and now it is very good :)</p>
</blockquote>
<p>That is very good indeed!  Very nice shape and color registration all around.  That's considerably better than I would have expected for that model.</p>



<a name="466445125"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466445125" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466445125">(Aug 31 2024 at 04:44)</a>:</h4>
<p>So now is that pygame visualizaiton doing real-time inference / lookups from the NNet or do you export the latent space to some fixed representation like mesh or voxels or lightfields, etc.?  If they're real-time lookups, what's the lookup rate?  Is there a significant diff between havoc and moss?</p>



<a name="466445579"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466445579" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466445579">(Aug 31 2024 at 04:45)</a>:</h4>
<p>Either way, this is looking very much like you're approaching publication-worthy if you want to take this work to the next level... we could also probably turn it into a feature, depending on how long training takes, how long it takes to load the net, how long inference takes, etc.</p>



<a name="466496005"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466496005" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466496005">(Aug 31 2024 at 09:08)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/466445125">ha scritto</a>:</p>
<blockquote>
<p>So now is that pygame visualizaiton doing real-time inference / lookups from the NNet or do you export the latent space to some fixed representation like mesh or voxels or lightfields, etc.?  If they're real-time lookups, what's the lookup rate?  Is there a significant diff between havoc and moss?</p>
</blockquote>
<p>They are real time lookups, you can see the code here <a href="https://github.com/bralani/rt_volume/blob/neural_rendering/src/rt/nvbh/camera.py">https://github.com/bralani/rt_volume/blob/neural_rendering/src/rt/nvbh/camera.py</a>. The inference time for each call of the forward method (ie this instruction output_label, _, _, output_rgb = model(input)) takes an average time of 1-2 ms for the havoc model (remember that in pygame the images are 256x256) but due to the limitations of python I have these metrics:<br>
Time to generate rays:  3.155 ms  -&gt; time to calculate the origin ray + direction ray for each pixel of the 256x256 camera<br>
Time to trace rays:  22 ms  -&gt; bottleneck due to the limitations of python (this includes the time to transfer data from cpu to gpu + the formula of intersection ray with sphere + the conversion to cartesian to spherical coordinates + the inference time + the time to transfer data from gpu to cpu. Since the inference time is only 1-2 ms, you can understand that all the time is taken by previous calculations + transfer time).<br>
Time to render image:  0.99 ms -&gt; time that pygame takes to show the input image<br>
So summing all together it takes something like 26 ms to render one frame (and it can be much better in C++) so I have an average of 36 FPS (in python).</p>



<a name="466497782"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466497782" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466497782">(Aug 31 2024 at 09:15)</a>:</h4>
<p>Instead, with moss model I can use a simpler network (with less resolution) and less sampling points (I have not implemented the smart sampling yet, I am still using the uniform one at the moment) and the times are these ones:<br>
Time to generate rays:  3,15ms (the same as before)<br>
Time to trace rays:  15,6 ms (with an inference time that is still of 1-2 ms)<br>
Time to render image: 0.99 ms<br>
In this case I have a total time of 19,75 ms with an average 50 FPS.</p>



<a name="466511439"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466511439" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466511439">(Aug 31 2024 at 10:51)</a>:</h4>
<p>There was an error in the trace rays method, I did all the calculations on the cpu and I moved to the gpu just before the inference call. Now I move the rays after their generation and the times are these:</p>
<p>MOSS:<br>
Time to generate rays: 3,15ms (the same as before)<br>
Time to trace rays: 10,19 ms (with an inference time that is still of 1-2 ms)<br>
Time to render image: 0.99 ms<br>
In this case I have a total time of 14,34 ms with an average 70 FPS.</p>
<p>HAVOC:<br>
Time to generate rays: 3,15ms (the same as before)<br>
Time to trace rays: 14,13 ms (with an inference time that is still of 1-2 ms)<br>
Time to render image: 0.99 ms<br>
In this case I have a total time of 18,28 ms with an average 54 FPS.</p>



<a name="466511846"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466511846" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466511846">(Aug 31 2024 at 10:57)</a>:</h4>
<p>I know these times are high but I believe they are due to the python overhead</p>



<a name="466515607"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466515607" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466515607">(Aug 31 2024 at 11:39)</a>:</h4>
<p>They aren't so high like I was thinking, I have printed rendering times in brl-cad with my mac m1:</p>
<p>MOSS<br>
65536 pixels (256x256) in      0.05 sec=50ms<br>
HAVOC<br>
65536 pixels (256x256) in      0.23 sec=230ms</p>
<p>There is an improvement even using python instead of c++.</p>



<a name="466516041"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466516041" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466516041">(Aug 31 2024 at 11:42)</a>:</h4>
<p>Probably this is because in brl-cad all the rays are traced sequentially or am I wrong?</p>



<a name="466744739"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466744739" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466744739">(Sep 01 2024 at 18:31)</a>:</h4>
<p>Today I implemented the first of the proposed optimizations to reduce the number of sampling points: now I follow the global rays distribution.</p>



<a name="466744798"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466744798" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466744798">(Sep 01 2024 at 18:32)</a>:</h4>
<p>Here you can see an uniform sampling with 50 points.<br>
<a href="/user_uploads/1549/LJxxGKncIuMYZKfq4oSVZCN0/uniform-distribution.mp4">uniform-distribution.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/LJxxGKncIuMYZKfq4oSVZCN0/uniform-distribution.mp4" title="uniform-distribution.mp4"><video preload="metadata" src="/user_uploads/1549/LJxxGKncIuMYZKfq4oSVZCN0/uniform-distribution.mp4"></video></a></div>



<a name="466744877"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466744877" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466744877">(Sep 01 2024 at 18:33)</a>:</h4>
<p>And here you can see a sampling following the global rays distribution (always 50 points):<br>
<a href="/user_uploads/1549/nyyHOG84CrMZ7pDwaj5imoMO/global-distribution.mp4">global-distribution.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/nyyHOG84CrMZ7pDwaj5imoMO/global-distribution.mp4" title="global-distribution.mp4"><video preload="metadata" src="/user_uploads/1549/nyyHOG84CrMZ7pDwaj5imoMO/global-distribution.mp4"></video></a></div>



<a name="466745177"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466745177" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466745177">(Sep 01 2024 at 18:37)</a>:</h4>
<p>The difference is evident: following the global distribution we are losing something on the boundaries (because there are less rays in those areas) but in all the other parts the resolution is way better.<br>
Following this sampling alone give us some advantages (but also drawbacks like you can see) but merging together with local distribution I expect to improve even more :)</p>



<a name="466745407"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466745407" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466745407">(Sep 01 2024 at 18:39)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> Regarding the paper, which conferences/journal do you suggest? I don't have experience in this yet</p>



<a name="466825939"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/466825939" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> fall Rainy <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#466825939">(Sep 02 2024 at 05:27)</a>:</h4>
<p>Is it possible to consider CVPR2025？:<a href="https://cvpr.thecvf.com/Conferences/2025">https://cvpr.thecvf.com/Conferences/2025</a></p>



<a name="467351499"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467351499" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467351499">(Sep 03 2024 at 20:09)</a>:</h4>
<p><span class="user-mention" data-user-id="700180">@fall Rainy</span> &amp; <span class="user-mention" data-user-id="702819">@Matteo Balice</span>  CVPR is possible and desirable, but the bar is very high.  They are the premier conference right now for CV-related work including NNet reconstruction.  </p>
<p>A paper there will need to very clearly demonstrate what the significant contributions are of the work, distinct and compared with other recent papers.  Both efforts have demonstrated contributions, but will take some work to show how well or different they're performing on a test/benchmark common with some other paper (at least one).</p>
<p>The novel significant contribution will have to be identified first, which is going to be something like some % quality metric, or training convergence metric, or lookup performance metric, or some specific feature that hasn't been demonstrated (like sharp corners or some other measurable improvement).</p>



<a name="467352250"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467352250" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467352250">(Sep 03 2024 at 20:14)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/466515607">said</a>:</p>
<blockquote>
<p>They aren't so high like I was thinking, I have printed rendering times in brl-cad with my mac m1:</p>
<p>MOSS<br>
65536 pixels (256x256) in      0.05 sec=50ms<br>
HAVOC<br>
65536 pixels (256x256) in      0.23 sec=230ms</p>
<p>There is an improvement even using python instead of c++.</p>
</blockquote>
<p>So <span class="user-mention" data-user-id="702819">@Matteo Balice</span> this is outstanding performance that opens up a potential state-of-the-art contribution.  I'm not sure that's faster than the last paper that did 3 points -- you'd need to test the same models to really demonstrate that -- but it is a "new" capability if you can demonstrate something that ray traces slowly being looked up much faster.  That is, demonstrate this as a viable preprocess acceleration structure for models that are expensive to raytrace. </p>
<p>Towards exploring that, I'd suggest downloading a 3DM (NURBS) model, running 3dm-g and raytracing it.  It'll be slow as that's an unoptimized representation, but then you can show how long training takes, and how long inference/generation takes at the same resolution.  Suggest 1024x1024 since that's pretty standard and results in convenient 1M primary rays.</p>



<a name="467355191"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467355191" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467355191">(Sep 03 2024 at 20:36)</a>:</h4>
<p>Here's the stanford bunny in nurbs format that someone made and posted online where you can see how costly it is:<br>
<a href="/user_uploads/1549/RcVYBbo1Ry_yjEwqdF2cNDqC/bunny_nurbs.g">bunny_nurbs.g</a></p>
<p>For me, it takes about 35 sec to prep the first time (uncached) and 45sec to render at 1024 on my laptop, around 22k rays/sec.</p>



<a name="467355215"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467355215" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467355215">(Sep 03 2024 at 20:37)</a>:</h4>
<p><a href="/user_uploads/1549/gFdrtGGebOMpagmxnllMr4wr/Screenshot-2024-09-03-at-4.34.20-PM.png">Screenshot-2024-09-03-at-4.34.20-PM.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/gFdrtGGebOMpagmxnllMr4wr/Screenshot-2024-09-03-at-4.34.20-PM.png" title="Screenshot-2024-09-03-at-4.34.20-PM.png"><img data-original-dimensions="1036x1058" src="/user_uploads/thumbnail/1549/gFdrtGGebOMpagmxnllMr4wr/Screenshot-2024-09-03-at-4.34.20-PM.png/840x560.webp"></a></div>



<a name="467469572"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467469572" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467469572">(Sep 04 2024 at 09:14)</a>:</h4>
<p><a href="/user_uploads/1549/rduCA2Y6x3cexL0-yVaBzuj8/pygame-window-2024-09-04-11-04-27.mp4">pygame-window-2024-09-04-11-04-27.mp4</a><br>
Here here is the 256x256 frames resolution trained with 100 different 512x512 frames (in pygame I have implemented only 256x256 views with a small range of the camera).</p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/rduCA2Y6x3cexL0-yVaBzuj8/pygame-window-2024-09-04-11-04-27.mp4" title="pygame-window-2024-09-04-11-04-27.mp4"><video preload="metadata" src="/user_uploads/1549/rduCA2Y6x3cexL0-yVaBzuj8/pygame-window-2024-09-04-11-04-27.mp4"></video></a></div><p>Regarding the 1024x1024, these are the times (in python without optimizations): <br>
Time to generate rays:  49,7 ms<br>
Time to trace rays:  12 ms<br>
Time to render image:  3,9 ms<br>
For a total time of 65,6 ms and an average 15,24 FPS. If you compare 65,6 ms (NN) with 66 seconds (true ray tracing on my mac M1), the NN is about 1006 times faster.</p>
<p>The true bottleneck is not the training time or the loading of the net but  the generation of the training set since generating 100 frames in 1024x1024 would require 100 x 66 seconds (on my pc) = almost 2 hours... For this reason I have trained only with 100 frames 512x512 (it has taken something like 30 minutes to generate the training set) and about 10 minutes to train it but I have not implemented the optimizations to reduce the number of sampling points yet (local sampling), so I expect that the training time (and inference) can be even smaller.</p>



<a name="467557205"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467557205" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467557205">(Sep 04 2024 at 14:33)</a>:</h4>
<p>I wanted to compare also the "statuette" model as in the nbvh paper and in the neural intersection paper, so I downloaded the stl model, converted to .g and ray-traced it. According to the nbvh paper it should take 4,9ms to ray-trace it (1920x1080):</p>
<p><a href="/user_uploads/1549/eMxzASzv2DXR4VkzoZVPMFdb/Screenshot-2024-09-04-alle-16.30.49.png">Screenshot-2024-09-04-alle-16.30.49.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/eMxzASzv2DXR4VkzoZVPMFdb/Screenshot-2024-09-04-alle-16.30.49.png" title="Screenshot-2024-09-04-alle-16.30.49.png"><img data-original-dimensions="334x294" src="/user_uploads/thumbnail/1549/eMxzASzv2DXR4VkzoZVPMFdb/Screenshot-2024-09-04-alle-16.30.49.png/840x560.webp"></a></div><p>But in brl-cad it takes several several minutes in 1024x1024... <br>
Using only a 256x256 size it takes about 60 seconds:<br>
<a href="/user_uploads/1549/WKEvDmBO1CJ3huZV7P6EbH6l/outputstatuette.png">outputstatuette.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/WKEvDmBO1CJ3huZV7P6EbH6l/outputstatuette.png" title="outputstatuette.png"><img data-original-dimensions="256x256" src="/user_uploads/thumbnail/1549/WKEvDmBO1CJ3huZV7P6EbH6l/outputstatuette.png/840x560.webp"></a></div><p>Why is there this behaviour?</p>



<a name="467557744"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467557744" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467557744">(Sep 04 2024 at 14:35)</a>:</h4>
<p>The model .g weights 600mb, while the stl is 500mb</p>



<a name="467559834"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467559834" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467559834">(Sep 04 2024 at 14:41)</a>:</h4>
<p>P.S:<br>
Seeing the times to ray trace all those models (according to the nbvh paper) it seems there is a bottleneck in my python code in the generation of the rays since in 1024x1024 it takes me 49 ms and it cannot be so bad.</p>



<a name="467588972"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/467588972" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#467588972">(Sep 04 2024 at 16:05)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/467559834">ha scritto</a>:</p>
<blockquote>
<p>P.S:<br>
Seeing the times to ray trace all those models (according to the nbvh paper) it seems there is a bottleneck in my python code in the generation of the rays since in 1024x1024 it takes me 49 ms and it cannot be so bad.</p>
</blockquote>
<p>I was right, there was a bottleneck in the generation of rays, now it is less than 1ms to generate 1M rays so the bunny model is raytraced in about 16-17 ms.</p>



<a name="469196400"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469196400" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469196400">(Sep 10 2024 at 19:49)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> can you show a 1024x1024 rendering of Bunny?  Looking to directly compare both performance (time0 and deviation (pixdiff) for a given view.</p>



<a name="469696669"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469696669" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469696669">(Sep 12 2024 at 14:46)</a>:</h4>
<p><a href="/user_uploads/1549/E1RoK2AFRjeLtFKoYlkBPxrF/bunny_pred.png">bunny_pred.png</a><br>
<a href="/user_uploads/1549/pE_hfSL2NJaegIjMFtiIkZpP/bunny_true.png">bunny_true.png</a><br>
The time is an average of 17ms but I'm trying to figure out why the light does not look like the true one</p>
<div class="message_inline_image"><a href="/user_uploads/1549/E1RoK2AFRjeLtFKoYlkBPxrF/bunny_pred.png" title="bunny_pred.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/E1RoK2AFRjeLtFKoYlkBPxrF/bunny_pred.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/pE_hfSL2NJaegIjMFtiIkZpP/bunny_true.png" title="bunny_true.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/pE_hfSL2NJaegIjMFtiIkZpP/bunny_true.png/840x560.webp"></a></div>



<a name="469697279"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469697279" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469697279">(Sep 12 2024 at 14:48)</a>:</h4>
<p>The shape is correctly encoded, it seems I have the same problem as in the moss model (the training set was small)</p>



<a name="469735083"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469735083" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469735083">(Sep 12 2024 at 17:22)</a>:</h4>
<p>thank you <span class="user-mention" data-user-id="702819">@Matteo Balice</span> that's definitely looking production-viable even with the light source issue.  How long did training take?  How many samples, how much time, etc?</p>



<a name="469735595"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469735595" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469735595">(Sep 12 2024 at 17:25)</a>:</h4>
<p>I'm wondering if we could try for actual integration in the time remaining, or if the shift to writing up a paper is more in order.  For integration, it would entail modifying the 'rt' application to have a training mode where some command-line flag would tell it to train/use the neural net in place of the do_pixel() function (since you have color).  Something like rt -N bunny.weights bunny.g bunny</p>



<a name="469735689"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469735689" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469735689">(Sep 12 2024 at 17:26)</a>:</h4>
<p>If bunny.weights doesn't exist, it trains.  If it does, it loads and uses it.</p>



<a name="469766490"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469766490" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469766490">(Sep 12 2024 at 19:45)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/469735083">ha scritto</a>:</p>
<blockquote>
<p>thank you <span class="user-mention silent" data-user-id="702819">Matteo Balice</span> that's definitely looking production-viable even with the light source issue.  How long did training take?  How many samples, how much time, etc?</p>
</blockquote>
<p>The training set consisted of 100 images with a resolution of 512x512 (approximately 26 million in total). The model was trained for approximately 5 minutes. The F1 loss for shape prediction was around 0.995. Additionally, the average error in predicting the hit position along the ray was about 0.006 -&gt; shape and hit position almost perfect.<br>
Regarding the RGB prediction, however, I have an average error of 24 (in "rgb" scale).</p>
<p>Each ray samples 200 points (each point has 3 float32 numbers: x y z) along its path, meaning each ray occupies 200 x (3 x 4 bytes (float32)) = 2,3 KB on the GPU. For training, I use a batch size of 2^13 rays per iteration, resulting in 2^13 x 2,3KB = 19.6 MB in memory.<br>
During the prediction process, the larger the batch size, the better the GPU parallelism can be utilized. Therefore, I load all 1024x1024 rays simultaneously, which requires 1024 x 1024 x 2,3 KB = 2,5 GB (my GPU allows it but it's ok to execute more iterations of the set of rays, it will be just a little bit slower).</p>
<p>I believe it is possible to reduce the number of sampling points but I am still working on it, I have not achieved good results for example sampling locally.</p>



<a name="469767078"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469767078" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469767078">(Sep 12 2024 at 19:48)</a>:</h4>
<p>I tried also with 500 frames in 256x256 and in this case the light's direction is encoded well but not the intensity.<br>
<a href="/user_uploads/1549/FnHCM-pWT5XGETeyXO6QXLKb/bunny_1024.png">bunny_1024.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/FnHCM-pWT5XGETeyXO6QXLKb/bunny_1024.png" title="bunny_1024.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/FnHCM-pWT5XGETeyXO6QXLKb/bunny_1024.png/840x560.webp"></a></div>



<a name="469767881"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469767881" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469767881">(Sep 12 2024 at 19:52)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/469735595">ha scritto</a>:</p>
<blockquote>
<p>I'm wondering if we could try for actual integration in the time remaining, or if the shift to writing up a paper is more in order.  For integration, it would entail modifying the 'rt' application to have a training mode where some command-line flag would tell it to train/use the neural net in place of the do_pixel() function (since you have color).  Something like rt -N bunny.weights bunny.g bunny</p>
</blockquote>
<p>Regarding the integration there are some points to understand first in order to achieve good results in inference time like I had in python:</p>
<ul>
<li>First of all we need batch processing of multiple rays in parallel (for examples 2^13 rays in parallel). Is there already implemented batch processing of rays in brl-cad?</li>
</ul>



<a name="469768152"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469768152" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469768152">(Sep 12 2024 at 19:53)</a>:</h4>
<ul>
<li>Second, I believe that it's better to write the NN in C++ and not binding with python to speed up even more, but this means that we need to write manually the code in CUDA for the GPU (for example I use the function torch.max in pytorch that are optimized for cuda GPUs).</li>
</ul>



<a name="469770376"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469770376" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469770376">(Sep 12 2024 at 20:03)</a>:</h4>
<p>I believe our approach is more suited to GPUs compared to NBVH, as it involves fewer conditional branches. This is because we completely avoid using BVHs; the only intersection we calculate is with the bounding sphere. After that, the inference process remains consistent for every ray, exploiting the true power of GPUs. This is the reason why even using more sampling point we have good results in inference time.</p>



<a name="469771106"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/469771106" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#469771106">(Sep 12 2024 at 20:06)</a>:</h4>
<p>I discovered one drawback: when I render the scene in 1024x1024 in pygame it's good for the first seconds (16-17 ms for each frame) but after that the memory of GPU goes to 100% and the inference time slow down a lot. Probably this is because they do not use well the garbage collector of tensors accumulated for previous frames (I have a RTX 4070 with 13GB of VRAM).</p>



<a name="472842346"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/472842346" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#472842346">(Sep 26 2024 at 08:30)</a>:</h4>
<p>I have written a report for my work, let me know if there are something missing or that I should change.</p>
<p><a href="/user_uploads/1549/WF1ql5ef87OW0jWDBWob91yb/Neural_rendering_paper.pdf">Neural_rendering_paper.pdf</a></p>
<p><span class="user-mention" data-user-id="102902">@Sean</span> <span class="user-mention" data-user-id="700180">@fall Rainy</span></p>



<a name="472903225"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/472903225" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#472903225">(Sep 26 2024 at 13:56)</a>:</h4>
<p>That's outstanding <span class="user-mention" data-user-id="702819">@Matteo Balice</span></p>



<a name="472903465"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/472903465" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#472903465">(Sep 26 2024 at 13:57)</a>:</h4>
<p>I'm still reading it, but I did a quick read through and really great write-up!  Love the background and inclusion of your early incremental progress, and of course final results.</p>



<a name="472908150"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/472908150" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#472908150">(Sep 26 2024 at 14:18)</a>:</h4>
<p>I attempted also to integrate the PyTorch code into the rt module, but encountered an issue with the PyTorch library I used for multi-hash resolution. The problem is that the library includes CUDA-specific scripts, preventing me from exporting the neural network...</p>



<a name="474475608"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474475608" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474475608">(Oct 03 2024 at 05:06)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span>  and <span class="user-mention" data-user-id="700180">@fall Rainy</span>  I'd like to showcase your work at the mentor summit.  Do you have a brief video or favorite image(s) that you'd like me to show that you feel best captures the results of your research?</p>



<a name="474512568"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474512568" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474512568">(Oct 03 2024 at 07:54)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/474475608">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span>  and <span class="user-mention silent" data-user-id="700180">fall Rainy</span>  I'd like to showcase your work at the mentor summit.  Do you have a brief video or favorite image(s) that you'd like me to show that you feel best captures the results of your research?</p>
</blockquote>
<p><a href="/user_uploads/1549/ECXvsG-8wrQR1hiEBJ7YlVSP/bunny_pred.png">bunny_pred.png</a><br>
<a href="/user_uploads/1549/mp3AwR0M9WyhpDdMZc5FCGzL/bunny_true.png">bunny_true.png</a><br>
<a href="/user_uploads/1549/X0rc8EBiokcoORjjqKr3TXCi/havoc_pred.png">havoc_pred.png</a><br>
<a href="/user_uploads/1549/1w-YCROWDkpWRBZ_Yb6vpc3D/havoc_true.png">havoc_true.png</a><br>
<a href="/user_uploads/1549/sndJWTG5Eloiyt9lLCyMRwxI/moss_pred.png">moss_pred.png</a><br>
<a href="/user_uploads/1549/JOViPmkpLpdewKl14S9TYcSe/moss_true.png">moss_true.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/1549/ECXvsG-8wrQR1hiEBJ7YlVSP/bunny_pred.png" title="bunny_pred.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/ECXvsG-8wrQR1hiEBJ7YlVSP/bunny_pred.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/mp3AwR0M9WyhpDdMZc5FCGzL/bunny_true.png" title="bunny_true.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/mp3AwR0M9WyhpDdMZc5FCGzL/bunny_true.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/X0rc8EBiokcoORjjqKr3TXCi/havoc_pred.png" title="havoc_pred.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/X0rc8EBiokcoORjjqKr3TXCi/havoc_pred.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/1w-YCROWDkpWRBZ_Yb6vpc3D/havoc_true.png" title="havoc_true.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/1w-YCROWDkpWRBZ_Yb6vpc3D/havoc_true.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/sndJWTG5Eloiyt9lLCyMRwxI/moss_pred.png" title="moss_pred.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/sndJWTG5Eloiyt9lLCyMRwxI/moss_pred.png/840x560.webp"></a></div><div class="message_inline_image"><a href="/user_uploads/1549/JOViPmkpLpdewKl14S9TYcSe/moss_true.png" title="moss_true.png"><img data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/1549/JOViPmkpLpdewKl14S9TYcSe/moss_true.png/840x560.webp"></a></div>



<a name="474601936"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474601936" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474601936">(Oct 03 2024 at 14:20)</a>:</h4>
<p>Can you make a diagram of your network layers?  While a technical audience, they’re not necessarily familiar with graphics or ai at all.</p>



<a name="474603087"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474603087" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474603087">(Oct 03 2024 at 14:24)</a>:</h4>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/467469572">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/rduCA2Y6x3cexL0-yVaBzuj8/pygame-window-2024-09-04-11-04-27.mp4">pygame-window-2024-09-04-11-04-27.mp4</a><br>
Here here is the 256x256 frames resolution trained with 100 different 512x512 frames (in pygame I have implemented only 256x256 views with a small range of the camera).</p>
<p>Regarding the 1024x1024, these are the times (in python without optimizations): <br>
Time to generate rays:  49,7 ms<br>
Time to trace rays:  12 ms<br>
Time to render image:  3,9 ms<br>
For a total time of 65,6 ms and an average 15,24 FPS. If you compare 65,6 ms (NN) with 66 seconds (true ray tracing on my mac M1), the NN is about 1006 times faster.</p>
<p>The true bottleneck is not the training time or the loading of the net but  the generation of the training set since generating 100 frames in 1024x1024 would require 100 x 66 seconds (on my pc) = almost 2 hours... For this reason I have trained only with 100 frames 512x512 (it has taken something like 30 minutes to generate the training set) and about 10 minutes to train it but I have not implemented the optimizations to reduce the number of sampling points yet (local sampling), so I expect that the training time (and inference) can be even smaller.</p>
</blockquote>
<p>Wonder if we could show bunny spinning orbitally.  This video is really good results but the view stays focused on the bunny’s butt.. even a simple 360 orbital would probably do well.</p>



<a name="474608224"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474608224" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474608224">(Oct 03 2024 at 14:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/474603087">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/467469572">said</a>:</p>
<blockquote>
<p><a href="/user_uploads/1549/rduCA2Y6x3cexL0-yVaBzuj8/pygame-window-2024-09-04-11-04-27.mp4">pygame-window-2024-09-04-11-04-27.mp4</a><br>
Here here is the 256x256 frames resolution trained with 100 different 512x512 frames (in pygame I have implemented only 256x256 views with a small range of the camera).</p>
<p>Regarding the 1024x1024, these are the times (in python without optimizations): <br>
Time to generate rays:  49,7 ms<br>
Time to trace rays:  12 ms<br>
Time to render image:  3,9 ms<br>
For a total time of 65,6 ms and an average 15,24 FPS. If you compare 65,6 ms (NN) with 66 seconds (true ray tracing on my mac M1), the NN is about 1006 times faster.</p>
<p>The true bottleneck is not the training time or the loading of the net but  the generation of the training set since generating 100 frames in 1024x1024 would require 100 x 66 seconds (on my pc) = almost 2 hours... For this reason I have trained only with 100 frames 512x512 (it has taken something like 30 minutes to generate the training set) and about 10 minutes to train it but I have not implemented the optimizations to reduce the number of sampling points yet (local sampling), so I expect that the training time (and inference) can be even smaller.</p>
</blockquote>
<p>Wonder if we could show bunny spinning orbitally.  This video is really good results but the view stays focused on the bunny’s butt.. even a simple 360 orbital would probably do well.</p>
</blockquote>
<p>Sure no problem.</p>



<a name="474658968"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474658968" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474658968">(Oct 03 2024 at 18:30)</a>:</h4>
<p>Interesting paper <a href="https://half-potato.gitlab.io/posts/ever/">https://half-potato.gitlab.io/posts/ever/</a></p>



<a name="474899534"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474899534" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sean <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474899534">(Oct 04 2024 at 20:53)</a>:</h4>
<p><span class="user-mention" data-user-id="702819">@Matteo Balice</span> any update on the orbital video?  Presentation is tomorrow morning :)</p>



<a name="474899674"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474899674" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474899674">(Oct 04 2024 at 20:55)</a>:</h4>
<p><span class="user-mention silent" data-user-id="102902">Sean</span> <a href="#narrow/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering/near/474899534">ha scritto</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="702819">Matteo Balice</span> any update on the orbital video?  Presentation is tomorrow morning :)</p>
</blockquote>
<p>I am currently generating it</p>



<a name="474910293"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474910293" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474910293">(Oct 04 2024 at 22:42)</a>:</h4>
<p><a href="/user_uploads/1549/ZksE16PSfajxZPA6wy8C-cu4/video_bunny.mp4">video_bunny.mp4</a></p>
<div class="message_inline_image message_inline_video"><a href="/user_uploads/1549/ZksE16PSfajxZPA6wy8C-cu4/video_bunny.mp4" title="video_bunny.mp4"><video preload="metadata" src="/user_uploads/1549/ZksE16PSfajxZPA6wy8C-cu4/video_bunny.mp4"></video></a></div><p><a href="https://drive.google.com/file/d/1ook3N4hRjUqK-7SKuEH-4qV48Sa6kxWO/view?usp=sharing">https://drive.google.com/file/d/1ook3N4hRjUqK-7SKuEH-4qV48Sa6kxWO/view?usp=sharing</a></p>



<a name="474910545"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474910545" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474910545">(Oct 04 2024 at 22:45)</a>:</h4>
<p>I don't know why it becomes all white from behind</p>



<a name="474983660"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/474983660" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#474983660">(Oct 05 2024 at 13:59)</a>:</h4>
<p><span class="user-mention" data-user-id="102902">@Sean</span> How was the presentation?</p>



<a name="522847656"></a>
<h4><a href="https://brlcad.zulipchat.com#narrow/stream/111975-Google%20Summer%20of%20Code/topic/Neural%20Rendering/near/522847656" class="zl"><img src="https://brl-cad.github.io/zulip_archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Balice <a href="https://brl-cad.github.io/zulip_archive/stream/111975-Google-Summer-of-Code/topic/Neural.20Rendering.html#522847656">(Jun 06 2025 at 21:16)</a>:</h4>
<p>Very cool paper that will be presented at siggraph 2025</p>
<p><a href="https://renderformer.github.io/pdfs/renderformer-paper.pdf">https://renderformer.github.io/pdfs/renderformer-paper.pdf</a></p>



<hr><p>Last updated: Oct 20 2025 at 00:56 UTC</p>
</html>